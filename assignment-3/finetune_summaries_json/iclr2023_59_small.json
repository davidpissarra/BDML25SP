{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" IBM Research Brazil Campbell D. Watson IBM Research New York, USADavid Rolnick Mila Quebec AI Institute Montreal, Canada ABSTRACT Running climate simulations informs us of future climate change. However, it is computationally expensive to resolve complex climate processes numerically. As one way to speed up climate simulations, neural networks have been used to downscale climate variables from fast-running low-resolution simulations. So far, all neural network downscaling models can only downscale input samples with a pre-defined upsampling factor. In this work, we propose a Fourier neural opera- tor downscaling model. It trains with data of a small upsampling factor and then can zero-shot downscale its input to arbitrary unseen high-resolutions. Evaluated on Navier-Stokes equation solution data and ERA5 water content data, our down- scaling model demonstrates better performance than widely used convolutional and adversarial generative super-resolution models in both learned and zero-shot downscaling. Our model’s performance is further boosted when a constraint layer is applied. In the end, we show that by combining our downscaling model with a low-resolution numerical PDE solver, the downscaled solution outperforms the solution of the state-of-the-art high-resolution data-driven solver. Our model can be used to cheaply and accurately generate arbitrarily high-resolution climate sim- ulation data with fast-running low-resolution simulation as input. 1 I NTRODUCTION Climate simulations are running hundreds of years ahead to help us understand how climate changes in the future. Complex physical processes inside climate dynamic systems are captured by partial differential equations (PDEs), which are extremely expensive to solve numerically. As a result, run- ning a long-term high-resolution climate simulation is still not feasible within the foreseeable future (Balaji, 2021), even with the current fast-increasing computational power. Given the fast forward inference speed of neural networks, deep learning was applied to speed up climate simulations. Climate simulations at low resolution are much cheaper to run than at high resolution. Therefore, there are attempts to use network networks to generate high-resolution climate variables out of their low-resolution counterpart. Such a process is named downscaling in climate science community (or super-resolution in machine learning community). H ¨ohlein et al. (2020) used convolutional neu- ral networks (CNNs) to downscale short-range forecasts of near-surface wind fields. A conditional generative adversarial network (GAN) was trained by Price & Rasp (2022) via a custom training procedure and augmented loss function to downscale precipitation forecasts. Groenke et al. (2020) 1Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2023 proposed the first unsupervised statistical downscaling method based on normalizing flows to in- crease the resolution of temperature and precipitation data. Limited by classic neural networks, which map between finite-dimensional spaces, all neural net- work downscaling models so far have fixed input and output sizes. For a single trained model, it can only downscale input samples with a pre-defined upsampling factor. Inspired by the recent success of Fourier neural operator (Li et al., 2021, FNO) of solving PDEs regardless of resolution, we design a novel FNO zero-shot downscaling model which is able to downscale input samples to arbitrary un- seen high resolution with training only once on data of a small upsampling factor. Experiments on Navier-Stokes solution data and ERA5 reanalysis (Hersbach et al., 2020) water content data show that our model achieves great performance not only on the learned downscaling (i.e., the model is trained on) tasks but also on zero-shot downscaling (i.e., the model is not trained on) tasks. The per- formance is even further improved when a softmax constraint layer (Harder et al., 2022) is stacked at the end of our model architecture to enforce conservation laws. Using our model to downscale low-resolution solution from a numerical Navier-Stokes equation solver, the downscaled solution obtains significantly higher accuracy than that from an FNO equation solver—one of the state-of- the-art data-driven solvers. These results validate our model’s potential to cheaply and accurately generate arbitrarily high-resolution climate simulation with fast-running low-resolution simulation as input. 2 M ETHODOLOGY 2.1 P ROBLEM SETUP Consider low-resolution input a∈Rdaand high-resolution output b∈Rdbwithda< db. So far, neural network downscaling models are looking for a mapping f:Rda→Rdbfrom low-resolution input ato high-resolution output b. This formulation induces a limitation where the downscaled output resolution is fixed to be db. We propose the following formulation to relax this limitation to achieve arbitrary resolution downscaling. Instead of looking for a mapping between two finite-dimensional spaces, our methodology learns a mapping from a finite-dimensional space to an infinite-dimensional space. Namely, this mapping takes in low-resolution input a\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nIBM Research Brazil and Campbell D. Watson, IBM Research New York, USADavid Rolnick, Mila Quebec AI Institute, Montreal, Canada\n\nABSTRACT\n\nRunning climate simulations informs us about future climate change. However, it is computationally expensive to resolve complex climate processes numerically. One way to speed up climate simulations is to use neural networks to downscale climate variables from fast-running low-resolution simulations. So far, all neural network downscaling models can only downscale input samples with a pre-defined upsampling factor. In this work, we propose a Fourier neural operator downscaling model. It trains with data of a small upsampling factor and can then downscale its input to arbitrary unseen high-resolutions without additional training. Evaluated on Navier-Stokes equation solution data and ERA5 water content data, our downscaling model demonstrates better performance than widely used convolutional and adversarial generative super-resolution models in both learned and zero-shot downscaling. Our model's performance is further improved when a constraint layer is applied. We also show that by combining our downscaling model with a low-resolution numerical PDE solver, the downscaled solution outperforms the solution of the state-of-the-art high-resolution data-driven solver. Our model can be used to generate arbitrarily high-resolution climate simulation data with fast-running low-resolution simulation as input.\n\nINTRODUCTION\n\nClimate simulations are run hundreds of years ahead to help us understand future climate changes. Complex physical processes inside climate dynamic systems are captured by partial differential equations (PDEs), which are extremely expensive to solve numerically. As a result, running a long-term high-resolution climate simulation is still not feasible within the foreseeable future, even with the current fast-increasing computational power. Given the fast forward inference speed of neural networks, deep learning was applied to speed up climate simulations. Climate simulations at low resolution are much cheaper to run than at high resolution. Therefore, there are attempts to use neural networks to generate high-resolution climate variables from their low-resolution counterparts. This process is named downscaling in the climate science community (or super-resolution in the machine learning community).\n\nPrevious studies have used convolutional neural networks (CNNs) to downscale short-range forecasts of near-surface wind fields (Höhlein et al., 2020) and conditional generative adversarial networks (GANs) to downscale precipitation forecasts (Price & Rasp, 2022). Groenke et al. (2020) proposed the first unsupervised statistical downscaling method based on normalizing flows to increase the resolution of temperature and precipitation data. However, all neural network downscaling models so far have a limitation: they can only downscale input samples with a pre-defined upsampling factor. Inspired by the recent success of Fourier neural operators (FNO) in solving PDEs regardless of resolution, we design a novel FNO zero-shot downscaling model that can downscale input samples to arbitrary unseen high resolution with training only once on data of a small upsampling factor.\n\nExperiments on Navier-Stokes solution data and ERA5 reanalysis water content data show that our model achieves great performance not only on learned downscaling tasks but also on zero-shot downscaling tasks. The performance is even further improved when a softmax constraint layer (Harder et al., 2022) is stacked at the end of our model architecture to enforce conservation laws. Using our model to downscale low-resolution solutions from a numerical Navier-Stokes equation solver, the downscaled solution obtains significantly higher accuracy than that from an FNO equation solver, one of the state-of-the-art data-driven solvers. These results validate our model's potential to generate arbitrarily high-resolution climate simulation data with fast-running low-resolution simulation as input.\n\nMETHODOLOGY\n\n2.1 PROBLEM SETUP\n\nConsider low-resolution input a∈Rda and high-resolution output b∈Rdb with da < db. So far, neural network downscaling models have been looking for a mapping f:Rda→Rdb from low-resolution input a to high-resolution output b. This formulation induces a limitation where the downscaled output resolution is fixed to be db. We propose a new formulation to relax this limitation and achieve arbitrary resolution downscaling. Instead of looking for a mapping between two finite-dimensional spaces, our methodology learns a mapping from a finite-dimensional space to an infinite-dimensional space. This mapping takes in low-resolution input a and produces a high-resolution output b with arbitrary resolution db."
}