{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" or by including the diagnostic variable as a target in the DDWP. However, the cost of training and deploying bespoke models for each diagnostic variable can increase dramatically with more diagnostic variables, and limit the operational use of such models. Likewise, retraining an entire DDWP each time a new diagnostic variable is added is also cost-prohibitive. We present an two-stage approach that allows new diagnostic variables to be added to an end-to-end DDWP model without the expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen and \"downstream\" models are trained to predict diag- nostic variables using only the latent representations of prognostic variables as input. Our experiments indicate that models trained using the two-stage approach offer accuracy comparable to training bespoke models, while leading to significant reduction in resource utilization during training and inference. This approach allows for new \"downstream\" models to be developed as needed, without affecting existing models and thus reducing the friction in operationalizing new models. 1 Introduction In recent years, data-driven weather prediction (DDWP) models, such as FourCastNet [ 10], GraphCast [5], and PanguWeather [ 1], have shown remarkable skill in multi-day forecasts compared to state- of-the-art, operational Numerical Weather Prediction (NWP) models such as Integrated Forecast Service (IFS) [ 12], and reanalyses data such as ERA5 [ 9]. Recent studies have indicated that these DDWP models and NWP emulators, while fully data-dependent, have learnt useful physics proving the robustness of this approach [ 2], and behave similarly to NWPs when comparing against in- situobservations [ 11]. However, most DDWPs often do not focus on diagnostic meteorological parameters such as precipitation, total cloud cover, solar irradiance, soil moisture, etc., that are essential for decision making in industries like transportation, energy, and agriculture. GraphCast[ 5] forecasts precipitation along with other prognostic variables, while FourCastNet[ 10] trains a bespoke model to predict precipitation, with the same complexity as the \"backbone\" model itself (Figure 1). In either approach, a full-scale DDWP needs to be re-trained for each new diagnostic variable to be predicted, which is not scalable either in training or in inference. It is commonly observed that the first few layers of most deep learning models learn a dense latent representation of the high-dimensional input space[ 7,13,14]. Since in most cases, the starting state for predict diagnostic variables is the current set of prognostic variables, we propose a two-stage approach Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.Figure 1: FourCastNet used a bespoke model to predict precipitation. A backbone model that only predicts \"core\" weather state, and a bespoke model that uses the weather state to predict diagnostic variables. Scaling such an approach for many downstream tasks would be challenging. to modeling diagnostic variables: first, we train an auto-encoder that learns to embed prognostic variables in a dense latent space. Then, for each diagnostic variable we train a \"downstream\" model that uses the dense representation of prognostic variables as an input. As the auto-encoder has already learned a high-quality dense representation, we can significantly reduce the size of each \"downstream\" model. The closest such approach is proposed in W-MAE [ 8], which also trains an auto-encoder but fine-tunes the auto-encoder to forecast prognostic variables and precipitation. Fine tuning the encoder prevents new diagnostic variables from being modeled without also re-training all previous models. In contrast, we propose training an autoencoder using decades of high quality ground truth hourly re- analyses data from ERA5, which is then frozen, and using the frozen auto-encoder to train downstream tasks. The encoderâ€™s dense representations can be used as-is, or be combined with other task-specific signals to directly forecast industry-specific weather-dependent outcomes, e.g., predicting likelihood of pest outbreaks as a function of humid weather conditions. 1.1 Our contributions The main contributions of this study are in demonstrating that (i) complex, high-dimensional weather data can be effectively represented in a condensed, embedded representation at a moderate cost, and (ii) weather-dependent tasks can be learned efficiently from dense representations of weather. We demonstrate this by not only quantifying the reconstruction error of the autoencoder model, but using it to build task-specific downstream applications, and comparing their performance to bespoke models. This finding unlocks the ability to readily use the weather state in key decision making processes by dramatically reducing the cost of training and deploying ML-driven weather models. Figure 2: a: The autoencoder model learns, via reconstructing the input, a rich dense representation of the current weather state, and b: The trained encoder is frozen and used to produce latent representations of the current weather state (block in\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nWe propose a two-stage approach to add new diagnostic variables to an end-to-end data-driven weather prediction (DDWP) model without the need for expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen, and \"downstream\" models are trained to predict diagnostic variables using only the latent representations of prognostic variables as input. Our experiments show that models trained using this approach offer accuracy comparable to bespoke models, while significantly reducing resource utilization during training and inference.\n\nThis approach allows for new \"downstream\" models to be developed as needed, without affecting existing models, thus reducing the friction in operationalizing new models.\n\nIn recent years, DDWP models such as FourCastNet, GraphCast, and PanguWeather have shown remarkable skill in multi-day forecasts compared to state-of-the-art, operational Numerical Weather Prediction (NWP) models. However, most DDWPs often do not focus on diagnostic meteorological parameters such as precipitation, total cloud cover, solar irradiance, and soil moisture, which are essential for decision making in industries like transportation, energy, and agriculture.\n\nGraphCast forecasts precipitation along with other prognostic variables, while FourCastNet trains a bespoke model to predict precipitation with the same complexity as the \"backbone\" model. However, a full-scale DDWP needs to be re-trained for each new diagnostic variable to be predicted, which is not scalable either in training or in inference.\n\nSince the first few layers of most deep learning models learn a dense latent representation of the high-dimensional input space, we propose a two-stage approach to modeling diagnostic variables. First, we train an autoencoder that learns to embed prognostic variables in a dense latent space. Then, for each diagnostic variable, we train a \"downstream\" model that uses the dense representation of prognostic variables as an input.\n\nThe closest approach to ours is proposed in W-MAE, which trains an autoencoder but fine-tunes the autoencoder to forecast prognostic variables and precipitation. However, fine-tuning the encoder prevents new diagnostic variables from being modeled without re-training all previous models. In contrast, we propose training an autoencoder using decades of high-quality ground truth hourly re-analyses data from ERA5, which is then frozen, and using the frozen autoencoder to train downstream tasks.\n\nOur contributions are in demonstrating that complex, high-dimensional weather data can be effectively represented in a condensed, embedded representation at a moderate cost, and that weather-dependent tasks can be learned efficiently from dense representations of weather. We demonstrate this by quantifying the reconstruction error of the autoencoder model and using it to build task-specific downstream applications, and comparing their performance to bespoke models. This finding unlocks the ability to readily use the weather state in key decision-making processes by dramatically reducing the cost of training and deploying ML-driven weather models."
}