{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"ervised learning for remote sensing data. Current self-supervised learning approaches for remote sensing data draw significant inspiration from techniques applied to natural images. However, remote sensing data has important differences from natural images – for example, the temporal dimension is critical for many tasks and data is collected from many complementary sensors. We show we can create significantly smaller performant models by designing architectures and self-supervised training techniques specifically for remote sensing data. We introduce the Pretrained Remote Sensing Transf ormer (Presto), a transformer-based model pre-trained on remote sensing pixel-timeseries data. Presto excels at a wide variety of globally distributed remote sensing tasks and performs competitively with much larger models while requiring far less compute. Presto can be used for transfer learning or as a feature extractor for simple models, enabling efficient deployment at scale. 1 Introduction & Related Work Recent advances in machine learning capabilities combined with vast remote sensing datasets have provided critical tools for mitigating and adapting to climate change, ranging from improved weather forecasting (English et al., 2013; V oosen, 2020) to disaster management (Kansakar and Hossain, 2016) to improving food security in a changing climate Krafft; Tseng et al. (2020). However, the remote sensing data modality has several characteristics that are important to consider when designing machine learning algorithms in this domain: •Highly multi-modal data : Satellites carry a wide range of sensors, including synthetic aperture radar (Torres et al., 2012) and multispectral optical sensors (Drusch et al., 2012). In addition, there are many derived data products which are created by the manipulation of these raw data sources (such as digital elevation maps (Rabus et al., 2003)). •A highly informative temporal dimension : The Earth’s highly dynamic nature (Yifang et al., 2015) and the relatively coarse resolution of freely available satellite data means that in remote sensing, the temporal dimension is critical for many downstream tasks (Rußwurm et al., 2023). A common approach by remote sensing practitioners is therefore to train single pixel-timeseries models (Rußwurm et al., 2023; Sainte Fare Garnot et al., 2020; Pelletier et al., 2019; Wang et al., 2020; Hengl et al., 2017) Tackling Climate Change with Machine Learning Workshop at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023).Figure 1: Presto learns from structurally-masked remote sensing pixel-timeseries. Datasets for remote sensing often have very few labels (Helber et al., 2019), which may be unreliable (Bressan et al., 2022; Yifang et al., 2015) or absent, especially for under-resourced geographies (Kerner et al., 2020; Nakalembe et al., 2021), leading to poor global generalization (Yifang et al., 2015). This limited availability of labels combined with plentiful unlabeled data has spurred the investigation of self-supervised learning algorithms for remote sensing data (Reed et al., 2022; Cong et al., 2022; Jean et al., 2019; Manas et al., 2021; Ayush et al., 2021). Previous approaches investigating self-supervised learning for remote sensing primarily treat remote sensing data as analogous to natural imagery, and therefore attempt to co-opt methods and architectures originally designed for natural imagery (i.e., ground-level photography) – for example, by using a ResNet (He et al., 2016) backbone (Jean et al., 2019; Manas et al., 2021; Ayush et al., 2021), or by adapting masked autoencoding for image classification (He et al., 2022) to satellite imagery (Reed et al., 2022; Cong et al., 2022). These models fail to leverage all the attributes of remote sensing data (for example, models which can only ingest data from a single RGB sensor, or which do not consider the temporal dimension of the data). While several pre-training methods have been proposed for remote sensing timeseries (Yuan and Lin, 2020; Yuan et al., 2022, 2023), these have not aimed at multi-task, global applicability, having been pre-trained and evaluated on highly local areas (e.g., central California) and evaluated only for a single task (e.g., crop type classification). To take advantage of the unique characteristics, global scope, and broad applicability of remote sensing data, we introduce the Pretrained Remote Sensing Transf ormer (Presto), a lightweight transformer- based model designed to ingest pixel-timeseries inputs from a variety of Earth observation sensors and data products. We tailor the self-supervised learning process to learn from multiple data sources and from the temporal dimension\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nSupervised learning for remote sensing data is challenging due to its unique characteristics. Current self-supervised learning approaches for remote sensing data draw inspiration from techniques applied to natural images, but they fail to leverage the full potential of remote sensing data. We show that we can create smaller and more performant models by designing architectures and self-supervised training techniques specifically for remote sensing data.\n\nWe introduce the Pretrained Remote Sensing Transformer (Presto), a transformer-based model pre-trained on remote sensing pixel-timeseries data. Presto excels at a wide variety of globally distributed remote sensing tasks and performs competitively with larger models while requiring less compute. Presto can be used for transfer learning or as a feature extractor for simple models, enabling efficient deployment at scale.\n\nRecent advances in machine learning capabilities combined with vast remote sensing datasets have provided critical tools for mitigating and adapting to climate change. However, remote sensing data has several characteristics that are important to consider when designing machine learning algorithms:\n\n* Highly multi-modal data: Satellites carry a range of sensors, including synthetic aperture radar and multispectral optical sensors. Derived data products, such as digital elevation maps, are also created by manipulating raw data sources.\n* Highly informative temporal dimension: The Earth's dynamic nature and the relatively coarse resolution of freely available satellite data make the temporal dimension critical for many downstream tasks.\n\nA common approach in remote sensing is to train single pixel-timeseries models. However, remote sensing datasets often have few labels, which may be unreliable or absent, especially for under-resourced geographies. This limited availability of labels has spurred the investigation of self-supervised learning algorithms for remote sensing data.\n\nPrevious approaches investigating self-supervised learning for remote sensing primarily treat remote sensing data as analogous to natural imagery, using methods and architectures originally designed for natural imagery. However, these models fail to leverage all the attributes of remote sensing data, such as the temporal dimension.\n\nTo address this, we introduce the Pretrained Remote Sensing Transformer (Presto), a lightweight transformer-based model designed to ingest pixel-timeseries inputs from a variety of Earth observation sensors and data products. We tailor the self-supervised learning process to learn from multiple data sources and from the temporal dimension, enabling global applicability and broad applicability of remote sensing data."
}