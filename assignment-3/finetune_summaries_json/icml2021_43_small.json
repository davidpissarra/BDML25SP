{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" wa- ter usage has been a slow and expensive manual process with many imperfections and abuses. Ma- chine learning and remote sensing developments have increased the ability to automatically mon- itor irrigation patterns, but existing techniques often require curated and labelled irrigation data, which are expensive and time consuming to ob- tain and may not exist for impactful areas such as developing countries. In this paper, we explore an end-to-end real world application of irrigation detection with uncurated and unlabeled satellite imagery. We apply state-of-the-art self-supervised deep learning techniques to optical remote sensing data, and ﬁnd that we are able to detect irrigation with up to nine times better precision, 90% better recall and 40% more generalization ability than the traditional supervised learning methods. 1. Introduction Water is essential for global food production and security, agriculture being the largest consumer of freshwater glob- ally (WWDR, 2014). While we need water to grow crops to address the growing demand for food, excessive use of *Equal contribution1School of Information, University of Cal- ifornia, Berkeley, USA2IBM Chief Analytics Ofﬁce, Armonk, New York, USA. Correspondence to: Chitra S. Agastya <chi- tra.agastya@berkeley.edu, Chitra.S.Agastya@ibm.com >, Sirak Ghebremusse <sirakzg@berkeley.edu >, Ian Anderson <iman- der@berkeley.edu >. Tackling Climate Change with Machine Learning Workshop at ICML 2021.water has negatively impacted ecosystem and adversely af- fected crop production and livelihood. Ground truth data on agricultural water demand, traditionally gathered from local surveys, are often inadequate and do not capture the temporal signature and dynamics of irrigation patterns (Graf, 2020). Irrigated land is difﬁcult to track in underdeveloped countries due to lack of infrastructure and government poli- cies around water usage. Detecting irrigation is critical to understand water usage and promote better water management. Such data will poten- tially enable the study of climate change impact on agricul- tural water sources, monitor water usage, help detect water theft and illegal agriculture and inform policy decisions and regulations related to water compliance and management. This is a particularly hard problem to solve due to the lack of curated and labelled data available that are centered around irrigation systems. BigEarthNet-S2, for example, is a small fraction of the 26 TB of data produced daily by the European Space Agency, and required several million dollar grants to curate and label [3]. The small sample of labelled datasets currently available are from developed countries and supervised learning from these may not generalize to developing and under developed countries. In this report we investigate the problem of irriga- tion detection using self-supervised learning on high resolu- tion multi-spectral satellite images that were collected for monitoring of land, vegetation, soil and water cover. We re- search whether pre-training with contrastive self-supervised learning from uncurated satellite images of one geography, followed by ﬁne-tuning with a small fraction of publicly available labelled data from a different geography, has the generalization ability to both detect irrigated land from the ﬁrst geography and also from entirely different geographical regions. 2. Methodology We use the following machine learning pipeline to build an irrigation detection system: (1) We pre-train a deep neural network using a large amount of unlabeled data from a ge- ographic area of interest, i.e. where we would like to doSelf-supervised Contrastive Learning for Irrigation Detection irrigation detection. (2) We ﬁne-tune the network using pub- licly available labeled satellite image datasets that contain irrigation labels. (3) We apply the irrigation detection sys- tem to the geographic area of interest used for pre-training in (1.). For (1.) we use the SimCLR framework(Chen et al., 2020a;b) because it consistently outperformed previ- ous methods for self-supervised and semi-supervised learn- ing on ImageNet, without requiring specialized architec- tures. 3. Data The data for our research are Sentinel2 surface reﬂectance images collected from three sources. We use Sentinel2 archive of level2A images of the Central Valley region of California as our unlabelled source for self-supervised pre- training. Central Valley is one of the most productive agri- cultural regions in the world [ 1]. The Central Valley is home to more than 7 million acres of permanently irrigated land and houses many major cities such as Sacramento and Fresno, providing a diverse mix of irrigated and non- irrigated land for our study [2]. BigEarthNet-S2 (Sumbul et al., 2019), a large scale bench- mark archive for remote sensing image understanding from ten European countries, is used in our experiments for\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nWater usage has been a slow and expensive manual process with many imperfections and abuses. Machine learning and remote sensing developments have increased the ability to automatically monitor irrigation patterns, but existing techniques often require curated and labeled irrigation data, which are expensive and time-consuming to obtain and may not exist for impactful areas such as developing countries. In this paper, we explore an end-to-end real-world application of irrigation detection with uncurated and unlabeled satellite imagery. We apply state-of-the-art self-supervised deep learning techniques to optical remote sensing data, and find that we are able to detect irrigation with up to nine times better precision, 90% better recall, and 40% more generalization ability than traditional supervised learning methods.\n\nWater is essential for global food production and security, with agriculture being the largest consumer of freshwater globally (WWDR, 2014). While we need water to grow crops to address the growing demand for food, excessive use of water has negatively impacted ecosystems and adversely affected crop production and livelihood. Ground truth data on agricultural water demand, traditionally gathered from local surveys, are often inadequate and do not capture the temporal signature and dynamics of irrigation patterns (Graf, 2020). Irrigated land is difficult to track in underdeveloped countries due to a lack of infrastructure and government policies around water usage. Detecting irrigation is critical to understand water usage and promote better water management. Such data will potentially enable the study of climate change impact on agricultural water sources, monitor water usage, help detect water theft and illegal agriculture, and inform policy decisions and regulations related to water compliance and management.\n\nThis is a particularly hard problem to solve due to the lack of curated and labeled data available that are centered around irrigation systems. BigEarthNet-S2, for example, is a small fraction of the 26 TB of data produced daily by the European Space Agency, and required several million-dollar grants to curate and label. The small sample of labeled datasets currently available are from developed countries, and supervised learning from these may not generalize to developing and underdeveloped countries.\n\nIn this report, we investigate the problem of irrigation detection using self-supervised learning on high-resolution multi-spectral satellite images that were collected for monitoring of land, vegetation, soil, and water cover. We research whether pre-training with contrastive self-supervised learning from uncurated satellite images of one geography, followed by fine-tuning with a small fraction of publicly available labeled data from a different geography, has the generalization ability to both detect irrigated land from the first geography and also from entirely different geographical regions.\n\nWe use the following machine learning pipeline to build an irrigation detection system:\n\n1. We pre-train a deep neural network using a large amount of unlabeled data from a geographic area of interest, i.e., where we would like to do irrigation detection.\n2. We fine-tune the network using publicly available labeled satellite image datasets that contain irrigation labels.\n3. We apply the irrigation detection system to the geographic area of interest used for pre-training in (1).\n\nFor pre-training, we use the SimCLR framework (Chen et al., 2020a; b) because it consistently outperformed previous methods for self-supervised and semi-supervised learning on ImageNet, without requiring specialized architectures.\n\nThe data for our research are Sentinel2 surface reflectance images collected from three sources. We use Sentinel2 archive of level 2A images of the Central Valley region of California as our unlabeled source for self-supervised pre-training. The Central Valley is one of the most productive agricultural regions in the world (1). The Central Valley is home to more than 7 million acres of permanently irrigated land and houses many major cities such as Sacramento and Fresno, providing a diverse mix of irrigated and non-irrigated land for our study (2). BigEarthNet-S2 (Sumbul et al., 2019), a large-scale benchmark archive for remote sensing image understanding from ten European countries, is used in our experiments for"
}