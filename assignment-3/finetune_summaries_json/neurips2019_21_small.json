{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" but may not have all of the complexity of an ESM. Here we demon- strate the use of a conditional generative adversarial network (GAN) to act as an ESM emulator. In doing so, we gain the ability to produce daily weather data that is consistent with what ESM might output over any chosen scenario. In particular, the GAN is aimed at representing a joint proba- bility distribution over space, time, and climate variables, enabling the study of correlated extreme events, such as ﬂoods, droughts, or heatwaves. The use of neural networks in weather forecasting predates the deep learning boom (Hall et al., 1999; Koizumi, 1999). Shi et al. (2015) introduced convolutional LSTMs for the task of precipitation nowcasting; we plan to incorporate elements from their architecture into our design. Dueben & Bauer (2018) and Schneider et al. (2017) both present impor- tant considerations and challenges in weather and climate modeling with machine learning. Wu et al. (2019) present a strategy for incorporating constraints into GANs that are applicable to our task. Rasp et al. (2018) and Brenowitz & Bretherton (2018) both demonstrate that deep learning can be used to accurate model subgrid processes in climate tasks. Neither use GANs, but Rasp et al. (2018) expresses optimism about their potential. Both Weber et al. (2019) and Lu & Ricciuto (2019) tackle efﬁcient surrogate modeling, and ﬁnd deep learning to be effective. 1Computer Science Department, Western Washington Uni- versity, Bellingham, WA2Joint Global Change Research Insti- tute, Paciﬁc Northwest National Laboratory, College Park, MD 3Computing and Analytics Division, Paciﬁc Northwest National Laboratory, Seattle, WA4Earth and Atmospheric Sciences Depart- ment, Indiana University, Bloomington, IN. Correspondence to: Brian Hutchinson <Brian.Hutchinson@wwu.edu >. NeurIPS 2019 Workshop Tackling Climate Change with Machine Learning, Vancouver, BC, Canada, 20192. High-Resolution Climate Data Generation 2.1. The DeepClimGAN Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) have been rapidly and widely adopted for the generation of realistic images. They leverage two compet- ing architectures: the generator and the discriminator. The networks are trained jointly in a minimax fashion, ideally reaching an equilibrium in which samples from the two dis- tributions are indistinguishable and the discriminator cannot exceed 50% accuracy. GANs have had widespread success in image and video applications, making them a promising choice for generating gridded climate data. DeepClimGAN is a conditional GAN, capable of produc- ing a spatio-temporal forecast, generating samples y2 RH\u0002W\u0002T\u0002V, where the spatial dimensions are HandW, the temporal dimension is T, and there are Vreal-valued climate variables predicted at each location and time. For simplicity, we set T= 32 for a convenient “month-like” forecast period. The V= 7 climate variables we use in this work are:fmin, avg, maxgtemperature,fmin, avg, maxgrelative humidity, and precipitation; we chose these variables because those are the variables required by various impact models, including hydrology, agriculture and health (e.g. heat index). A high-resolution generator for these variables would enable new insights into climate impacts and risks faced by human systems. Each sample is conditioned on some context, c. This condi- tioning information should capture the initial state from the start of the forecast and the constraints we want our forecast to observe. Therefore, we assume that cconsists of two components: 1) “monthly” context c12RH\u0002W\u00022, contain- ing the average precipitation and temperature for the month (length Tperiod), and 2) recent context c22RH\u0002W\u0002KV, containing all Vclimate variables for the Kdays immedi- ately preceding the month, stacked. The the c1information allows us to specify the type of scenario (e.g. high or low warming) we wish to generate, while the c2information allows us to ensure continuity between months. The generator and discriminator architectures, including conditioning subarchitectures, are shown in Figures 1 and 2, respectively, and described below. Both architectures were inspired by the work of V ondrick et al. (2016) on videoDeepClimGAN: A High-Resolution Climate Data Generator Figure 1. Generator. generation with GANs. GENERATOR As shown in the bottom track of Fig. 1, the base gener- ator projects noise z2R100toR4096via two fully con- nected layers; it is then\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nWe demonstrate the use of a conditional generative adversarial network (GAN) to act as an Earth System Model (ESM) emulator. This allows us to produce daily weather data consistent with what an ESM might output over any chosen scenario. The GAN represents a joint probability distribution over space, time, and climate variables, enabling the study of correlated extreme events, such as floods, droughts, or heatwaves.\n\nThe use of neural networks in weather forecasting predates the deep learning boom. Shi et al. (2015) introduced convolutional LSTMs for precipitation nowcasting, and we plan to incorporate elements from their architecture into our design. Dueben and Bauer (2018) and Schneider et al. (2017) discuss important considerations and challenges in weather and climate modeling with machine learning. Wu et al. (2019) present a strategy for incorporating constraints into GANs applicable to our task. Rasp et al. (2018) and Brenowitz and Bretherton (2018) demonstrate the effectiveness of deep learning in modeling subgrid processes in climate tasks, although they do not use GANs. Both studies express optimism about the potential of GANs.\n\nWeber et al. (2019) and Lu and Ricciuto (2019) tackle efficient surrogate modeling and find deep learning to be effective. Our approach uses a conditional GAN, which can produce a spatio-temporal forecast, generating samples y ∈ R^H × W × T × V, where H and W are spatial dimensions, T is the temporal dimension, and V is the number of real-valued climate variables predicted at each location and time. We set T = 32 for a convenient \"month-like\" forecast period. The V = 7 climate variables we use are: minimum temperature, average temperature, maximum temperature, minimum relative humidity, average relative humidity, maximum relative humidity, and precipitation. These variables are required by various impact models, including hydrology, agriculture, and health.\n\nA high-resolution generator for these variables would enable new insights into climate impacts and risks faced by human systems. Each sample is conditioned on some context, c. This conditioning information captures the initial state from the start of the forecast and the constraints we want our forecast to observe. We assume that c consists of two components: 1) \"monthly\" context c1 ∈ R^H × W × 2, containing the average precipitation and temperature for the month (length T_period), and 2) recent context c2 ∈ R^H × W × K × V, containing all V climate variables for the K days immediately preceding the month, stacked. The c1 information allows us to specify the type of scenario (e.g., high or low warming) we wish to generate, while the c2 information ensures continuity between months.\n\nThe generator and discriminator architectures, including conditioning subarchitectures, are shown in Figures 1 and 2, respectively, and described below. Both architectures were inspired by the work of Vondrick et al. (2016) on video generation with GANs.\n\nDeepClimGAN is a conditional GAN, capable of producing a spatio-temporal forecast, generating samples y ∈ R^H × W × T × V, where the spatial dimensions are H and W, the temporal dimension is T, and there are V real-valued climate variables predicted at each location and time. For simplicity, we set T = 32 for a convenient \"month-like\" forecast period. The V = 7 climate variables we use are: minimum temperature, average temperature, maximum temperature, minimum relative humidity, average relative humidity, maximum relative humidity, and precipitation. We chose these variables because they are required by various impact models, including hydrology, agriculture, and health.\n\nEach sample is conditioned on some context, c. This conditioning information captures the initial state from the start of the forecast and the constraints we want our forecast to observe. We assume that c consists of two components: 1) \"monthly\" context c1 ∈ R^H × W × 2, containing the average precipitation and temperature for the month (length T_period), and 2) recent context c2 ∈ R^H × W × K × V, containing all V climate variables for the K days immediately preceding the month, stacked. The c1 information allows us to specify the type of scenario (e.g., high or low warming) we wish to generate, while the c2 information ensures continuity between months.\n\nThe generator and discriminator architectures, including conditioning subarchitectures, are shown in Figures 1 and 2, respectively, and described below. Both architectures were inspired by the work of Vondrick et al. (2016) on video generation with GANs.\n\nGENERATOR\nThe generator projects noise z ∈ R^100 to R^409"
}