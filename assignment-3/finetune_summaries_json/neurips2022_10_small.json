{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" Allen Institute for AI Seattle, WA 98103 jeremym@allenai.org Christopher Bretherton Climate Modeling Allen Institute for AI Seattle, WA 98103 spencerc@allenai.org Abstract While previous works have shown that machine learning (ML) can improve the prediction accuracy of coarse-grid climate models, these ML-augmented methods are more vulnerable to irregular inputs than the traditional physics-based models they rely on. Because ML-predicted corrections feed back into the climate model’s base physics, the ML-corrected model regularly produces out of sample data, which can cause model instability and frequent crashes. This work shows that adding semi-supervised novelty detection to identify out-of-sample data and disable the ML-correction accordingly stabilizes simulations and sharply improves the quality of predictions. We design an augmented climate model with a one-class support vector machine (OCSVM) novelty detector that provides better temperature and precipitation forecasts in a year-long simulation than either a baseline (no-ML) or a standard ML-corrected run. By improving the accuracy of coarse-grid climate models, this work helps make accurate climate models accessible to researchers without massive computational resources. 1 Introduction Accurate climate models are essential for diagnosing the general trends of climate change and predicting its localized impacts. Given finite resources, having computationally efficient models is also important to assess climate policies by making simulations cheap and easy. Previous works [ 1–5] have suggested that augmenting physics-based climate models with machine learning can reduce bias and improve the overall skill of coarse climate models, while sometimes introducing instability. This work draws on the idea of using a compound parameterization [ 6,7] to mask ML models with high uncertainty and builds on those ML-corrected models by incorporating out-of-sample detection. Our \"Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.\"approach adds stability and outperforms these past approaches (specifically, [ 3,8]) on temperature and precipitation metrics. We model the atmosphere as a system of partial differential equations (PDEs). The atmospheric state is modeled as X= (x1,..., x N)∈Rd×N, a three-dimensional grid of Nlatitude/longitude coordinates with d-dimensional column vectors of air temperature, specific humidity, and other fields. The state of a particular column xi∈Rdevolves over time as dxi dt=fi(X, t) (1) for some fixed fiderived from physically-based assumptions; we refer to this as the baseline model. The size of Ncorresponds to the grid resolution; large Nyields more accurate but computationally expensive simulations. While accuracy penalties due to a loss of resolution are expected for small N, coarse-grid simulations are additionally biased by poor representations of subgrid-scale processes like thunderstorms and cloud radiative effects [ 9,10]. ML is an appealing way to de-bias this coarse climate model by predicting and compensating for its error. Put precisely, the ML-corrected model is dxi dt=fi(X, t) +g(xi, qi;θ), (2) where g(·;θ) :Rd+3→Rdis a learned function with parameters θthat predicts corrective tendencies from the column, xi∈Rd, and its insolation, surface elevation, and latitude qi∈R3. The ML correction enables the baseline to better approximate a reference fine-grid model while maintaining the underlying physics as the core of the modeling approach [2, 3]. While ML-based models frequently improve overall error, these models—especially deep neural networks—are often not robust, meaning they perform poorly with out-of-sample data that lies outside the training distribution. In online application (where predictions are fed back into the model repeatedly for a simulation) of these models, ML model errors accumulate in time and overwhelm the damping mechanisms of the baseline physics [ 11]. In past works [ 8], letting xirepresent a vertical column of air temperature and specific humidity values resulted in an accurate and stable model, but including horizontal winds in xicaused the model to crash or be more inaccurate for certain fields within a few simulated weeks. Other works [ 12] have stabilized ML-corrected climate models by tapering upper-atmospheric outputs to zero and removing upper-atmospheric inputs when learning g, but this approach has not been applied to models with wind tendencies. This poses a dilemma: By omitting the wind tendencies from g, the model is unable to incorporate relevant climate information into its predictions. Yet including the wind tendencies introduces new instabilities. We fix this by employing semi-supervised novelty detection to predict when a column xibelongs to the training distribution of gand suppress the tendencies of the ML model if not. Our model has the form dxi dt=fi(X, t) +η(xi;ρ)g(xi, qi;θ), (3) for a novelty detector η(·;ρ) :Rd→[0,1]. A properly tuned\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThe Allen Institute for AI, located in Seattle, Washington, has developed a climate modeling approach that combines machine learning (ML) with traditional physics-based models to improve prediction accuracy. However, previous studies have shown that ML-augmented methods are more susceptible to irregular inputs than their traditional counterparts. This is because ML-predicted corrections can feed back into the climate model's base physics, leading to model instability and frequent crashes.\n\nThis work proposes a solution by incorporating semi-supervised novelty detection to identify out-of-sample data and disable the ML correction accordingly. The approach stabilizes simulations and significantly improves the quality of predictions. An augmented climate model with a one-class support vector machine (OCSVM) novelty detector is designed to provide better temperature and precipitation forecasts in a year-long simulation than a baseline (no-ML) or a standard ML-corrected run.\n\nThe goal of this work is to make accurate climate models accessible to researchers without requiring massive computational resources. Accurate climate models are essential for understanding climate change and predicting its localized impacts. However, traditional climate models can be computationally expensive, making it challenging to assess climate policies.\n\nPrevious studies have suggested that augmenting physics-based climate models with machine learning can reduce bias and improve the overall skill of coarse climate models. However, this approach can introduce instability. This work builds on the idea of using a compound parameterization to mask ML models with high uncertainty and incorporates out-of-sample detection to improve stability.\n\nThe atmosphere is modeled as a system of partial differential equations (PDEs), with the atmospheric state represented as a three-dimensional grid of N latitude/longitude coordinates with d-dimensional column vectors of air temperature, specific humidity, and other fields. The state of a particular column evolves over time according to a fixed function f derived from physically-based assumptions.\n\nThe size of N corresponds to the grid resolution, with larger N yielding more accurate but computationally expensive simulations. Coarse-grid simulations are biased by poor representations of subgrid-scale processes like thunderstorms and cloud radiative effects. Machine learning is used to de-bias this coarse climate model by predicting and compensating for its error.\n\nThe ML-corrected model is represented as dxi/dt = fi(X, t) + g(xi, qi; θ), where g(·; θ) is a learned function that predicts corrective tendencies from the column, xi, and its insolation, surface elevation, and latitude, qi. The ML correction enables the baseline to better approximate a reference fine-grid model while maintaining the underlying physics as the core of the modeling approach.\n\nHowever, ML-based models can be robust, performing poorly with out-of-sample data that lies outside the training distribution. In online applications, ML model errors can accumulate in time and overwhelm the damping mechanisms of the baseline physics. Previous works have stabilized ML-corrected climate models by tapering upper-atmospheric outputs to zero and removing upper-atmospheric inputs when learning g, but this approach has not been applied to models with wind tendencies.\n\nThis work addresses this issue by employing semi-supervised novelty detection to predict when a column belongs to the training distribution of g and suppress the tendencies of the ML model if not. The model has the form dxi/dt = fi(X, t) + η(xi; ρ)g(xi, qi; θ), where η(·; ρ) is a novelty detector that outputs a value between 0 and 1."
}