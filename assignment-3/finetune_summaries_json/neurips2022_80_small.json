{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" maturation to decay. This paper proposes a novel transformer-based model for precipitation nowcasting that can extract global and local dynamics within meteorological characteristics. The experimental results show our model achieves state-of-the-art performances on the precipitation nowcasting benchmark. 1 Introduction Climate change has induced heavy downpours in many parts of the globe, causing significant damage to society [ 1,2,3,4,5,6]. Therefore, predicting short-term precipitation changes in advance is becoming important and has received increasing interest from researchers [7,8,9,10]. Precipitationnowcastingpredictsprecipitationchangeswithin6hours, predicting and responding to rapid changes in real time [2, 6, 11, 12]. Deep learning-based precipitation nowcasting tasks are defined to predict future precipitation conditions using satellite videos or radar measurements. Many previous models leverage the architecture of video prediction, a similar task to nowcasting, focusing on exploiting spatial and temporal information by applying convolutional layers and transformer blocks [5,9,10,11,13,14]. However, precipitation data have unique characteristics that differ from common video prediction benchmarks. The general video has a moving specific rigid body with a stationary background [ 15,16,17], whereas the precipitation video features a fluid mass spreading in a particular direction. Furthermore, each area of the fluid has an individual life cycle from initiation to maturation to decay; that is, the intensity of the moving fluid changes continuously [ 18]. Therefore, a precipitation nowcasting model reflecting meteorological patterns is required. In this paper, we propose a novel transformer-based model for precipitation nowcasting, which can extract global and local dynamics within meteorological characteristics. The global dynamic attention module can extract global spatial features from the frames so that the model can predict long-term future frames with high accuracy, while locally extracted temporal relationships from the local dynamic attention module help the model learn how the intensity of fluids changes at each point in the frames. Our proposed model shows the Tackling Climate Change with Machine Learning: workshop at NeurIPS 2021.Input Past framesPredicted Future frames NowformerBlock xDecoderEncoderNowformerBlockNowformerResidual Connection√ó\tùëÅ(b) NowformerBlock(a) FClayer Average Pooling Average Pooling Average Pooling(c) TAUlocal(d) gridP(e) ldPInputEmb.Global DynamicAttenLocal DynamicAttenNormMLP NormFigure 1: (a) Overall framework of Nowformer. (b) Nowformer block. (c-e) The variants of the local dynamic strategies, which are named TAUlocal, gridP, and ldP. best performance compared with other state-of-the-art video prediction and precipitation nowcasting models in the SEVIR precipitation nowcasting benchmark [2]. 2 Methodology 2.1 Overall Pipeline We formulate precipitation nowcasting as a spatiotemporal predictive learning problem. Given past Tframes of precipitation, the model predicts the future T0frames. As shown in Fig. 1 (a), the overall structure of the nowformer contains an encoder, nowformer blocks, and a decoder. The encoder and decoder comprise convolutional blocks that extract features and map features to predictions. The nowformer block captures spatiotemporal patterns from frame features, as detailed in Section 2.2. After the nowformer block, an additional residual connection from the encoder to the decoder layer is applied to directly use the past frame information. We train the nowformer using the mean squared error (MSE) loss between the predicted precipitation frames and its target. 2.2 Nowformer Block Each nowformer block has two subblocks of spatiotemporal attention and multi-layer per- ceptron (MLP) [ 19,20]. As shown in Fig. 1, the nowformer block module is formulated as follows: Zl=MLP(BN(Z0 l)) +Z0 l; Z0 l=Attention (BN(Zl\u00001)) +Zl\u00001; (1) where, given the previous block features Zl\u00001as an input of the l\u0000thblock, Z0 landZlare the outputs of the Attention module and MLPmodule, respectively. Through the attention module, the model can capture the fluid‚Äôs average flow direction and variations in intensity based on the fluid‚Äôs life cycle in each area. Batch normalization (BN) is used before each subblock, and a residual connection is used after each subblock. Attention. To capture the spatiotemporal pattern of precipitation features, we build the attention block with two core designs: (1) global dynamic attention ( GlobalDynamicAttn and (2) local dynamic attention ( LocalDynamicAttn ), which is Attention = (GlobalDynamicAttn  LocalDynamicAttn ) F; (2) where F2RC\u0002H\u0002Wis an input feature and GlobalDynamicAttn ;LocalDynamicAttn 2 RC\u0002H\u0002Wdenote an attention map, respectively. The score on the attention\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and data removed:\n\nMaturation to decay. This paper proposes a novel transformer-based model for precipitation nowcasting that can extract global and local dynamics within meteorological characteristics. The experimental results show our model achieves state-of-the-art performance on the precipitation nowcasting benchmark.\n\nIntroduction\nClimate change has induced heavy downpours in many parts of the globe, causing significant damage to society. Therefore, predicting short-term precipitation changes in advance is becoming increasingly important and has received growing interest from researchers. Precipitation nowcasting predicts precipitation changes within six hours, predicting and responding to rapid changes in real-time.\n\nDeep learning-based precipitation nowcasting tasks are defined to predict future precipitation conditions using satellite videos or radar measurements. Many previous models leverage the architecture of video prediction, a similar task to nowcasting, focusing on exploiting spatial and temporal information by applying convolutional layers and transformer blocks. However, precipitation data have unique characteristics that differ from common video prediction benchmarks. The general video has a moving specific rigid body with a stationary background, whereas the precipitation video features a fluid mass spreading in a particular direction. Furthermore, each area of the fluid has an individual life cycle from initiation to maturation to decay; that is, the intensity of the moving fluid changes continuously. Therefore, a precipitation nowcasting model reflecting meteorological patterns is required.\n\nIn this paper, we propose a novel transformer-based model for precipitation nowcasting, which can extract global and local dynamics within meteorological characteristics. The global dynamic attention module can extract global spatial features from the frames so that the model can predict long-term future frames with high accuracy, while locally extracted temporal relationships from the local dynamic attention module help the model learn how the intensity of fluids changes at each point in the frames.\n\nOur proposed model shows the best performance compared with other state-of-the-art video prediction and precipitation nowcasting models in the SEVIR precipitation nowcasting benchmark.\n\nMethodology\n2.1 Overall Pipeline\nWe formulate precipitation nowcasting as a spatiotemporal predictive learning problem. Given past T frames of precipitation, the model predicts the future T0 frames. The overall structure of the nowformer contains an encoder, nowformer blocks, and a decoder. The encoder and decoder comprise convolutional blocks that extract features and map features to predictions. The nowformer block captures spatiotemporal patterns from frame features, as detailed in Section 2.2.\n\n2.2 Nowformer Block\nEach nowformer block has two subblocks of spatiotemporal attention and multi-layer perceptron (MLP). The nowformer block module is formulated as follows:\n\nZl = MLP(BN(Z0l)) + Z0l\nZ0l = Attention(BN(Zl-1)) + Zl-1\n\nwhere Zl-1 is the previous block features, Z0l and Zl are the outputs of the Attention module and MLP module, respectively. Through the attention module, the model can capture the fluid's average flow direction and variations in intensity based on the fluid's life cycle in each area. Batch normalization (BN) is used before each subblock, and a residual connection is used after each subblock.\n\nAttention\nTo capture the spatiotemporal pattern of precipitation features, we build the attention block with two core designs: (1) global dynamic attention and (2) local dynamic attention, which is Attention = (GlobalDynamicAttn + LocalDynamicAttn) * F, where F is an input feature and GlobalDynamicAttn and LocalDynamicAttn are attention maps, respectively. The score on the attention map is calculated as the dot product of the query and key vectors."
}