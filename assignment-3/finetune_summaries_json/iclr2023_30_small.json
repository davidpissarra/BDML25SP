{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" to quickly locate and mitigate potential faulty solar panels. However, this task is extremely tedious and is not scalable for the ever increasing capacity of so- lar power across the globe. Therefore, we propose an end-to-end deep learning framework for detecting individual solar panels using a rotated object detection architecture. We evaluate our approach on a diverse dataset of solar power plants collected from across the United States and report a mAP score of 83.3%. Figure 1: Oriented Panel Detection Architecture. 1 I NTRODUCTION The adoption of renewable energy resources is paramount to fighting the climate change crisis. Over the last decade renewable energy production has nearly quadrupled, 26% of which is contributed by solar energy (Rapier, 2020). To ensure that solar power plants are operating at maximum capacity, inspections utilizing remotely sensed imagery are important in identifying anomalies in damaged panels. However, with this rapid increase in solar production, it has become increasingly difficult to scale these inspections efficiently. The initial step in many inspection pipelines is to localize and georeference individual panels for downstream evaluation tasks. This can be prohibitively time- consuming for commercial sites, any of which can easily contain tens of thousands of solar panels. Therefore, this requires an automated approach for detecting and georeferencing individual solar 1Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2023 panels from large scale aerial imagery. To be specific, we wish to create a model that directly predicts the coordinates of the vertices of each solar panel. We also require the approach to generalize to images of solar arrays in any orientation across a wide variety of landscapes and environments. In this paper we introduce a rotated object detection framework for localizing individual solar panels with arbitrary orientation. We preprocess large-scale orthomosaics into patches which are then pro- cessed in batches. The predictions are stitched back together and projected from pixel coordinates to geospatial coordinates, creating an accurate mapping of individual panels in each site. To the best of our knowledge this is the first study to model solar panel detection as a rotated object detection problem which allows us to efficiently map individual solar panels in an end-to-end fashion. 2 R ELATED WORK Most recent works build algorithms for mapping solar panels from aerial or satellite imagery (Yu et al., 2018; Camilo et al., 2017; Mujtaba & Wani, 2021; Golovko et al., 2021) with the goal of estimating surface area as a proxy for energy capacity, location density, and other potential insights. These studies have focused on both small-scale residential solar sites (Zhuang et al., 2020; Khomi- akov et al., 2022) as well as large-scale commercial sites (Yu et al., 2018). Most approaches use a two-stage architecture for mapping solar panels from aerial imagery (Hou et al., 2020; Parhar et al., 2021). The first stage consists of a convolutional neural network (CNN) classifier for predicting the probability of the given image containing solar panels or not. The second stage uses a segmentation model for segmenting out solar panels, contingent upon the first stage predicting the given image to contain solar panels. While these methods have shown promise in mapping the surface area of solar arrays across a diverse set of geographies, it remains nontrivial to extract the coordinates of individual solar panel vertices at scale. 3 M ETHODOLOGY In this section, we describe the proposed framework’s architecture and the modeling of detection targets for solar panels. 3.1 R OTATED BOUNDING BOXES Our key desideratum is to accurately localize individual solar panels, regardless of the orientation of the panels in the image, and to use this localization to extract the coordinates of the vertices of each panel. Accordingly, we model the problem as an arbitrarily oriented object detection task where the ground truth annotations of the solar panels are represented as rotated bounding boxes. Each box is comprised of the 5-dimensional tuple (x, y, w, h, θ )where (x, y)is the centroid pixel coordinate of the box, wis the width defined as the shorter side of the box, his the height defined as the longer side of the box, and θis the rotation angle in degrees required to obtain the rotated box. This bounding box formulation provides a compact representation which allows us to easily convert to the complete set of vertex coordinates (x1, y1, x2, y2, x3, y3, x4, y4)using equation 1 in Appendix B. 3.2 R OTATED ANCHORS Following R-CNN style object detection architectures, we define a set of proposal anchors as a strong basis for regression to ground truth rotated bounding boxes. In addition to scale and aspect ratio, we also provide rotation angle anchors. We specify seven different rotation anchors: −90◦, −60◦,−30◦,0◦,30◦,60�\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nThe task of quickly locating and mitigating potential faulty solar panels is extremely tedious and not scalable for the ever-increasing capacity of solar power globally. We propose an end-to-end deep learning framework for detecting individual solar panels using a rotated object detection architecture. Our approach is evaluated on a diverse dataset of solar power plants collected from across the United States, achieving a mean Average Precision (mAP) score of 83.3%. \n\nThe adoption of renewable energy resources is crucial in fighting the climate change crisis. Over the last decade, renewable energy production has nearly quadrupled, with 26% contributed by solar energy (Rapier, 2020). To ensure that solar power plants operate at maximum capacity, inspections using remotely sensed imagery are essential in identifying anomalies in damaged panels. However, with the rapid increase in solar production, it has become increasingly difficult to scale these inspections efficiently.\n\nThe initial step in many inspection pipelines is to localize and georeference individual panels for downstream evaluation tasks. This can be time-consuming for commercial sites, which can contain tens of thousands of solar panels. Therefore, an automated approach is required for detecting and georeferencing individual solar panels from large-scale aerial imagery. We aim to create a model that directly predicts the coordinates of the vertices of each solar panel, generalizing to images of solar arrays in any orientation across various landscapes and environments.\n\nIn this paper, we introduce a rotated object detection framework for localizing individual solar panels with arbitrary orientation. We preprocess large-scale orthomosaics into patches, which are then processed in batches. The predictions are stitched back together and projected from pixel coordinates to geospatial coordinates, creating an accurate mapping of individual panels in each site. To the best of our knowledge, this is the first study to model solar panel detection as a rotated object detection problem, allowing for efficient mapping of individual solar panels in an end-to-end fashion.\n\nMost recent works have focused on mapping solar panels from aerial or satellite imagery (Yu et al., 2018; Camilo et al., 2017; Mujtaba & Wani, 2021; Golovko et al., 2021) with the goal of estimating surface area as a proxy for energy capacity, location density, and other potential insights. These studies have focused on both small-scale residential solar sites (Zhuang et al., 2020; Khomikov et al., 2022) and large-scale commercial sites (Yu et al., 2018). Most approaches use a two-stage architecture for mapping solar panels from aerial imagery (Hou et al., 2020; Parhar et al., 2021). The first stage consists of a convolutional neural network (CNN) classifier for predicting the probability of the given image containing solar panels or not. The second stage uses a segmentation model for segmenting out solar panels, contingent upon the first stage predicting the given image to contain solar panels.\n\nWhile these methods have shown promise in mapping the surface area of solar arrays across a diverse set of geographies, it remains nontrivial to extract the coordinates of individual solar panel vertices at scale.\n\nIn this section, we describe the proposed framework's architecture and the modeling of detection targets for solar panels.\n\n3.1 Rotated Bounding Boxes\n\nOur key objective is to accurately localize individual solar panels, regardless of the orientation of the panels in the image, and to use this localization to extract the coordinates of the vertices of each panel. We model the problem as an arbitrarily oriented object detection task where the ground truth annotations of the solar panels are represented as rotated bounding boxes. Each box is comprised of a 5-dimensional tuple (x, y, w, h, θ) where (x, y) is the centroid pixel coordinate of the box, w is the width defined as the shorter side of the box, h is the height defined as the longer side of the box, and θ is the rotation angle in degrees required to obtain the rotated box.\n\n3.2 Rotated Anchors\n\nFollowing R-CNN style object detection architectures, we define a set of proposal anchors as a strong basis for regression to ground truth rotated bounding boxes. In addition to scale and aspect ratio, we also provide rotation angle anchors. We specify seven different rotation anchors: -90°, -60°, -30°, 0°, 30°, 60°."
}