{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" quantification. Deep learning-based surrogate models offer the possibility to solve PDEs many orders of magnitudes faster than conventional simulators, but they are difficult to scale to industrial-scale problem settings. Using model-parallel deep learning, we train the largest CO 2surrogate model to date on a 3D simulation grid with two million grid points. To train the 3D simulator, we generate a new training dataset based on a real-world CCS simulation benchmark. Once trained, each simulation with the network is five orders of magnitude faster than a numerical reservoir simulator and 4,500 times cheaper. This paves the way to applications that require thousands of (sequential) simulations, such as optimizing the location of CO 2injection wells to maximize storage capacity and minimize risk of leakage. 1 Introduction Numerical reservoir simulations play a critical role in Carbon Capture and Storage (CCS) and are used to answer important key questions throughout the lifetime of a CCS project [1]: • Planning: Where are potential CO 2storage sites? • Operation: How much CO 2can safely be injected and stored in a given location? •Monitoring: How does the CO 2behave after injection and does it remain in the storage site? Conventionally, numerical reservoir simulators such as GEOSX [ 2], Open Porous Media (OPM) [ 3] or Eclipse [ 4] are used for modeling subsurface CO 2flow and for answering the above questions. Most reservoir simulators use the finite volume (FV) or finite element (FEM) method for solving the underlying multi-phase flow equations in porous media. Running numerical simulations for a production-scale storage site is computationally expensive, as it involves solving large-scale linear systems with iterative methods and it thus requires techniques from high-performance computing (HPC) for running simulators on distributed memory architectures. Simulations typically take multiple hours to run at the relevant scales, which is prohibitive for downstream applications that require thousands of simulations in sequence, such as inverse problems or uncertainty quantification (UQ). Due to the high computational cost of conventional reservoir simulations, data-driven approaches based on deep learning ( Scientific AI/ML ) are increasingly being adopted for numerical CO 2modeling [5–9]. The promise of deep-learning based reservoir simulations are speedups of multiple orders of magnitudes over conventional simulators, as well as the ability to compute sensitivities and Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.Figure 1: Parallel FNO block based on tensor/domain decomposition. The hidden states of the network are distributed across four GPUs (represented by different colors) along one of the spatial data dimensions. Each FNO block consists of a (distributed) forward FFT, multiplication with the complex network weights and and inverse FFT. gradients with automatic differentiation (AD) - a feature that is currently not supported by most reservoir simulation packages [ 10]. However, one of the major road blocks in applying deep learning to industry-scale CO 2projects is the size of the input and output data. Reservoir simulations in commercial settings involve geological models with millions (or billions) of grid points that describe physical properties of the subsurface (e.g., porosity, permeability) and they predict CO 2saturation and/or pressure as a function of both space and time. Existing deep neural networks for CO 2flow are either two-dimensional [ 7] or small-scale three-dimensional simulators [ 6,5,8] that operate on significantly smaller mesh sizes than required for commercial settings [2]. Existing deep learning-based simulators are not able to scale to industry-scale problem sizes, as they are implemented with data parallelism and are thus limited to network and data sizes that are supported by the available memory of a single GPU (i.e., up to 80 GB on the Nvidia A100). In data parallelism, samples of a (mini-)batch are distributed across multiple GPUs, but each GPU must at least fit a single data sample (including its hidden states) and the corresponding network weights into memory [ 11]. In this paper, we overcome the memory limitations of a single GPU through model-parallel deep learning [11], in which we distributed both the data (input-, output- and hidden states), as well as the network weights across multiple GPUs. Using a model-parallel version of the Fourier Neural Operator architecture [ 12,13], we train the largest AI-driven simulator to date for simulating multi-phase CO 2flow on a 3D simulation grid with two million grid points and we create a new training dataset based on the Sleipner CO 2model, a real-world reservoir simulation benchmark from the world’s first off-shore commercial CCS project [14]. 2 Model-parallel Fourier Neural Operators We base our network architecture for simulating 3D CO 2flow on Fourier Neural Operators (FNOs) [12], which have shown very promising performance on a variety of challenging PDEs, including the Navier-St\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nQuantification of complex systems can be accelerated using deep learning-based surrogate models, which can solve partial differential equations (PDEs) many orders of magnitude faster than conventional simulators. However, these models are challenging to scale to industrial-scale problem settings. To address this limitation, we employed model-parallel deep learning to train the largest CO2 surrogate model to date on a 3D simulation grid with two million grid points. The training dataset was generated based on a real-world carbon capture and storage (CCS) simulation benchmark.\n\nOur trained model enables simulations to be performed five orders of magnitude faster than numerical reservoir simulators and at a cost 4,500 times lower. This breakthrough paves the way for applications that require thousands of simulations, such as optimizing the location of CO2 injection wells to maximize storage capacity and minimize the risk of leakage.\n\nNumerical reservoir simulations play a critical role in CCS and are used to answer key questions throughout the project lifecycle:\n\n* Planning: Where are potential CO2 storage sites?\n* Operation: How much CO2 can safely be injected and stored in a given location?\n* Monitoring: How does CO2 behave after injection and does it remain in the storage site?\n\nConventionally, numerical reservoir simulators such as GEOSX, Open Porous Media (OPM), or Eclipse are used for modeling subsurface CO2 flow and answering these questions. Most reservoir simulators use the finite volume (FV) or finite element (FEM) method for solving the underlying multi-phase flow equations in porous media. Running numerical simulations for a production-scale storage site is computationally expensive, requiring high-performance computing (HPC) techniques for distributed memory architectures.\n\nSimulations typically take multiple hours to run at relevant scales, which is prohibitive for downstream applications that require thousands of simulations in sequence, such as inverse problems or uncertainty quantification (UQ). To address this challenge, data-driven approaches based on deep learning are increasingly being adopted for numerical CO2 modeling.\n\nDeep learning-based reservoir simulations offer speedups of multiple orders of magnitude over conventional simulators, as well as the ability to compute sensitivities and gradients with automatic differentiation (AD). However, one of the major roadblocks in applying deep learning to industry-scale CO2 projects is the size of the input and output data. Reservoir simulations in commercial settings involve geological models with millions of grid points that describe physical properties of the subsurface and predict CO2 saturation and/or pressure as a function of space and time.\n\nExisting deep neural networks for CO2 flow are either two-dimensional or small-scale three-dimensional simulators that operate on significantly smaller mesh sizes than required for commercial settings. To overcome this limitation, we employed model-parallel deep learning, which distributes both the data and network weights across multiple GPUs. Using a model-parallel version of the Fourier Neural Operator architecture, we trained the largest AI-driven simulator to date for simulating multi-phase CO2 flow on a 3D simulation grid with two million grid points.\n\nOur training dataset was based on the Sleipner CO2 model, a real-world reservoir simulation benchmark from the world's first off-shore commercial CCS project."
}