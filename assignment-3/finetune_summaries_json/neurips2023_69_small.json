{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\". Although multi-agent reinforcement learning (MARL) methods have been applied to distributed MG voltage control, they suffer from bad scalability and are found difficult to control the MG with a large number of DGs due to the well-known curse of dimensionality. To address this, we propose a scalable network-aware reinforcement learning framework which exploits network structure to truncate the critic’s Q-function to achieve scalability. Our experiments show effective control of a MG with up to 84 DGs, surpassing the existing maximum of 40 agents in the existing literature. We also compare our framework with state-of- the-art MARL algorithms to show the superior scalability of our framework. 1 Introduction Renewable energy plays a vital role in mitigating climate change by reducing greenhouse gas emissions and promoting energy resilience and efficiency Osman et al. (2023). The rising utilization of renewable energy has catalyzed the transformation of power grids, leading to an increasing number of distributed generations (DGs). To accommodate DGs such as photo-voltaic, fuel-cells and wind turbines, Microgrids (MGs) have emerged as a promising solution Lasseter, Paigi (2004) where DGs can be connected to MGs through power electronics converters and the renewable energy is flexibly distributed to the local loads and main grids Pogaku et al. (2007); Banerji et al. (2013). In this way, MGs can facilitate DGs and high penetration of renewable energy. However, the MG voltage control during islanded operation presents unique challenges. To maintain voltage of the MG at predefined nominal values, secondary control methods are necessary Olivares et al. (2014); Rajesh et al. (2017); Khayat et al. (2020). To handle the large number of DGs in MG, distributed secondary control methods are needed to make control only based on local and neighbor information Bidram et al. (2013); Lu et al. (2018). However, the nonlinear dynamics of MGs and the uncertainty associated with loads and renewable energies make the design of model-based distributed control methods challenging, thereby negatively impacting the control performance. Having achieved great success in complex control tasks like game playing Mnih et al. (2013); Nguyen, La (2019), robot manipulation Kober et al. (2013), reinforcement learning (RL), a model- free approach, has been recognized to have great potential for distributed secondary control Chen et al. (2022b,a); Hossain et al. (2022); Yang et al. (2022); Wang et al. (2023). More specifically, for control tasks involving multiple DGs as in our setting, multi-agent RL (MARL) is needed. However, Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.Figure 1: Basic components in micorgrid. the dominant paradigm in MARL is Centralized Training and Distributed Execution (CTDE). In this framework, the Q-function of the critics needs to take the global observations and actions to estimate expected rewards and train individual actors. The size of the observation and action spaces exponentially increase with the number of agents rendering the lack of scalability of this framework Canese et al. (2021); Qu et al. (2021). Therefore, when the number of DGs (e.g., agents) is large, it becomes difficult to effectively train the critics whose input size increases exponentially with the number of agents and the eventual training performance is not ideal. For this reason, the number of agents in existing literature on inverter control can only reach 40 Chen et al. (2022a). Contribution. We aim to address this scalability issue and propose a novel scalable network-aware framework. The highlight of our model is that it leverages network structure to truncate the critic’s Q-function, and decomposes the global reward to achieve scalability. Our framework is theoretically grounded, as we show exponential decay property of the Q-function in MG voltage control problem. Further, experiments confirm that our framework can effectively control an MG containing up to 84 DGs. To our knowledge, this number surpasses the current maximum number of agents—40 reported in existing literature Chen et al. (2022a). This indicates the potential of our method to efficiently control MGs that contain numerous DGs. Apart from voltage control problem, our framework can also be applied to solve distributed frequency and energy management problems Chen et al. (2022c) to ensure the safe and efficient operation of MGs with high penetration of renewable energy. We envision our approach to serve as a critical technical tool to enable greater integration of renewable energy, which is vital for tackling climate change. 2 Problem Formulation and Methodology 2.1 Problem Formulation In MGs, there are three basic components: loads, DGs, and transmission lines. Loads and DGs are connected via transmission lines, as depicted in Figure 1 (a). Loads typically have stochastic variations. Nondispatchable DGs that generate power\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed and the content preserved:\n\nMulti-agent reinforcement learning (MARL) methods have been applied to distributed microgrid (MG) voltage control, but they suffer from poor scalability and struggle to control MGs with a large number of distributed generators (DGs) due to the curse of dimensionality. To address this issue, we propose a scalable network-aware reinforcement learning framework that exploits the network structure to truncate the critic's Q-function, achieving scalability. Our experiments demonstrate effective control of an MG with up to 84 DGs, surpassing the existing maximum of 40 agents in the literature.\n\nRenewable energy plays a vital role in mitigating climate change by reducing greenhouse gas emissions and promoting energy resilience and efficiency. The increasing adoption of renewable energy has led to the emergence of microgrids (MGs) as a promising solution, where DGs can be connected to MGs through power electronics converters and renewable energy can be flexibly distributed to local loads and the main grid. However, MG voltage control during islanded operation presents unique challenges. To maintain the MG voltage at predefined nominal values, secondary control methods are necessary. Distributed secondary control methods are required to handle the large number of DGs in MGs, making control decisions based on local and neighbor information.\n\nThe nonlinear dynamics of MGs and the uncertainty associated with loads and renewable energies make the design of model-based distributed control methods challenging, negatively impacting control performance. Reinforcement learning (RL), a model-free approach, has been recognized for its potential in distributed secondary control. For control tasks involving multiple DGs, multi-agent RL (MARL) is necessary. The dominant paradigm in MARL is Centralized Training and Distributed Execution (CTDE), where the Q-function of the critics needs to take global observations and actions to estimate expected rewards and train individual actors. However, the size of the observation and action spaces increases exponentially with the number of agents, rendering the lack of scalability of this framework.\n\nTo address the scalability issue, we propose a novel scalable network-aware framework that leverages network structure to truncate the critic's Q-function and decomposes the global reward. Our framework is theoretically grounded, with an exponential decay property of the Q-function in the MG voltage control problem. Experiments confirm that our framework can effectively control an MG containing up to 84 DGs, surpassing the current maximum number of agents reported in the literature. This indicates the potential of our method to efficiently control MGs with numerous DGs. Our framework can also be applied to solve distributed frequency and energy management problems to ensure the safe and efficient operation of MGs with high penetration of renewable energy.\n\nWe envision our approach as a critical technical tool to enable greater integration of renewable energy, which is vital for tackling climate change."
}