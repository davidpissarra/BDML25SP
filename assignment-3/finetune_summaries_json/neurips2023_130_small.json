{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"alanobis distance-based confidence scores to automatically detect new moth species in a region. We intend to make out-of-distribution detection interpretable by identifying morphological characteris- tics of different species using Grad-CAM. We hope this algorithm will be a useful tool for entomologists to study range shifts and inform climate change adaptation. 1 Introduction Climate change results in increased temperature, more extreme weather events, and changes in precipitation, affecting insect biodiversity [ 1] and causing insect range shifts in many regions [ 2]. Understanding how insect distribution and biodiversity change is crucial for habitat conservation and pest management in a changing climate. With more than 160,000 species worldwide [ 3], moths play critical roles in different ecosystems as pollinators, prey, agricultural pests, and indicator species of habitat disturbance. Due to climate change, some regions have observed a decline in moth population that may threaten the local ecosystem [ 4], while others have observed distribution shifts or increased populations of moths that lead to more challenges of pest management [5]. Machine learning-based methods including object detection and image classification have been applied for automated camera-assisted insect monitoring, providing valuable large-scale data for quantifying moth abundance and biodiversity [ 6]. To leverage the camera trap images, we propose to use out-of-distribution detection to automatically detect new species1to study moth range shifts. We propose to use Mahalanobis distance-based confidence scores [ 7] to differentiate in-distribution (ID) and out-of-distribution (OOD) species and interpret the result with Grad-CAM [ 8], which can provide concept-specific visualization for fine-grained classification. 2 Related work 2.1 Insect monitoring Automated insect monitoring with machine learning has emerged as a promising area. In agricul- ture, computer vision has been used to automatically identify insect species with trap images to 1We use “new species” to refer to any species that has not been documented in a specific region. These can be species that are new to science or well-known species that have only recently colonized the region. Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.facilitate pest management [ 9,10]. Meanwhile, an increasing number of studies have also started to focus on monitoring insect biodiversity with machine learning [ 6,11,12]. Bjerge et al. suggest a non-lethal method to monitor moth biodiversity with camera trap images [ 13]. Jain et al. propose a complete machine-learning pipeline from objection detection to fine-grained species-level classifi- cation for automated moth monitoring [ 14]. Although benchmark datasets including iNat2017 [ 15] and BIOSCAN-1M insect dataset [ 16] have spurred interest in both biodiversity and fine-grained classification research, long-term data that cover a wide range of regions and species are still rare [ 2]. As a result, current studies on insect range shifts [ 2,17,18] still mainly rely on species distribution models instead of directly monitoring their distribution with machine learning and computer vision. 2.2 OOD detection Most prior works [ 19–22] on OOD detection focus on common benchmark datasets like CIFAR- 10[23], SVHN[ 24], Texture[ 25], and iSUN[ 26], where images in different datasets are from unrelated classes. A few works [ 27,28] have considered OOD detection for fine-grained classification datasets including CUB-200-2011[ 29] and Aircraft 300 [ 30]. A simple logit-based OOD detection has been applied for coarse-grained insect recognition (a dataset of 9 species for training and 11 species for testing) to detect samples that are “unsure” to the classifier [ 6]. However, to our knowledge, there is no study on OOD detection that focuses on fine-grained classification of wildlife. 3 Proposed methodology Figure 1: Our proposed workflow (see §3.1 and 3.2). 3.1 Dataset and pre-trained classifier Since we do not have information on new species that might occur in a region, it is impractical to include OOD samples during training. Hence, we will use post-hoc OOD detection methods which use features extracted by pre-trained classifiers to differentiate ID and OOD samples. Pre-trained classifiers were trained with GBIF, an open-source biodiversity dataset [ 31]. We use trained classifiers for Quebec-Vermont, the UK-Denmark, and Panama (following methods detailed in [ 14]). Classes included in the training set were determined by regional species checklists provided by entomologists. For OOD detection training and evaluation, we leverage images from both GBIF and camera traps, using known moth species that are not in the target region to test our OOD detection algorithms. 3.2 OOD detection and visual explanation We use Mahalanobis distance-based confidence score (M-score) [ 7] for\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nWe propose using Alanis distance-based confidence scores to automatically detect new moth species in a region. To make out-of-distribution detection interpretable, we will identify morphological characteristics of different species using Grad-CAM. Our goal is to develop a useful tool for entomologists to study range shifts and inform climate change adaptation.\n\nClimate change leads to increased temperatures, more extreme weather events, and changes in precipitation, affecting insect biodiversity and causing insect range shifts in many regions. Understanding how insect distribution and biodiversity change is crucial for habitat conservation and pest management in a changing climate. With over 160,000 species worldwide, moths play critical roles in different ecosystems as pollinators, prey, agricultural pests, and indicator species of habitat disturbance. Due to climate change, some regions have observed a decline in moth populations that may threaten the local ecosystem, while others have observed distribution shifts or increased populations of moths that lead to more challenges in pest management.\n\nMachine learning-based methods, including object detection and image classification, have been applied for automated camera-assisted insect monitoring, providing valuable large-scale data for quantifying moth abundance and biodiversity. To leverage camera trap images, we propose using out-of-distribution detection to automatically detect new species and study moth range shifts. We will use Mahalanobis distance-based confidence scores to differentiate in-distribution (ID) and out-of-distribution (OOD) species and interpret the results with Grad-CAM, which can provide concept-specific visualization for fine-grained classification.\n\nAutomated insect monitoring with machine learning has emerged as a promising area. In agriculture, computer vision has been used to automatically identify insect species with trap images to facilitate pest management. An increasing number of studies have also focused on monitoring insect biodiversity with machine learning. Bjerge et al. suggest a non-lethal method to monitor moth biodiversity with camera trap images. Jain et al. propose a complete machine-learning pipeline from object detection to fine-grained species-level classification for automated moth monitoring.\n\nAlthough benchmark datasets, including iNat2017 and BIOSCAN-1M insect dataset, have spurred interest in both biodiversity and fine-grained classification research, long-term data that cover a wide range of regions and species are still rare. As a result, current studies on insect range shifts mainly rely on species distribution models instead of directly monitoring their distribution with machine learning and computer vision.\n\nMost prior works on out-of-distribution detection focus on common benchmark datasets, such as CIFAR-10, SVHN, Texture, and iSUN, where images in different datasets are from unrelated classes. A few works have considered out-of-distribution detection for fine-grained classification datasets, including CUB-200-2011 and Aircraft 300. However, to our knowledge, there is no study on out-of-distribution detection that focuses on fine-grained classification of wildlife.\n\nWe propose a workflow that includes the following steps: \n\n1. Dataset and pre-trained classifier: We will use post-hoc out-of-distribution detection methods that use features extracted by pre-trained classifiers to differentiate ID and OOD samples. Pre-trained classifiers were trained with GBIF, an open-source biodiversity dataset. We will use trained classifiers for Quebec-Vermont, the UK-Denmark, and Panama. Classes included in the training set were determined by regional species checklists provided by entomologists.\n\n2. Out-of-distribution detection and visual explanation: We will use Mahalanobis distance-based confidence score (M-score) for out-of-distribution detection."
}