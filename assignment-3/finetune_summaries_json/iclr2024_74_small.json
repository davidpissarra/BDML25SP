{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" be performed. This results in significant uncertainty in key climate metrics esti- mated from ESM ensembles. We propose a Bayesian optimal experimental design (BOED) approach to efficiently calibrate ESM simulations to observational data by actively selecting the most informative input parameters. BOED optimises the expected information gain (EIG) to select the ESM input parameter to reduce the final uncertainty estimates in the climate metrics of interest. Initial results on a synthetic benchmark demonstrate our approach can more efficiently reduce un- certainty compared to common sampling schemes like Latin hypercube sampling. 1 I NTRODUCTION Earth system models (ESMs) (Flato, 2011) constitute an extensive simulation of the Earth’s atmo- sphere and ocean fluid dynamics, based on energy, mass, and momentum conservation equations. As such, they stand as key tools to examine the climate system, project its response to anthropogenic emissions, and study its underlying drivers. An ESM run generates a rich range of spatially resolved climate variables, including surface temperatures, precipitations and winds, which we shall refer to assimulated variables. These simulated variables are then used to diagnose important character- istic properties of the climate system, such as the top-of-atmosphere effective radiative forcing, or timescales and equilibrium responses to changes in greenhouse gas and aerosol emissions (Allen et al., 2009; Collins et al., 2014; Levy et al., 2013), which we shall refer to as latent variables. Accurately diagnosing these latent variables is critical to improve our understanding of how the cli- mate system reacts to changes in emissions and better constrain our idea of what an uncertain future warming may look like. For example, diagnosing the so called climate feedback parameter allows to quantify the magnitude of the Earth’s feedback response to a given change in global mean surface temperature. Diagnosing the aerosol effective radiative forcing allows to quantify how much of the current warming is masked by the aerosol cooling effect. Better understanding and constraining these effects is crucial for planning and informing adaption strategies. The latent variable diagnosis is typically achieved by running multiple ESM simulations for per- turbed parameter ensembles, and then using the ensemble of simulated outputs to compute an esti- mate of the latent variables. However, each simulation is extremely computationally expensive—for reference, running the CESM2 model (Danabasoglu et al., 2020) for a single year ahead takes about 2000 core hours on a supercomputer. Using large ensembles of simulations is therefore computa- tionally prohibitive. As a result, a large uncertainty remains on the estimates of these latent variables. In the case of the the aerosol effective radiative forcing mentioned earlier, the uncertainty bounds are so wide that the forcing could offset global warming or double its effects (Boucher et al., 2013). A common practice to create ensemble members is to perturb the input parameters using Latin hypercube sampling (LHS) (McKay et al., 2000) or some other form of random sampling (Lee et al., 2011; Qian et al., 2015; Watson-Parris et al., 2020). However, this is potentially wasteful because 1Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024 it does not take into account the observed data and therefore potentially evaluates the simulators in parameter regions which are unlikely to produce simulations which match the observed data. As an alternative we propose to select the simulator inputs in a more active manner, directly account- ing for the observed data. To achieve this we leverage tools from Bayesian optimal experimental design (BOED) (Lindley, 1956; Chaloner & Verdinelli, 1995; Ryan et al., 2016; Rainforth et al., 2023). In order to leverage BOED approaches, we postulate a surrogate model in the form of a Gaussian process (GP) for the simulator which is trained on the real-world observed data and the simulated data. The input parameters to the simulator are then selected based on optimizing the expected information gain (EIG) which measures the expected reduction in Shannon entropy after having observed a given data point (Lindley, 1956). In this proposal we are going to outline: 1) how to frame the problem of constraining the uncertainty on ESMs latent variables as a probabilistic inference problem, 2) show how this formulation natu- rally leads to a BOED mechanism to select the simulator input parameters, and 3) present promising initial results on a synthetic benchmark. 2 O PTIMAL EXPERIMENTAL DESIGN FOR EARTH SYSTEM MODELS We will use ξt∈Ξto denote the simulator inputs of the tth run, consistent with terminology in the experimental design literature we will sometimes refer to them as designs. The input parameter space Ξis often constrained to be the unit hypercube. The simulated andlatent variables produced by the\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nEarth system models (ESMs) are a crucial tool for examining the climate system, projecting its response to anthropogenic emissions, and studying its underlying drivers. ESMs simulate the Earth's atmosphere and ocean fluid dynamics based on energy, mass, and momentum conservation equations. They generate a range of spatially resolved climate variables, including surface temperatures, precipitation, and winds, which are used to diagnose important characteristics of the climate system, such as the top-of-atmosphere effective radiative forcing and timescales and equilibrium responses to changes in greenhouse gas and aerosol emissions.\n\nAccurately diagnosing these characteristics is critical to improve our understanding of how the climate system reacts to changes in emissions and better constrain our idea of what an uncertain future warming may look like. For example, diagnosing the climate feedback parameter allows us to quantify the magnitude of the Earth's feedback response to a given change in global mean surface temperature. Diagnosing the aerosol effective radiative forcing allows us to quantify how much of the current warming is masked by the aerosol cooling effect.\n\nHowever, running multiple ESM simulations for perturbed parameter ensembles is extremely computationally expensive. For instance, running the CESM2 model for a single year ahead takes about 2000 core hours on a supercomputer. Using large ensembles of simulations is therefore computationally prohibitive, resulting in a large uncertainty on the estimates of these characteristics.\n\nA common practice to create ensemble members is to perturb the input parameters using Latin hypercube sampling or some other form of random sampling. However, this approach does not take into account the observed data and may evaluate the simulators in parameter regions that are unlikely to produce simulations that match the observed data.\n\nWe propose an alternative approach, leveraging tools from Bayesian optimal experimental design (BOED), to select the simulator inputs in a more active manner, directly accounting for the observed data. To achieve this, we postulate a surrogate model in the form of a Gaussian process for the simulator, which is trained on the real-world observed data and the simulated data. The input parameters to the simulator are then selected based on optimizing the expected information gain, which measures the expected reduction in Shannon entropy after having observed a given data point.\n\nWe will outline how to frame the problem of constraining the uncertainty on ESMs' latent variables as a probabilistic inference problem, show how this formulation naturally leads to a BOED mechanism to select the simulator input parameters, and present promising initial results on a synthetic benchmark.\n\nIn this context, we will use ξt∈Ξ to denote the simulator inputs of the tth run, and refer to them as designs. The input parameter space Ξ is often constrained to be the unit hypercube. The simulated and latent variables produced by the ESM are used to diagnose the characteristics of the climate system."
}