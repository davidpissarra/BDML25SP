{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\".9 ×and 2.5 ×, respectively over 1.5 years; during a similar time period, data capacity for Meta’s production recommendation mod- els doubled (Wu et al., 2022). While the exponential scaling has enabled unprecedented capabilities across computer vision, natural language processing, generative AI, protein modeling, personalized recommendation, it comes at the expense of significant energy and environmental footprints. Recent work demonstrates the high carbon footprint incurred by AI at scale. Patterson et al. (2021) illustrate that training a single natural language processing model, such as Meena, consumes the equivalent carbon footprint of thousands of miles traveled by an average passenger vehicle. How- ever, such estimates account for only a portion of AI’s holistic environmental impact as they quantify emissions owing to operational energy consumption during training alone. We must consider the real environmental impact of the end-to-end AI ecosystem going forward including, model life cycles (i.e., training, inference) and hardware life cycles (i.e., hardware man- ufacturing, operational hardware use). As an example, when considering only dynamic power con- sumption, training a 176 billion parameter BLOOM language model consumes 24.7 metric tonnes of CO 2; on the other hand, considering the holistic training process, including overheads of manu- facturing training platforms, the training footprint increases to 50.5 metric tonnes of CO 2, doubling the environmental impact. And this does not include any of the impact incurred from serving – i.e., actually using – the model (which is often even larger). At Meta, data collection and storage, train- ing and experimentation, and inference deployment have been found to account for roughly 30%, 30%, and 40% of AI infrastructure footprint (Wu et al., 2022). The goal of this proposed project is to investigate the design of environmentally sustainable, accu- rate, and efficient AI models. We frame this as a multi-objective optimization problem with under- studied and non-intuitive tradeoffs. Central to this work is holistically accounting for the environ- mental impact across both model and hardware life cycles. 2 R ESEARCH PROPOSAL In this section, we provide details on the problem formulation that we intend to study. At a high level, we are interested in maximizing performance -related objectives, namely accuracy and efficiency, while keeping the sustainability costs low. The levers (or decision variables) at our disposal are model and training hyperparameters (e.g., architectures, learning rates, batch sizes) and compute parameters (e.g., which datacenter to use, hardware platform). In general, both types of levers can influence both performance and sustainability objectives: for example, a model architecture with more parameters will have an adverse effect on sustainability costs. In the subsequent subsections, we detail the optimization methods and models used in our proposed study. 2.1 M ULTI -OBJECTIVE OPTIMIZATION It is clear that there are difficult trade-offs to consider between performance and sustainability ob- jectives. At the same time, evaluating the objectives is time-consuming and expensive, as it requires training a model to completion. We therefore propose to study this problem using the frame- work of multi-objective Bayesian optimization (MOBO) (Belakaria et al., 2019; Daulton et al., 2020; Konakovic Lukovic et al., 2020; Paria et al., 2020; Daulton et al., 2021), a set of tech- niques for sample-efficient multi-objective optimization. Given decision variables x∈ X and a 1Workshop paper at “Tackling Climate Change with Machine Learning”, ICLR 2023 Figure 1: An example Pareto frontier after 50 trials of multi-objective Bayesian optimization on a toy recommendation model, where we tuned the optimizer learning rate, the embedding dimension, and the number of training epochs. Explicitly accounting for CO2 emissions as an optimization objective, we find configurations with low validation loss and significantly reduced CO2 impact. vector-valued objective function f(x)∈RM, the goal of MOBO is to identify a Pareto frontier P∗={f(x) :x∈ X,∄x′∈ X s.t.f(x)≻f(x′)}, where f(x)≻f(x′)means f(x)≥f(x′) with at least one dimension’s inequality being strict. In other words, the Pareto frontier represents the set of tradeoffs where one cannot improve one objective without hurting another. We plan to use, and build upon, the noisy expected hypervolume improvement (qNEHVI) method (Daulton et al., 2021), which are available as open source software (Balandat et al., 2020). 2.2 O PTIMIZATION MODELS Post-deployment model. We first describe the post-deployment version of the problem, where we\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThe training of large-scale AI models has led to unprecedented capabilities in computer vision, natural language processing, generative AI, protein modeling, and personalized recommendation. However, this exponential scaling comes at the expense of significant energy and environmental footprints. Recent studies demonstrate the high carbon footprint incurred by AI at scale, with training a single natural language processing model consuming the equivalent carbon footprint of thousands of miles traveled by an average passenger vehicle. However, these estimates only account for a portion of AI's holistic environmental impact, as they quantify emissions due to operational energy consumption during training alone.\n\nTo consider the real environmental impact of the end-to-end AI ecosystem, we must account for model life cycles (training and inference) and hardware life cycles (manufacturing and operational use). For example, training a 176 billion parameter BLOOM language model consumes 24.7 metric tonnes of CO2, but considering the holistic training process, including the overheads of manufacturing training platforms, the training footprint increases to 50.5 metric tonnes of CO2, doubling the environmental impact. This does not include the impact incurred from serving the model, which is often even larger.\n\nAt Meta, data collection and storage, training and experimentation, and inference deployment account for roughly 30%, 30%, and 40% of AI infrastructure footprint. The goal of this proposed project is to investigate the design of environmentally sustainable, accurate, and efficient AI models.\n\nWe frame this as a multi-objective optimization problem with understudied and non-intuitive tradeoffs. Central to this work is holistically accounting for the environmental impact across both model and hardware life cycles.\n\n**Research Proposal**\n\nIn this section, we provide details on the problem formulation that we intend to study. At a high level, we are interested in maximizing performance-related objectives, namely accuracy and efficiency, while keeping the sustainability costs low. The levers (or decision variables) at our disposal are model and training hyperparameters (e.g., architectures, learning rates, batch sizes) and compute parameters (e.g., which datacenter to use, hardware platform).\n\nIn general, both types of levers can influence both performance and sustainability objectives. For example, a model architecture with more parameters will have an adverse effect on sustainability costs.\n\n**Multi-Objective Optimization**\n\nIt is clear that there are difficult trade-offs to consider between performance and sustainability objectives. Evaluating the objectives is time-consuming and expensive, as it requires training a model to completion. We propose to study this problem using the framework of multi-objective Bayesian optimization (MOBO), a set of techniques for sample-efficient multi-objective optimization.\n\nGiven decision variables x∈ X and a vector-valued objective function f(x)∈ RM, the goal of MOBO is to identify a Pareto frontier P∗={f(x) :x∈ X,∄x′∈ X s.t.f(x)≻f(x′)}, where f(x)≻f(x′) means f(x)≥f(x′) with at least one dimension's inequality being strict. The Pareto frontier represents the set of tradeoffs where one cannot improve one objective without hurting another.\n\nWe plan to use, and build upon, the noisy expected hypervolume improvement (qNEHVI) method, which is available as open source software.\n\n**Optimization Models**\n\nPost-deployment model. We first describe the post-deployment version of the problem, where we aim to optimize the performance and sustainability of a model that has already been deployed."
}