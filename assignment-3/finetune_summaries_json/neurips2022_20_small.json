{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"urate knowledge of flood-extent for ongoing and historical events facilitates climate adaptation in flood-prone commu- nities by enabling near real-time disaster monitoring to support planning, response, and relief during these extreme events. Satellite observations can be used to derive flood-extent maps directly; however, these observations are impeded by cloud and canopy cover, and can be very infrequent and hence miss the flood completely. In contrast, physically-based inundation models can produce spatially complete event maps but suffer from high uncertainty if not frequently calibrated with expensive land and infrastructure surveys [17, 19]. In this study, we propose a deep learn- ing approach to reproduce satellite-observed fractional flood-extent maps given dynamic state variables from hydrologic models, fusing information contained within the states with direct observations from satellites. Our model has an hourly temporal resolution, contains no cloud-gaps, and generalizes to watersheds across the continental United States with a 6% error on held-out areas that never flooded before. We further demonstrate through a case study in Houston, Texas that our model can distinguish tropical cyclones that caused flooding from those that did not within two days of landfall, thereby providing a reliable source for flood-extent maps that can be used by disaster monitoring services. 1 Introduction Floods caused losses of USD 20 billion globally in 2021 alone, and the relative property loss caused by floods are highest in places with social vulnerability [16], further exacerbating economic disparities. Effective disaster response can mitigate the aftermath of widespread flooding; however, flood managers and disaster response personnel require timely and accurate maps of the maximum or \"peak\" spatial inundation (flood-extent maps) to mount an appropriate response. Previous work mapping floods and flood risk falls broadly in two categories: physically-based hydraulic models and satellite-observed segmentation models. Hydraulic models use physical equations that define relationships between streamflow, elevation, slope, soil-type, and human infrastructure to produce flood depth and extent maps. To build high-quality hydraulic flood models however, requires engineering-grade models that capture geographical and infrastructure conditions, a complex and expensive process that is not accessible to resource-limited communities in short time frames. Freely available hydraulic models exist and can be used to generate flood maps, but suffer from oversimplifications such as excluding precipitation-driven or pluvial flooding [4, 20], that reduces the accuracy of their outputs. Publicly available optical and active microwave satellite Tackling Climate Change with Machine Learning Workshop 36th Conference on Neural Information Processing Systems (NeurIPS 2022).imagery enables model-free flood monitoring and can be used to generate flood-extent maps with machine learning methods. However, cloud and canopy cover consistently limit observations during rainfall-driven disasters for optical satellites, and the 6-12 day revisit times of active microwave (cloud-piercing) satellites mean only slow-moving floods can be reliably captured [22]. Emerging studies have leveraged both observed and modeled signals to detect floods, with limitations in geographic generalization and applicability. Dasgupta et al. [2] used coarse soil moisture and precipitation observations to predict inundation given a pre-flood optical satellite image in a case study a single region of interest. However, in a feature analysis they showed no impact of flood forcing information, a counterintuitive result that indicates overfitting to the information in a single region of interest (ROI), where flooding primarily occurred in low-lying areas adjacent to a river. Furthermore, their model requires cloud-free pre-flood and during-flood images to train, which can be impractical to collect for fast-moving or rain-driven events. Guo et al. [5] trained an image translation network to convert static terrain representations to water depth images given a hyetograph. While their results are promising, their study was limited to 18 events in a single catchment, and all training data was simulated using hydraulic models. Other recent works have trained networks to produce the outputs of a hydraulic model given a similar set of inputs; however, these studies have been limited to synthetic flooding scenarios [6, 21], single and/or small study areas [6, 9, 21], or riverine (fluvial) flooding only [6]. Contribution In this study, we train a fully convolutional encoder-decoder network on hydrologic model states and auxiliary static layers to produce fractional water extent maps (henceforth referred to as \"flood maps\") similar to those derived directly from satellite observations. To our knowledge, this is the first work that directly uses hydrologic states and satellite observed water to train a single network in a large, multi-watershed study. Our approach leverages the robustness and scalability of satellite observations with the spatial completeness of physically based inundation models in order to produce hourly, gap-free flood maps, which can enable all communities in the continental United States to respond and adapt to the effects of increasingly prevalent flooding. 2 Methods We trained a fully convolutional encoder-decoder network to regress the fractional water in a 2km\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nKnowledge of flood extent for ongoing and historical events is crucial for climate adaptation in flood-prone communities, enabling near real-time disaster monitoring to support planning, response, and relief during extreme events. Satellite observations can be used to derive flood-extent maps directly, but these observations are often impeded by cloud and canopy cover, and can be infrequent, missing the flood entirely. In contrast, physically-based inundation models can produce spatially complete event maps but suffer from high uncertainty if not frequently calibrated with expensive land and infrastructure surveys.\n\nWe propose a deep learning approach to reproduce satellite-observed fractional flood-extent maps given dynamic state variables from hydrologic models, fusing information contained within the states with direct observations from satellites. Our model has an hourly temporal resolution, contains no cloud gaps, and generalizes to watersheds across the continental United States with a 6% error on held-out areas that never flooded before. We demonstrate through a case study in Houston, Texas, that our model can distinguish tropical cyclones that caused flooding from those that did not within two days of landfall, providing a reliable source for flood-extent maps that can be used by disaster monitoring services.\n\nFloods caused losses of USD 20 billion globally in 2021 alone, and the relative property loss caused by floods is highest in places with social vulnerability, exacerbating economic disparities. Effective disaster response can mitigate the aftermath of widespread flooding, but flood managers and disaster response personnel require timely and accurate maps of the maximum or \"peak\" spatial inundation (flood-extent maps) to mount an appropriate response.\n\nPrevious work mapping floods and flood risk falls broadly into two categories: physically-based hydraulic models and satellite-observed segmentation models. Hydraulic models use physical equations to produce flood depth and extent maps, but require engineering-grade models that capture geographical and infrastructure conditions, a complex and expensive process that is not accessible to resource-limited communities in short time frames. Freely available hydraulic models exist but suffer from oversimplifications, such as excluding precipitation-driven or pluvial flooding, reducing the accuracy of their outputs.\n\nPublicly available optical and active microwave satellite imagery enables model-free flood monitoring and can be used to generate flood-extent maps with machine learning methods. However, cloud and canopy cover limit observations during rainfall-driven disasters for optical satellites, and the 6-12 day revisit times of active microwave satellites mean only slow-moving floods can be reliably captured.\n\nEmerging studies have leveraged both observed and modeled signals to detect floods, with limitations in geographic generalization and applicability. Previous studies have used coarse soil moisture and precipitation observations to predict inundation given a pre-flood optical satellite image in a single region of interest, but these models require cloud-free pre-flood and during-flood images to train, which can be impractical to collect for fast-moving or rain-driven events.\n\nWe train a fully convolutional encoder-decoder network on hydrologic model states and auxiliary static layers to produce fractional water extent maps (henceforth referred to as \"flood maps\") similar to those derived directly from satellite observations. Our approach leverages the robustness and scalability of satellite observations with the spatial completeness of physically based inundation models to produce hourly, gap-free flood maps, enabling all communities in the continental United States to respond and adapt to the effects of increasingly prevalent flooding."
}