{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"for- tunately, the computational requirements of modern earth system models limit the resolution of simulations. For this reason, raw model output is routinely post-processed using statistical methods to downscale results to higher spatial resolution (Maraun & Widmann, 2018). Given shortcomings of using traditional statistical tech- niques for downscaling on many metrics (Widmann et al., 2019; Guti ´errez et al., 2019; Hertig et al., 2019; Maraun et al., 2019), there has been considerable work on applying modern deep learning architectures to this problem. While bias correction (Cannon, 2011; B ¨urger et al., 2012) and un- supervised methods using normalising ﬂows (Groenke et al., 2020) have been proposed, the majority of studies apply perfect prognosis models. In these methods the aim is to learn a transfer function mapping from low resolution pre- dictors to high resolution outputs. This function is trained on observational data then applied to the coarse resolution model output (Maraun & Widmann, 2018). Architectures previously applied to this task include convolutional neural networks (Vandal et al., 2017; Wang et al., 2021; Liu et al., 2020; Ba ˜no-Medina et al., 2020), autoencoders (Vandal et al., 2019), generative adversarial networks (Chaudhuri & Robertson, 2020), multilayer perceptrons (MLPs; Cannon, 2008) and long short-term memory networks (Misra et al., 2018). In these studies the transfer function maps from a set of coarse resolution predictors to a ﬁxed set of locations, typi-cally on a grid, where training data are available. The model is then ﬁtted by minimising a loss function between obser- vations and model predictions at each point. This raises the question of how to make predictions at locations where training data are not available. Wang et al. (2021) used trans- fer learning to apply a convolutional neural network trained to map low resolution gridded predictors to high resolution gridded observations in one region to make skillful predic- tions in another. Though this allows predictions to be made at other locations, the resolution of the output grid remains ﬁxed by the resolution of the training data. An alternative approach is to learn a transfer function from the low reso- lution predictors to a stochastic process (i.e a distribution over spatial functions of the variable being downscaled). This has advantages that the predicted stochastic process can be queried at any spatial location at test time, and un- certainty in the predictions is quantiﬁed. Vaughan et al. (2021) applied convolutional conditional neural processes (convCNP; Gordon et al., 2019) to downscaling temperature and precipitation at 86 locations in Europe. Unfortunately, the convCNP model is of little practical use for climate impact studies as it cannot produce spatially coherent sam- ples (Dubois et al., 2020). A further limitation is that the convCNP model is only suitable for univariate downscaling. In many applications, for example agriculture and wildﬁre prediction, it is necessary to accurately model the joint dis- tribution of multiple variables. In this study we build on the work of Vaughan et al. (2021) to develop a new model for multivariate downscaling using a convolutional latent neural process (convLNP; Foong et al., 2020) to predict a multivariate stochastic process describing spatial ﬁelds of temperature and precipitation given low res- olution predictor ﬁelds. This model jointly downscales daily maximum temperature and precipitation, quantiﬁes uncer- tainty in predictions, generates coherent spatial samples and can generate predictions at arbitrary locations at test time. For this work the convLNP model is trained to downscale gridded low-resolution ERA-5 reanalysis data to station observations over Germany, with performance evaluated at held out locations. To our knowledge this is the ﬁrst attempt at multivariate downscaling by learning a transfer function to a stochastic process. Our ﬁndings indicate that this model is suitable for generating multivariate projections of temperature and precipitation suitable for use in climateMultivariate climate downscaling with latent neural processes Figure 1. convLNP model architecture. impact studies. 2. Methodology Idea: Use a latent neural process Garnelo et al. (2018) to learn a transfer function mapping a set of daily gridded low resolution climate predictors to a multivariate stochastic pro- cess indexed by longitude and latitude. Unlike the convCNP model used by Vaughan et al. (2021), the latent neural pro- cess is able to model correlations between locations (Dubois et al., 2020).\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nFortunately, the computational requirements of modern earth system models limit the resolution of simulations. For this reason, raw model output is routinely post-processed using statistical methods to downscale results to higher spatial resolution (Maraun & Widmann, 2018). Given the shortcomings of using traditional statistical techniques for downscaling on many metrics (Widmann et al., 2019; Gutiérrez et al., 2019; Hertig et al., 2019; Maraun et al., 2019), there has been considerable work on applying modern deep learning architectures to this problem. While bias correction (Cannon, 2011; Bürger et al., 2012) and unsupervised methods using normalizing flows (Groenke et al., 2020) have been proposed, the majority of studies apply perfect prognosis models. In these methods, the aim is to learn a transfer function mapping from low-resolution predictors to high-resolution outputs. This function is trained on observational data and then applied to the coarse-resolution model output (Maraun & Widmann, 2018).\n\nArchitectures previously applied to this task include convolutional neural networks (Vandal et al., 2017; Wang et al., 2021; Liu et al., 2020; Bano-Medina et al., 2020), autoencoders (Vandal et al., 2019), generative adversarial networks (Chaudhuri & Robertson, 2020), multilayer perceptrons (MLPs; Cannon, 2008), and long short-term memory networks (Misra et al., 2018). In these studies, the transfer function maps from a set of coarse-resolution predictors to a fixed set of locations, typically on a grid, where training data are available. The model is then fitted by minimizing a loss function between observations and model predictions at each point. This raises the question of how to make predictions at locations where training data are not available.\n\nWang et al. (2021) used transfer learning to apply a convolutional neural network trained to map low-resolution gridded predictors to high-resolution gridded observations in one region to make skillful predictions in another. Although this allows predictions to be made at other locations, the resolution of the output grid remains fixed by the resolution of the training data. An alternative approach is to learn a transfer function from the low-resolution predictors to a stochastic process, i.e., a distribution over spatial functions of the variable being downscaled. This has the advantage that the predicted stochastic process can be queried at any spatial location at test time, and uncertainty in the predictions is quantified.\n\nVaughan et al. (2021) applied convolutional conditional neural processes (convCNP; Gordon et al., 2019) to downscale temperature and precipitation at 86 locations in Europe. Unfortunately, the convCNP model is of little practical use for climate impact studies as it cannot produce spatially coherent samples (Dubois et al., 2020). A further limitation is that the convCNP model is only suitable for univariate downscaling. In many applications, for example, agriculture and wildfire prediction, it is necessary to accurately model the joint distribution of multiple variables.\n\nIn this study, we build on the work of Vaughan et al. (2021) to develop a new model for multivariate downscaling using a convolutional latent neural process (convLNP; Foong et al., 2020) to predict a multivariate stochastic process describing spatial fields of temperature and precipitation given low-resolution predictor fields. This model jointly downscales daily maximum temperature and precipitation, quantifies uncertainty in predictions, generates coherent spatial samples, and can generate predictions at arbitrary locations at test time. For this work, the convLNP model is trained to downscale gridded low-resolution ERA-5 reanalysis data to station observations over Germany, with performance evaluated at held-out locations. To our knowledge, this is the first attempt at multivariate downscaling by learning a transfer function to a stochastic process.\n\nOur findings indicate that this model is suitable for generating multivariate projections of temperature and precipitation suitable for use in climate impact studies. \n\nIdea: Use a latent neural process (Garnelo et al., 2018) to learn a transfer function mapping a set of daily gridded low-resolution climate predictors to a multivariate stochastic process indexed by longitude and latitude. Unlike the convCNP model used by Vaughan et al. (2021), the latent neural process is able to model correlations between locations (Dubois et al., 2020)."
}