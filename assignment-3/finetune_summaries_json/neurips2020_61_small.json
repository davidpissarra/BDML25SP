{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" best understanding of the Earth system, allowing research to be conducted on its future under alternative assumptions of how human-driven climate forces are going to evolve. An important application of climate models is to provide metrics of mean and extreme climate changes, particularly under these alternative future scenarios, as these quantities drive the impacts of climate on society and natural systems [ 1,2,3]. Furthermore, efforts in integrated modeling seek to “close the loop,” by having impacts on society feedback on societal conditions that drive emissions [ 4]. Because of the need to explore a wide range of alternative scenarios and other sources of uncertainties in a computationally efﬁcient manner, climate models can only take us so far, as they require large computational resources, with a single simulation of the 21stcentury taking on the order of weeks on a supercomputer. The computational requirements expand considerably when attempting to characterize extreme events, which are rare and thus demand long and numerous simulations exploring a noisy system in order to accurately represent their changing statistics. Climate model emulators address some of these problems. Trained on climate model output, emulators are simpler, data-driven tools (often obtained through parametric ﬁts like regressions) that are less accurate or less complex than climate models but can produce values in fractions of a second on a laptop. Their computational cost, when signiﬁcant, is made upfront in the training phase. Traditionally, emulators like Pattern Scaling have been used to approximate average quantities, like annual or seasonal or monthly average temperature and precipitation [ 5,6,7,8,9,10,11,12]. Recently the accuracy of some of these techniques for representing extremes has been documented as well [ 13]. “Top-down” approaches to emulation involve directly approximating metrics themselves, like the hottest or the wettest day of the year. Alternatively, a “bottom-up” approach tackles the emulation of the building blocks (in these cases, daily temperatures and precipitation during the year) and then compute the metric of interest. Examples include stochastic weather generators [ 14,15,16], which rely on parametrizing the distribution of the weather variable and randomly sample its realizations. Weather generators have been usually developed for limited domains and speciﬁc applications, rarely facing the issue of representing non-stationarities and non-linearities, which are critical for integrated modeling of impacts, arbitrary domains, and scenario generation. Increasingly, joint efforts between climate science and machine learning are being formed to tackle some of the most complex data-driven problems [ 17,18]. So far most of the applications have focused on bringing deep learning in aid of better model forecasts, model parameterizations, or in substitution of climate models [ 19,20,21,22,23,24,25,26,27]; of better detection of signals, from extreme events to large scale patterns of anthropogenic changes amidst the internal noise of the climate system [ 28,29,30,31,32,33]; and of spatial in-ﬁlling in the case of ﬁne-scale features that models would be too expensive, or plainly unable, to generate, or observations cannot cover [34, 35, 36, 37]. Here we use deep learning in a proof of concept that lays the foundation for emulating global climate model output for different scenarios. We train Generative Adversarial Networks (GANs) that emulate daily precipitation output from a fully coupled Earth system model. Our GANs are trained to produce samples in the form of T\u0002H\u0002Wtensors, whereTdenotes the number of timesteps (days) and HandWare the spatial height and width, respectively, of a regular grid discretizing the globe. The goal is for these samples to be statistically indistinguishable from samples of the same dimension drawn from a state-of-the-art earth system model. Our trained GAN can rapidly generate numerous realizations at a vastly reduced computational expense, compared to large ensembles of climate models [ 38,39], which Tackling Climate Change with Machine Learning workshop at NeurIPS 2020.(a) Generator  (b) Critic 2.0x (c) Generator block. 0.5x (d) Critic block. Figure 1: Generator (a), critic (b), generator block (c), and critic block (d) architectures. Subscript i!jdenotes the feature dimension of the input ( i) and output ( j). Convs in the generator block are followed by batch norm and Leaky ReLU; Convs in the critic block are followed by Leaky ReLU. Figure 2: Generated samples. Top row: precipitation maps for three successive generated days. Bottom row: precipitation maps for three successive test days. Units: mm/day. greatly aids in estimating the statistics of extreme events. Compared to our prior “DeepClimGAN” [ 40], we ﬁnd that the approach proposed here produces signiﬁcantly higher quality spatio-temp\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThe best understanding of the Earth system is crucial for conducting research on its future under alternative assumptions of how human-driven climate forces will evolve. An important application of climate models is to provide metrics of mean and extreme climate changes, particularly under these alternative future scenarios, as these quantities drive the impacts of climate on society and natural systems. Furthermore, efforts in integrated modeling seek to \"close the loop\" by having impacts on society feedback on societal conditions that drive emissions.\n\nBecause of the need to explore a wide range of alternative scenarios and other sources of uncertainties in a computationally efficient manner, climate models can only take us so far. They require large computational resources, with a single simulation of the 21st century taking weeks on a supercomputer. The computational requirements expand considerably when attempting to characterize extreme events, which are rare and thus demand long and numerous simulations exploring a noisy system to accurately represent their changing statistics.\n\nClimate model emulators address some of these problems. Trained on climate model output, emulators are simpler, data-driven tools that are less accurate or less complex than climate models but can produce values in fractions of a second on a laptop. Their computational cost, when significant, is made upfront in the training phase. Traditionally, emulators like Pattern Scaling have been used to approximate average quantities, such as annual or seasonal or monthly average temperature and precipitation.\n\nRecently, the accuracy of some of these techniques for representing extremes has been documented. \"Top-down\" approaches to emulation involve directly approximating metrics themselves, such as the hottest or the wettest day of the year. Alternatively, a \"bottom-up\" approach tackles the emulation of the building blocks (in these cases, daily temperatures and precipitation during the year) and then computes the metric of interest. Examples include stochastic weather generators, which rely on parametrizing the distribution of the weather variable and randomly sampling its realizations.\n\nIncreasingly, joint efforts between climate science and machine learning are being formed to tackle some of the most complex data-driven problems. So far, most applications have focused on bringing deep learning in aid of better model forecasts, model parameterizations, or in substitution of climate models; of better detection of signals, from extreme events to large-scale patterns of anthropogenic changes amidst the internal noise of the climate system; and of spatial in-filling in the case of fine-scale features that models would be too expensive, or plainly unable, to generate, or observations cannot cover.\n\nHere, we use deep learning in a proof of concept that lays the foundation for emulating global climate model output for different scenarios. We train Generative Adversarial Networks (GANs) that emulate daily precipitation output from a fully coupled Earth system model. Our GANs are trained to produce samples in the form of T x H x W tensors, where T denotes the number of timesteps (days) and H and W denote the spatial height and width, respectively, of a regular grid discretizing the globe. The goal is for these samples to be statistically indistinguishable from samples of the same dimension drawn from a state-of-the-art Earth system model.\n\nOur trained GAN can rapidly generate numerous realizations at a vastly reduced computational expense, compared to large ensembles of climate models. This greatly aids in estimating the statistics of extreme events. Compared to our prior \"DeepClimGAN,\" we find that the approach proposed here produces significantly higher quality spatio-temporal precipitation maps."
}