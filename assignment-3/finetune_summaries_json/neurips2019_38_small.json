{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" these data manually or semi-automatically, which is time-consuming and prone to inconsistencies. This paper proposes a deep learning framework for the automatic de- tection of schools of herring from echograms. Ex- periments demonstrated that our approach outper- forms a traditional machine learning algorithm that uses hand-crafted features. Our framework could easily be expanded to detect more species of interest to sustainable ﬁsheries. 1. Introduction The study of acoustic backscatter is commonly utilized by biologists as a means to monitor underwater sites in a thor- ough and non-invasive manner. Different species possess different acoustic properties, thus producing different re- sponses. Acoustic survey data are typically interpreted via time-consuming manual or semi-automatic approaches prone to inconsistencies, using expensive softwares such as Echoview (https://www.echoview.com/). In this paper, we apply deep learning methods for automatically detecting speciﬁc biological targets in acoustic survey data. Our goals are to improve data processing and interpretation for species abundance tracking and environmental monitoring, and to provide a tool that reliably supports analyses of the effects of climate change. We present a case study on schools of herring. *Equal contribution1University of Victoria, Victoria, Canada 2ASL Environmental Sciences, Victoria, Canada3Fisheries and Oceans Canada, Victoria, Canada. Correspondence to: Alexandra Branzan Albu <aalbu@uvic.ca >. Tackling Climate Change with Machine Learning Workshop at the33rdConference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.Acoustic data are obtained via multifrequency echosounders, such as the Acoustic Zooplankton Fish Proﬁler (AZFP) [ 1], and visualized in 2D, with depth along the y-axis and time along the x-axis, producing an echogram. A color code represents the echo amplitude, usually in the form of volu- metric backscatter strength. Visual structures indicate geo- logical and biological elements. Acoustic-scattering models provide a link between echograms and the size/abundance distribution of the animals [ 2]. Echograms are traditionally analyzed using statistical characteristics of the aggregations of organisms [ 3]. Feature-based classiﬁcation methods com- monly favor a classical machine learning [ 4,5,6,7,8,9] paradigm and use hand-crafted features. Deep learning, which has been shown to be very effective at various tasks in computer vision such as object detection and recogni- tion, has yet to permeate echogram analysis. Only a few methods deal with identifying ﬁsh from echograms utilizing deep learning and are quite limited in the nature of their experiments [ 10] or data [ 11]. A few additional works have applied deep learning to the detection of mobile marine life in sonar data [ 12,13,14], which typically have a higher resolution than echograms. Our contributions are two-fold. Firstly, we propose a novel application of deep learning techniques for ﬁsh detection from echograms. Secondly, our framework automates acous- tic survey analyses; an automatic approach will reduce pro- cessing times, required man-power, and inconsistencies in the results. Our approach also has the potential to be scaled to handle additional underwater species. Biologists collect large quantities of echograms so the amount of data is not a limitation for the training of a deep learning-based frame- work; however, the annotation process is a tedious task. We show that, even using a smaller annotated dataset, deep learning-based solutions can outperform a classical machine learning method. Our promising results indicate that with the annotation of more data, deep learning can be efﬁciently applied in underwater acoustic analysis. 2. Technical Approach Thanks to the emergence of convolutional neural networks (CNNs) and the existence of large annotated datasets likeA Deep Learning-based Framework for the Detection of Schools of Herring in Echograms Figure 1. ROI extractor pipeline and sample processed echograms at each stage. MS COCO [ 15], PASCAL VOC [ 16], and ImageNet [ 17], object detection is now well addressed for natural scenes. CNNs have been utilizing different architectures to ﬁnd regions of interest (ROIs) in images and to classify them. While earlier networks like R-CNN [ 18] and Fast R-CNN [19] were using selective search [ 20] for ﬁnding ROIs, more recent ones like Faster R-CNN [ 21] use dedicated networks (i.e., Region Proposal Networks (RPNs)) to that end. Unfor- tunately, this approach is not feasible in applications outside the natural scene scope, including ours, where there is in- sufﬁcient box-annotated data for training RPNs. We thus designed an ROI extractor based on high level information on the intensity and morphology of schools of herring. We introduce the proposed\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThis paper proposes a deep learning framework for automatically detecting schools of herring from echograms. Experiments demonstrated that our approach outperforms a traditional machine learning algorithm that uses hand-crafted features. Our framework can easily be expanded to detect more species of interest to sustainable fisheries.\n\nThe study of acoustic backscatter is commonly used by biologists to monitor underwater sites in a thorough and non-invasive manner. Different species possess different acoustic properties, resulting in distinct responses. Acoustic survey data are typically interpreted via time-consuming manual or semi-automatic approaches prone to inconsistencies, using expensive software such as Echoview. In this paper, we apply deep learning methods for automatically detecting specific biological targets in acoustic survey data. Our goals are to improve data processing and interpretation for species abundance tracking and environmental monitoring, and to provide a tool that reliably supports analyses of the effects of climate change.\n\nWe present a case study on schools of herring. Our approach aims to improve data processing and interpretation for species abundance tracking and environmental monitoring, and to provide a tool that reliably supports analyses of the effects of climate change.\n\nAcoustic data are obtained via multifrequency echosounders, such as the Acoustic Zooplankton Fish Profiler (AZFP), and visualized in 2D, with depth along the y-axis and time along the x-axis, producing an echogram. A color code represents the echo amplitude, usually in the form of volumetric backscatter strength. Visual structures indicate geological and biological elements. Acoustic-scattering models provide a link between echograms and the size/abundance distribution of the animals.\n\nEchograms are traditionally analyzed using statistical characteristics of the aggregations of organisms. Feature-based classification methods commonly favor a classical machine learning paradigm and use hand-crafted features. Deep learning, which has been shown to be effective at various tasks in computer vision, such as object detection and recognition, has yet to permeate echogram analysis. Only a few methods deal with identifying fish from echograms using deep learning, and these are limited in the nature of their experiments or data.\n\nOur contributions are two-fold. Firstly, we propose a novel application of deep learning techniques for fish detection from echograms. Secondly, our framework automates acoustic survey analyses, reducing processing times, required manpower, and inconsistencies in the results. Our approach also has the potential to be scaled to handle additional underwater species.\n\nBiologists collect large quantities of echograms, so the amount of data is not a limitation for the training of a deep learning-based framework. However, the annotation process is a tedious task. We show that, even using a smaller annotated dataset, deep learning-based solutions can outperform a classical machine learning method. Our promising results indicate that with the annotation of more data, deep learning can be efficiently applied in underwater acoustic analysis.\n\n2. Technical Approach\n\nThanks to the emergence of convolutional neural networks (CNNs) and the existence of large annotated datasets, object detection is now well-addressed for natural scenes. CNNs have been utilizing different architectures to find regions of interest (ROIs) in images and to classify them. We designed an ROI extractor based on high-level information on the intensity and morphology of schools of herring. We introduce the proposed framework, which consists of an ROI extractor and a classification network. The ROI extractor identifies potential regions of interest in the echogram, and the classification network classifies these regions as either schools of herring or background."
}