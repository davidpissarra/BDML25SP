{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" satellite imagery. However, these maps can be outdated and are often inaccurate,particularly in their representation of developing countries.We worked with the European Space Agency (ESA) to develop a LULC deep learning workflow on the cloud that can ingest Sentinel-2 optical imagery for a large scale LULC change detection. Sentinel-2 has high temporal and spatial resolutions, is openly licensed, and can be freely downloaded from ESA or other service providers. The workflow, Deep LULC,  aims to create automated, accurate, fast, scalable LULC maps to support decision making around natural resource management and urban resilience, especially in developing countries. Our current workflow can be broken down into three steps:1.Generating training data; 2.Training deep learning models on the cloud;3.Predicting LULC over a new area of interest (AOI)IntroductionResults The designedworkflow isan end-to-end workflow that sits on top of two comprehensive tools, SentinelHub, and eo-learn.Sentinel Hubis a cloud based GIS platform for distribution, management and analysis of satellite data. Eo-learn isan earth observation processing framework for machine learning in Python. Deep LULCseamlessly link earth observation data with machine learning, and has a dynamicU-Net under the hood that allows user to train a LULC model quickly.Deep LULC takes in the labeled LULC and associated AOI in shapefiles, set up a task to fetch cloud-free, time series imagery stacks within the defined time interval by the users. It will pair the satellite imagery tile with it’s labeled LULC mask for the supervised deep learning model training on the cloud. On the deep learning model training side, we’re using Dynamic UNetfrom Fast.ai. Fast.aiis a deep learning algorithms python package that lets users to train and test the best practices neural nets with their own data With dynamicU-Netunderthehood of Deep LULC, users can swap-in a variety of models to be used as the UNetencoder. This allows users to quickly experiment and switch the models according to their task, AOI, diversity of data and desired LULC classes. Once a well-performing model is trained, it can be exported as a Tensorflow/Pytorchserving docker image to work with our cloud-based model inference pipeline, Chip n’ Scale. Chip n’ Scale is a open-source package created by Development Seed. It’s a  Queue Arranger helps users run machine learning models over satellite imagery at scale on the cloud. The inference pipeline can automatically scale with the number of images to be processed.Methodology We thankESAfund this work.AcknowledgementsLand, forests, and water are intimately connected to how people live. Changes in land use are heavily influenced by human activities (e.g. agriculture, deforestation, human settlement expansion) and have been a great source of greenhouse gas emissions. Sustainable forest and land management practices vary from region to region, which means having flexible, scalable tools will be critical. With these tools, we can empower analysts, engineers, and decision-makers to see where contributions to climate-smart agricultural, forestry and urban resilience programs can be made. The pipeline, written into Jupyternotebook, is open sourced under eo-learn examples now.Comparing to traditional tree-base and machine learning supervised learning algorithm, e.gRandomForest, SupportVectorMachine and XGBoost, Deep learning LULC method is more sensitive to class imbalance. Model performs poorly to the classes have less data in the training dataset. However, a deep learning LULC workflow is more scalable once a good-performed model is trained and select with cloud GPU machines’ computation powers. Conclusion Figure 2. The pipeline fetches training data, Sentinel-2 optical imagery and labeled 10 classes LULC, for the AOI (in green) that covers 1296 km2 in Slovenia. A UNetusing ResNet50 as the encoder was trained, and the model prediction was done over a new area (in red), and the LULC classification is shown on the right.  Figure 1. The deep learning pipeline that fetches and creates training data for LULC modeling on the cloud. It can be scaled up with our current open-sourced and cloud-based pipeline Chip n’ Scale. •Forthetraining dataset generation, weremoved too cloudy scenes, and data was saved as eopatches.Astacked numpyndarrayattached with spatial information. We went through:–Check the ratio of the valid data for each patch and for each time frame–Keep only time frames with > 99% valid coverage (no clouds)•Concatenate BAND, NDVI, NDWI, NDBIinfo into a single feature called FEATURES•Perform temporal interpolation (filling gaps and resampling to the same dates)–Create a task for linear interpolation in the temporal dimension–Provide the cloud mask to tell the interpolating function which values to update•Perform erosion–This removes artefacts with a width of\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nSatellite imagery can be outdated and inaccurate, particularly in developing countries. We collaborated with the European Space Agency (ESA) to develop a Land Use Land Cover (LULC) deep learning workflow on the cloud that can process Sentinel-2 optical imagery for large-scale LULC change detection. Sentinel-2 offers high temporal and spatial resolutions, is openly licensed, and can be freely downloaded from ESA or other service providers.\n\nOur LULC workflow, called Deep LULC, aims to create automated, accurate, fast, and scalable LULC maps to support decision-making around natural resource management and urban resilience, especially in developing countries. The workflow consists of three steps:\n\n1. Generating training data\n2. Training deep learning models on the cloud\n3. Predicting LULC over a new area of interest (AOI)\n\nThe Deep LULC workflow is an end-to-end solution that sits on top of two comprehensive tools: SentinelHub and eo-learn. SentinelHub is a cloud-based GIS platform for distributing, managing, and analyzing satellite data, while eo-learn is an earth observation processing framework for machine learning in Python. Deep LULC seamlessly links earth observation data with machine learning and has a dynamic U-Net architecture that allows users to train a LULC model quickly.\n\nDeep LULC takes in labeled LULC and associated AOI in shapefiles, fetches cloud-free, time-series imagery stacks within a defined time interval, and pairs the satellite imagery with its labeled LULC mask for supervised deep learning model training on the cloud. We use the Dynamic U-Net from Fast.ai for model training, which allows users to swap in various models as the U-Net encoder. Once a well-performing model is trained, it can be exported as a TensorFlow or PyTorch serving docker image to work with our cloud-based model inference pipeline, Chip n' Scale.\n\nChip n' Scale is an open-source package created by Development Seed that helps users run machine learning models over satellite imagery at scale on the cloud. The inference pipeline can automatically scale with the number of images to be processed.\n\nWe acknowledge the support of ESA for this work. Land, forests, and water are intimately connected to how people live, and changes in land use are heavily influenced by human activities (e.g., agriculture, deforestation, human settlement expansion) and have been a significant source of greenhouse gas emissions. Sustainable forest and land management practices vary from region to region, making flexible and scalable tools critical. With these tools, we can empower analysts, engineers, and decision-makers to identify areas where contributions to climate-smart agricultural, forestry, and urban resilience programs can be made.\n\nOur pipeline, written in Jupyter Notebook, is open-sourced under eo-learn examples. Compared to traditional tree-based and machine learning supervised learning algorithms (e.g., Random Forest, Support Vector Machine, and XGBoost), the Deep LULC method is more sensitive to class imbalance. However, once a good-performing model is trained and deployed on cloud GPU machines, a deep learning LULC workflow is more scalable.\n\nFigure 2 shows the pipeline fetching training data, Sentinel-2 optical imagery, and labeled 10-class LULC for an AOI in Slovenia. A U-Net using ResNet50 as the encoder was trained, and the model prediction was done over a new area, with the LULC classification shown on the right.\n\nFor training dataset generation, we removed cloudy scenes and saved the data as eopatches. We performed the following steps:\n\n- Checked the ratio of valid data for each patch and time frame\n- Kept only time frames with > 99% valid coverage (no clouds)\n- Concatenated BAND, NDVI, NDWI, and NDBI information into a single feature called FEATURES\n- Performed temporal interpolation (filling gaps and resampling to the same dates)\n- Created a task for linear interpolation in the temporal dimension\n- Provided a cloud mask to tell the interpolating function which values to update\n- Performed erosion to remove artefacts with a width of"
}