{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"ely but efficiently approximate these processes are a leading source of uncertainty in long-term projected warming and precipitation patterns. Machine Learning (ML)-based parameterizations have long been hailed as a promising alter- native with the potential to yield higher accuracy at a fraction of the cost of more explicit simulations. However, these ML variants are often unpredictably unstable and inaccurate in coupled testing (i.e. in a downstream hybrid simulation task where they are dynamically interacting with the large-scale climate model). These issues are exacerbated in out-of-distribution climates. Certain design decisions such as “climate-invariant\" feature transformation for moisture inputs, input vector expansion, and temporal history incorporation have been shown to improve coupled performance, but they may be insufficient for coupled out-of-distribution general- ization. If feature selection and transformations can inoculate hybrid physics-ML climate models from non-physical, out-of-distribution extrapolation in a chang- ing climate, there is far greater potential in extrapolating from observational data. Otherwise, training on multiple simulated climates becomes an inevitable neces- sity. While our results show generalization benefits from these design decisions, the obtained improvment does not sufficiently preclude the necessity of using multi-climate simulated training data. 1 Introduction and Motivation Anthropogenic climate change is increasing the frequency and severity of climate extremes and natural disasters, requiring informed adaptation and mitigation measures from policymakers ( 1;2;3). While domain scientists continue to achieve notable progress in improving our climate physics understanding, significant uncertainty in projected warming and precipitation patterns remains. Much of this uncertainty stems from the intractable computational expense of explicitly resolving subgrid processes like convection and radiation, making cheaper conventional parameterizations that approximate their effects necessary ( 1;4). Even if hardware advancements continue at the pace of Moore’s Law, it would take decades to be able to run global climate simulations that resolve the turbulent eddies responsible for low cloud formation, a major source of uncertainty in projected warming (5). Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.Neural network parameterizations could be trained on more explicit simulations to emulate unresolved subgrid processes, enabling a higher fidelity representation using current-generation hardware ( 6; 7;8;9;10;11). However, the task of parameterizing subgrid physics (in our case convection and radiation) becomes stubbornly difficult when these neural network emulators are coupled to the large-scale climate model and integrated in time. Because coupled behavior is highly variable, large-scale coupled tests are necessary for drawing conclusions on surrogate model design decisions (12). Based on proven coupled in-distribution benefits ( 12) and using large-scale coupled tests on an out-of-distribution climate, we rigorously test generalization improvement of the following three design decisions: 1.Using a relative humidity “climate-invariant\" feature transformation for the moisture input (13). 2. Expanding the input vector to address potential omitted variable bias (12) 3. Incorporating memory effects (i.e. temporal history) in the input (14; 12) Our results show that these design decisions improve generalization on an out-of-distribution climate relative to our baseline neural network configuration, but they are not sufficient to supplant multi- climate training, something that is argued necessary in previous works (15; 16). 2 Methods 2.1 Reference Climate Simulation Our neural networks are trained on and validated against the Super-Parameterized Community Atmosphere Model v3 (SPCAM 3), which has served as a test-bed of for prototyping neural network emulators of subgrid convection in previous works ( 7;17;18;13;19). In super-parameterization, a high-fidelity, 2D model of convection called a Cloud-Resolving Model (CRM) with 32 columns at a 4-km horizontal resolution is embedded inside each grid-cell of the host climate model ( 20;21;22). For simplicity, we use a fixed season, prescribed sea surface temperatures, and a zonally-symmetric aquaplanet. The timestep is fixed to 30 minutes and 30 vertical levels are considered within each grid cell. Using SPCAM 3, we create two reference simulations, with one having prescribed sea surface temperatures that are 4K warmer. All hybrid-ML climate models are trained using the colder climate and coupled in both settings. 2.2 Neural Network Configurations To assess the generalization benefits of our design decisions, we train and evaluate 330 neural networks for each design decision and each of the following configurations. The Specific Humidity (SH) Configuration is a baseline similar to previous work ( 17). The Relative Humidity (RH) Configuration uses a “climate-invariant\" relative humidity feature transformation for the moisture input variable. The Expanded Variables (EV) Configuration concatenates meridional wind, ozone mixing ratio, and cosine of zenith angle to the input variables of the RH configuration. Finally, the Previous Tendencies (PT) Configuration concatenates heating\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nApproximating subgrid processes is a leading source of uncertainty in long-term projected warming and precipitation patterns. Machine learning (ML)-based parameterizations have been proposed as a promising alternative to yield higher accuracy at a lower cost than explicit simulations. However, these ML variants are often unstable and inaccurate in coupled testing, where they interact with large-scale climate models. This issue is exacerbated in out-of-distribution climates. Certain design decisions, such as \"climate-invariant\" feature transformation for moisture inputs, input vector expansion, and temporal history incorporation, have been shown to improve coupled performance but may be insufficient for out-of-distribution generalization.\n\nIf feature selection and transformations can protect hybrid physics-ML climate models from non-physical, out-of-distribution extrapolation in a changing climate, there is potential for extrapolating from observational data. Otherwise, training on multiple simulated climates becomes necessary. Our results show that generalization benefits from these design decisions, but the improvement is not sufficient to preclude the necessity of using multi-climate simulated training data.\n\nIntroduction and Motivation\n\nAnthropogenic climate change is increasing the frequency and severity of climate extremes and natural disasters, requiring informed adaptation and mitigation measures from policymakers. While significant progress has been made in improving climate physics understanding, uncertainty in projected warming and precipitation patterns remains. Much of this uncertainty stems from the computational expense of explicitly resolving subgrid processes like convection and radiation, making cheaper conventional parameterizations necessary. Even with continued hardware advancements, it would take decades to run global climate simulations that resolve turbulent eddies responsible for low cloud formation, a major source of uncertainty in projected warming.\n\nTackling Climate Change with Machine Learning: workshop at NeurIPS 2023\n\nNeural network parameterizations could be trained on more explicit simulations to emulate unresolved subgrid processes, enabling a higher fidelity representation using current-generation hardware. However, parameterizing subgrid physics becomes difficult when these neural network emulators are coupled to the large-scale climate model and integrated in time. Large-scale coupled tests are necessary for drawing conclusions on surrogate model design decisions.\n\nBased on previous in-distribution benefits and using large-scale coupled tests on an out-of-distribution climate, we rigorously test generalization improvement of the following design decisions:\n\n1. Using a relative humidity \"climate-invariant\" feature transformation for the moisture input.\n2. Expanding the input vector to address potential omitted variable bias.\n3. Incorporating memory effects (i.e., temporal history) in the input.\n\nOur results show that these design decisions improve generalization on an out-of-distribution climate relative to our baseline neural network configuration, but they are not sufficient to supplant multi-climate training.\n\nMethods\n\n2.1 Reference Climate Simulation\n\nOur neural networks are trained on and validated against the Super-Parameterized Community Atmosphere Model v3 (SPCAM 3), which has served as a test-bed for prototyping neural network emulators of subgrid convection. In super-parameterization, a high-fidelity, 2D model of convection is embedded inside each grid-cell of the host climate model. For simplicity, we use a fixed season, prescribed sea surface temperatures, and a zonally-symmetric aquaplanet. The timestep is fixed to 30 minutes and 30 vertical levels are considered within each grid cell. We create two reference simulations, with one having prescribed sea surface temperatures that are 4K warmer. All hybrid-ML climate models are trained using the colder climate and coupled in both settings.\n\n2.2 Neural Network Configurations\n\nTo assess the generalization benefits of our design decisions, we train and evaluate 330 neural networks for each design decision and each of the following configurations. The Specific Humidity (SH) Configuration is a baseline similar to previous work. The Relative Humidity (RH) Configuration uses a \"climate-invariant\" relative humidity feature transformation for the moisture input variable. The Expanded Variables (EV) Configuration concatenates meridional wind, ozone mixing ratio, and cosine of zenith angle to the input variables of the RH configuration. Finally, the Previous Tendencies (PT) Configuration concatenates heating tendencies to the input variables."
}