{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"ular supply chain data. As a first-order approximation, standard reports use Economic Input-Output based Life Cycle Assessment (EIO-LCA) which estimates carbon emissions per dollar at an industry sector level using transactions between different parts of the economy. For EIO-LCA, an expert needs to map each product to one of upwards of 1000 potential industry sectors. We present CaML, an algorithm to automate EIO-LCA using semantic text similarity matching by leveraging the text descrip- tions of the product and the industry sector. CaML outperforms the previous man- ually intensive method, yielding a MAPE of 22% with no domain labels. 1 I NTRODUCTION Figure 1: CaML uses semantic text similarity to estimate CO 2eemissions with EIO-LCA. Household products and services contribute to 60% of greenhouse gas emissions Ivanova et al. (2016). Life Cycle Assessment (LCA) is a scientific framework that is used to estimate environmen- tal CO 2eemissions of products starting from raw material extraction to disposal or other end-of-life pathways Hauschild et al. (2018); ISO (2006). To precisely estimate the carbon embodied in a product, we need to know the materials and processes of manufacturing, transport data from manu- facturer to customer, emissions during use such as fuel for a stove, and how the product is disposed. EIO-LCA reduces the effort involved by estimating the aggregate sector-level CO 2eemissions based on the materials and energy use measured through economic transactions Suh (2009); Yang et al. (2017). To assign carbon emissions to a product, we need to find its corresponding industry sector defined by standards such as North American Industry Classification System (NAICS) Krishnan & Press (2003). We consider products sold in the United States (US). The US government publishes the kgCO 2eper dollar estimate for aggregated NAICS codes Ingwersen et al. (2022). Picking from one of 1K +NAICS codes is time consuming. To reduce annotation burden, car- bon footprint reports aggregate products into categories, and then map the category to an industry sector Amazon (2021); Kucukvar et al. (2019). We consider the manual product category mapping based carbon emission estimates as our baseline. Our CaML (carbon assessment with ML) algorithm 1Published as a workshop paper at “Tackling Climate Change with Machine Learning”, ICLR 2023 uses SBERT, a bi-encoder transformer model that generates a vector embedding given a sentence as an input, and uses cosine similarity between sentence embeddings as a measure of semantic similar- ity Reimers & Gurevych (2019). Figure 1 illustrates the CaML algorithm. Appendix A provides an overview of LCA, and summarizes prior works in EIO-LCA automation. To our knowledge, we are the first to study zero-shot ML for EIO-LCA. We open source our code and dataset. 2 C AML M ETHODOLOGY CaML uses the “all-mpnet-base-v2” model from the sentence-transformer library because it gives the best average performance across sentence similarity benchmarks HuggingFace (2022). The model has been trained on 1 billion sentence pairs from a collection of 33 NLP datasets. The model consists of 110M parameters, is of size 420MB, and outputs 768 dimensional embeddings. We use a sentence length of 128 tokens, which translates to about 100 English words; the rest of the sentence is truncated. We include an ablation analysis of our parameter choices in Appendix I. NAICS codes have multiple industries associated with them even at the lowest level in the hierarchy (see Figure D in Appendix). CaML treats each industry description as a separate sentence in our se- mantic matching algorithm. The specificity of the NAICS description helps find improved matches. In total, we have 11623 NAICS sentences. We observe the best performance when we concatenate the detailed industry descriptions with their corresponding BEA title, as we show in Appendix I. Algorithm 1: Pseudocode for CaML Input : product text, naics textlist, eio lcatable Output: product kgCO2e perdollar similarity scores = [] product text = preprocess(product text) product embedding = model(product text) fornaics text in naics textlistdo naics text = preprocess(naics text) naics embedding = model(naics text) similarity scores.append( cosine similarity(naics embedding, product embedding)) naics index = arg max(similarity scores) naics match = naics textlist[naics index] product kgCO2e perdollar = eio lcatable(naics match) Algorithm 1 gives an overview of CaML. Both the product text and NAICS text are fed as inputs to the SBERT model after pre-processing to get their corresponding embeddings. CaML computes the cosine similarity\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy data removed:\n\nThe supply chain data can be approximated using Economic Input-Output based Life Cycle Assessment (EIO-LCA), which estimates carbon emissions per dollar at an industry sector level based on transactions between different parts of the economy. For EIO-LCA, an expert needs to map each product to one of over 1,000 potential industry sectors. We present CaML, an algorithm that automates EIO-LCA using semantic text similarity matching by leveraging the text descriptions of the product and the industry sector.\n\nCaML outperforms the previous manual method, achieving a Mean Absolute Percentage Error (MAPE) of 22% without requiring domain labels. \n\nLife Cycle Assessment (LCA) is a scientific framework used to estimate environmental CO2 emissions of products from raw material extraction to disposal or end-of-life pathways. To precisely estimate the carbon embodied in a product, we need to know the materials and processes of manufacturing, transportation data from manufacturer to customer, emissions during use, and how the product is disposed.\n\nEIO-LCA reduces the effort involved by estimating aggregate sector-level CO2 emissions based on materials and energy use measured through economic transactions. To assign carbon emissions to a product, we need to find its corresponding industry sector defined by standards such as the North American Industry Classification System (NAICS). We consider products sold in the United States, where the government publishes the kg CO2 per dollar estimate for aggregated NAICS codes.\n\nPicking from over 1,000 NAICS codes is time-consuming. To reduce annotation burden, carbon footprint reports aggregate products into categories and then map the category to an industry sector. We consider the manual product category mapping-based carbon emission estimates as our baseline.\n\nOur CaML algorithm uses the SBERT model, a bi-encoder transformer model that generates a vector embedding given a sentence as input, and uses cosine similarity between sentence embeddings as a measure of semantic similarity. The algorithm is illustrated in Figure 1.\n\nCaML uses the \"all-mpnet-base-v2\" model from the sentence-transformer library, which provides the best average performance across sentence similarity benchmarks. The model has been trained on 1 billion sentence pairs from a collection of 33 NLP datasets. We use a sentence length of 128 tokens, which translates to about 100 English words, and truncate the rest.\n\nWe have 11,623 NAICS sentences, each treated as a separate sentence in our semantic matching algorithm. The specificity of the NAICS description helps find improved matches. We observe the best performance when we concatenate the detailed industry descriptions with their corresponding BEA title.\n\nAlgorithm 1 provides an overview of CaML:\n\nInput: product text, NAICS text list, EIO-LCA table\nOutput: product kg CO2 per dollar similarity scores\n\n1. Preprocess the product text and NAICS text.\n2. Get the embeddings for the product text and NAICS text using the SBERT model.\n3. Compute the cosine similarity between the product embedding and each NAICS embedding.\n4. Select the NAICS text with the highest similarity score.\n5. Get the corresponding kg CO2 per dollar value from the EIO-LCA table.\n\nCaML computes the cosine similarity between the product and NAICS embeddings to determine the industry sector and estimate the carbon emissions."
}