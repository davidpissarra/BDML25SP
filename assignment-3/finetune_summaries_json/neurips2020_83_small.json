{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" code describing interactions of the atmosphere, land, oceans, and ice, among other components. As development of the CESM is constantly ongoing, simulation outputs need to be continuously controlled for quality. To be able to distinguish a “climate-changing” modiﬁcation of the code base from a true climate-changing physical process or intervention, there needs to be a principled way of assessing statistical reproducibility that can handle both spatial and temporal high-dimensional simulation outputs. Our proposed work uses probabilistic classiﬁers like tree-based algorithms and deep neural networks to perform a statistically rigorous goodness-of-ﬁt test of high- dimensional spatio-temporal data. 1 Introduction Climate change adaptation has been identiﬁed as one of the two main action items in addressing climate change [ 22]. The main goals in climate change adaptation are to anticipate the consequences of extreme climate events and understand the effects on climate of environmental and man-made changes. In this context, forecasts from climate models are essential for informing adaptation strategies, both at a local and national level (such as the IPCC reports [ 18,19]). Also, climate models can be used to estimate the impact on the climate of a speciﬁc action or policy. In a recent example, scientists managed to estimate the effect of COVID19-related lockdown and travel restrictions on global warming (which turned out to be negligible) using the FaIR v1.5 carbon cycle emulator [24]. Overall, climate models are divided into two categories, General Circulation Models (GCMs) or Earth System Models (ESMs) [ 7]. Within the latter category, the Community Earth System Model (CESM [ 9]) is a state-of-the-art “virtual laboratory” for studying past, present, and future global climate states. Developed mainly at the National Center for Atmospheric Research (NCAR), CESM consists of different simulation components covering various aspects of the climate system, including atmosphere, land, river runoff, land-ice, oceans, and sea-ice. CESM is a fully coupled system, meaning that the differential equations within each component are all solved at the same time by a custom computing architecture [ 3]. About 2,900 academic publications have used CESM and CESM data, and the code base currently contains around 1.5 million lines of code.2 Such high-capacity and complex climate models are in a constant state of development, and frequent checks need to be in place for “quality assurance” [ 17]; that is, to detect and reduce errors which could adversely affect the simulation results and potentially erode the model’s scientiﬁc credibility. \u0003Equal Contribution 2Source: http://www.cesm.ucar.edu/ and Hammerling et al., 2020 Joint Statistical Meeting Tackling Climate Change with Machine Learning workshop at NeurIPS 2020.Figure 1: Schematics of the ECT methodology for quality assurance of climate models. A series of simulations with different initial conditions are run on a “trusted” machine (blue lines) to form a baseline ensemble which deﬁnes the forecast uncertainty (grey area). Test runs (red line) are then evaluated against this initial condition ensemble. The current state-of-the-art is to compress the data ﬁrst by PCA, which may lead to estimation bias and loss of power. In this work, we propose a new testing framework ( HECT ) based on probabilistic classiﬁers that provides diagnostics and allows the data scientist to work directly with high-dimensional spatial and temporal outputs. CESM is a deterministic simulation model, i.e., the output from two simulations are bit-for-bit (BFB) identical if they are run with the same initial conditions and on the same computing infrastructure. However, because of the chaotic nature of the equations underlying the simulation process, running the same code on new machine architecture, or running a tweaked version of the original code expected to return the same results, could produce output that is not BFB identical but still represents the same climate model. How can we make sure that non-BFB identical simulation outputs are a result of this natural variation rather than a “climate-changing” error we introduced in the code? Ensemble consistency testing (ECT, [ 1,15,16]) provides a statistical answer to such question. Figure 1 provides a schematic representation of ECT. Multiple CESM runs are initialized using a “trusted” version of the climate model (in blue), where in each run the initial temperatures are perturbed on the order of O(10\u000014). The ensemble of outputs from these slightly perturbed runs provides a baseline which approximates the natural variability in accepted simulation output (represented by the grey area). This ensemble is contrasted to outputs from a series of “test runs”, i.e. runs from the modiﬁed version of the climate model (in red), and a pass or fail is issued based on the ﬁrst 50 sample PCA scores for global climate variable averages at the last time step of\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThe code describing interactions among the atmosphere, land, oceans, and ice, among other components, requires continuous quality control as the Community Earth System Model (CESM) is constantly being developed. To distinguish between a \"climate-changing\" modification of the code base and a true climate-changing physical process or intervention, a principled way of assessing statistical reproducibility is needed to handle high-dimensional simulation outputs. Our proposed work uses probabilistic classifiers like tree-based algorithms and deep neural networks to perform a statistically rigorous goodness-of-fit test on high-dimensional spatio-temporal data.\n\nClimate change adaptation has been identified as a key action item in addressing climate change. The main goals in climate change adaptation are to anticipate the consequences of extreme climate events and understand the effects on climate of environmental and man-made changes. Climate models are essential for informing adaptation strategies, both at a local and national level, such as the IPCC reports. Climate models can also be used to estimate the impact on the climate of a specific action or policy. For example, scientists used the FaIR v1.5 carbon cycle emulator to estimate the effect of COVID-19-related lockdown and travel restrictions on global warming, which was found to be negligible.\n\nClimate models are divided into two categories: General Circulation Models (GCMs) and Earth System Models (ESMs). The Community Earth System Model (CESM) is a state-of-the-art \"virtual laboratory\" for studying past, present, and future global climate states. CESM consists of different simulation components covering various aspects of the climate system, including atmosphere, land, river runoff, land-ice, oceans, and sea-ice. CESM is a fully coupled system, meaning that the differential equations within each component are solved simultaneously by a custom computing architecture.\n\nCESM has been used in over 2,900 academic publications, and its code base contains around 1.5 million lines of code. Given its high capacity and complexity, frequent checks are necessary for \"quality assurance\" to detect and reduce errors that could affect the simulation results and erode the model's scientific credibility.\n\nTo address this challenge, we propose a new testing framework, HECT, based on probabilistic classifiers that provides diagnostics and allows data scientists to work directly with high-dimensional spatial and temporal outputs. CESM is a deterministic simulation model, meaning that the output from two simulations is bit-for-bit identical if they are run with the same initial conditions and on the same computing infrastructure. However, due to the chaotic nature of the equations underlying the simulation process, running the same code on a new machine architecture or a tweaked version of the original code may produce non-bit-for-bit identical output that still represents the same climate model.\n\nTo determine whether non-bit-for-bit identical simulation outputs are due to natural variation or a \"climate-changing\" error, ensemble consistency testing (ECT) provides a statistical answer. ECT involves initializing multiple CESM runs using a \"trusted\" version of the climate model, where the initial temperatures are perturbed on the order of 10^14. The ensemble of outputs from these slightly perturbed runs provides a baseline that approximates the natural variability in accepted simulation output. This ensemble is contrasted to outputs from a series of \"test runs\" from the modified version of the climate model, and a pass or fail is issued based on the first 50 sample PCA scores for global climate variable averages at the last time step."
}