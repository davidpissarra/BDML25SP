{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"Joint Global Change Research Institute, Pacific Northwest National Laboratory, College Park, MD Abstract The Global Change Analysis Model (GCAM) simulates complex interactions between the coupled Earth and human systems, providing valuable insights into the co-evolution of land, water, and energy sectors under different future scenarios. Understanding the sensitivities and drivers of this multisectoral system can lead to more robust understanding of the different pathways to particular outcomes. The interactions and complexity of the coupled human-Earth systems make GCAM simulations costly to run at scale - a requirement for large ensemble experiments which explore uncertainty in model parameters and outputs. A differentiable emulator with similar predictive power, but greater efficiency, could provide novel scenario discovery and analysis of GCAM and its outputs, requiring fewer runs of GCAM. As a first use case, we train a neural network on an existing large ensemble that explores a range of GCAM inputs related to different relative contributions of energy production sources, with a focus on wind and solar. We complement this existing ensemble with interpolated input values and a wider selection of outputs, predicting 22,528GCAM outputs across time, sectors, and regions. We report a median R2score of 0.998for the emulator’s predictions and an R2score of 0.812 for its input-output sensitivity. 1 Introduction and Background The global change problem involves both Earth and human system dynamics, interacting and creating feedbacks among the multiple components and sectors that make up the whole system. The Global Change Analysis Model (GCAM) [ 2,3] and other models of the same class are essential to represent the future evolution of the human system, including socioeconomic, land, energy, and water sectors, giving rise to future plausible and coherent scenarios of emissions. These scenarios are in turn used as drivers of Earth system model projections. In the opposite direction, climate output from Earth system models is used to model impacts in GCAM and other integrated multi-sector models. This work focuses on emulating GCAM specifically; it is an open-source multisector dynamic model that simulates the integrated, simultaneous evolution of energy, agriculture, land use, water, and climate system components. GCAM simulates global markets segmented into 32 distinct socioeconomic regions, 235 hydrological basins, forming 384 land units from the intersection of basins and regions. Historically, GCAM and comparable models have run a discrete set of “storylines” or representa- tive future scenarios. In contrast, thanks to advances in computational power and analysis tools, exploratory modeling, sampling a much larger set of drivers (and therefore outcomes) has become popular in recent years [ 4,5]. In this approach, large ensembles of scenarios are designed and run Tackling Climate Change with Machine Learning: workshop at NeurIPS 2024.to fill the gaps between the representative storyline scenarios. This approach has been fruitful for exploring the complex sensitivities these models have to assumptions about the systems under test, and the external drivers that determine their outcomes. This understanding of sensitivity and drivers can facilitate identification of pros and cons of different pathways to outcomes of interest (e.g., to minimize water scarcity [ 5]). The ensembles are often designed to incorporate a range of data sources, expert opinion, and discrete parameterizations in a factorial combination [ 18]. However, even with access to modern computing clusters, computational cost hinders a comprehensive exploration of these inputs. We aim to enable this comprehensive exploration via deep learning-based emulation of GCAM. Existing large ensembles provide data to train and evaluate such emulators. Once trained, a high-fidelity emulator can be used to aid our understanding both of the coupled Earth-human systems and their models (e.g., GCAM). For example, an emulator could be used to explore the input (assumption) space, to steer the generation of large GCAM ensembles, or to better characterize model sensitivities. There are two defining aspects to our approach that set it apart from GCAM toward these goals. First, once trained, predicting outcomes for novel scenarios is faster than GCAM by at least three orders of magnitude. Second, the differentiability of the emulation enables efficient search algorithms over the input space. Relatively little work has been done with emulation of integrated, multisector models, but results have been promising [ 17,19]. Here we introduce a high-fidelity emulator of GCAM, both in the predictions and in the input-output sensitivities. 2 Methods 2.1 Data Each scenario of GCAM is shaped by exogenous factors like socioeconomic trends (population and GDP growth), technology costs and performance, historical information, and assumptions about future values of key drivers. These are what we call “inputs” in this paper, and a subset of these will be sampled in our ensembles. GCAM provides a detailed, time-evolving analysis of sectors within the economy and simulates how different external factors might affect specific sectors over time, taking into account the effects from all other sectors; these serve as the outputs of our emulator. Inputs: This paper follows the experiment set\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nThe Joint Global Change Research Institute at the Pacific Northwest National Laboratory in College Park, MD, has developed the Global Change Analysis Model (GCAM). This model simulates the complex interactions between the Earth and human systems, providing valuable insights into the co-evolution of land, water, and energy sectors under different future scenarios. Understanding the sensitivities and drivers of this multisectoral system can lead to a more robust understanding of the different pathways to particular outcomes.\n\nThe interactions and complexity of the coupled human-Earth systems make GCAM simulations costly to run at scale, which is a requirement for large ensemble experiments that explore uncertainty in model parameters and outputs. A differentiable emulator with similar predictive power but greater efficiency could provide novel scenario discovery and analysis of GCAM and its outputs, requiring fewer runs of GCAM.\n\nAs a first use case, we trained a neural network on an existing large ensemble that explores a range of GCAM inputs related to different relative contributions of energy production sources, with a focus on wind and solar. We complemented this existing ensemble with interpolated input values and a wider selection of outputs, predicting 22,528 GCAM outputs across time, sectors, and regions. We report a median R2 score of 0.998 for the emulator's predictions and an R2 score of 0.812 for its input-output sensitivity.\n\nThe global change problem involves both Earth and human system dynamics, interacting and creating feedbacks among the multiple components and sectors that make up the whole system. The Global Change Analysis Model (GCAM) and other models of the same class are essential to represent the future evolution of the human system, including socioeconomic, land, energy, and water sectors, giving rise to future plausible and coherent scenarios of emissions. These scenarios are used as drivers of Earth system model projections.\n\nGCAM is an open-source multisector dynamic model that simulates the integrated, simultaneous evolution of energy, agriculture, land use, water, and climate system components. It simulates global markets segmented into 32 distinct socioeconomic regions, 235 hydrological basins, forming 384 land units from the intersection of basins and regions.\n\nHistorically, GCAM and comparable models have run a discrete set of \"storylines\" or representative future scenarios. In contrast, thanks to advances in computational power and analysis tools, exploratory modeling, sampling a much larger set of drivers (and therefore outcomes), has become popular in recent years. This approach has been fruitful for exploring the complex sensitivities these models have to assumptions about the systems under test, and the external drivers that determine their outcomes.\n\nThe ensembles are often designed to incorporate a range of data sources, expert opinion, and discrete parameterizations in a factorial combination. However, even with access to modern computing clusters, computational cost hinders a comprehensive exploration of these inputs. We aim to enable this comprehensive exploration via deep learning-based emulation of GCAM.\n\nExisting large ensembles provide data to train and evaluate such emulators. Once trained, a high-fidelity emulator can be used to aid our understanding both of the coupled Earth-human systems and their models (e.g., GCAM). For example, an emulator could be used to explore the input (assumption) space, to steer the generation of large GCAM ensembles, or to better characterize model sensitivities.\n\nOur approach has two defining aspects that set it apart from GCAM. First, once trained, predicting outcomes for novel scenarios is faster than GCAM by at least three orders of magnitude. Second, the differentiability of the emulation enables efficient search algorithms over the input space.\n\nRelatively little work has been done with emulation of integrated, multisector models, but results have been promising. Here we introduce a high-fidelity emulator of GCAM, both in the predictions and in the input-output sensitivities.\n\nThe data used in this study consists of exogenous factors such as socioeconomic trends (population and GDP growth), technology costs and performance, historical information, and assumptions about future values of key drivers. These are referred to as \"inputs\" in this paper, and a subset of these will be sampled in our ensembles. GCAM provides a detailed, time-evolving analysis of sectors within the economy and simulates how different external factors might affect specific sectors over time, taking into account the effects from all other sectors; these serve as the outputs of our emulator."
}