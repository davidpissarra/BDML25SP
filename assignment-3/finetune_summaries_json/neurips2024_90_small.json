{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" disclosures and sustainability reports in dense text forms, and no systematic, sector and region specific reduction lever libraries are available to companies. This research proposes a multi-agent system leveraging Large Language Models (LLMs) integrated with Retrieval-Augmented Generation (RAG) to systematically extract, classify, and validate carbon reduction actions from publicly available sustainability reports. By constructing a standardized database of reduction levers categorized by industry, geography, and greenhouse gas scopes, this work empowers companies to prioritize high-impact, cost-effective emissions reduction strategies. We plan to integrate environmentally-extended input-output models to ensure that these actions are closely tied to sector-specific emissive sources, increasing their relevance and scala- bility. This initiative is expected to support companies in mitigating greenhouse gas emissions by offering a practical resource that accelerates the transition to a low- carbon economy, and makes actionable insights readily available to corporations, industry and the research community. 1 Introduction Over 9,000 companies, including more than half of the Fortune 2,000 companies, have pledged to go net zero by mid-century [1]. As companies strive to achieve these goals, the need for actionable, data-driven strategies to reduce greenhouse gas (GHG) emissions is increasing. Despite numerous publications on mitigation strategies (e.g. from IEA [2], IPCC [3], US EPA[4]), a comprehensive, standardized database of feasible actions is still lacking. Existing carbon reduction frameworks like Project Drawdown [5] for example, though valuable, often overlook regional feasibility and lack guidance on prioritizing high-impact strategies based on the emissive sources within each sector. Having access to transparent, sector- and geography-specific data on successful corporate emissions reductions initiatives is critical. While this information is often included in public sustainability reports and other disclosures, it is typically buried within long-form text, tables, or figures. Other ∗varsha@watershedclimate.com †sangwon@watershedclimate.com Tackling Climate Change with Machine Learning: workshop at NeurIPS 2024.entities like GHG Protocol [6] and Science-Based Targets Initiative (SBTi) [7] also provide sector- specific guidance on carbon emissions reduction, but the non-standardized representation makes it hard to quickly extract and compare actionable insights across companies and sectors. This work aims to address this challenge by creating a standardized dataset of carbon emissions reduction levers, categorized by industry sector and geography, and validated against environmentally- extended input output models [8]. This dataset will be organized by emissive source, GHG scopes, and associated quantitative metrics, allowing actions to be ranked by impact. Using pre-trained Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) techniques, our system will autonomously extract and classify reduction actions from publicly available sustainability reports to build this dataset. The dataset will help prioritize high-impact strategies and provide a practical tool for driving reductions. 2 Proposed framework Multi-agent LLM system  Sustainability  reports Extracted text   from reports  Database of sector,  source-speciﬁc  carbon emissions  reduction actions  Ranking  actions based  on quantitative  metrics IPCC emissive source  category from USEEIO  Text extraction  LLM-agent for  summarization of  actions Database of actions  and metadata  Project drawdown climate  solutions  LLM-agent for  context-aware  classification  Human-in-the-loop  development and  validation  Figure 1: Multi-agent LLM system for creating a carbon emissions reduction database. 2.1 Extraction pipeline The overall framework is described in Figure 1. The first step involves extracting relevant text from a list of publicly available sustainability and ESG reports. We propose using traditional text extraction and cleaning methods (e.g. Tesseract OCR) for this step. The next agent will then classify these chunks of text and summarize extracted information into actionable climate solutions. We propose using transformers such as Anthropic’s Claude 3.5 Sonnet [9], or OpenAI’s GPT models [10] or BART[11] to perform context-aware text classification and summarization. The actions will be structured it into a comprehensive knowledge database, including key metadata such as industrial sector, associated North American Industry Classification System (NAICS) code, and geography. Validation of extracted actions will be done by domain experts reviewing a random sample of actions. Domain experts will also help craft prompts to guide the summarization process to ensure alignment with sustainability best practices. We will also evaluate incorporating ClimateBERT [12], a model specifically trained on climate-related texts to enhance the accuracy of extracted actions. 2.2 Categorizing actions into emissive sources To equip companies with the tools to better understand effective strategies to reduce sector-specific emissions, we will use an LLM-agent to classify each action extracted from sustainability reports into a taxonomy of emissive sources. This agent will be refined on some domain specific information such as IPCC’s classification of over 200 emissions sources [13, 14] which forms the basis for the taxonomy. Examples of source category includes N 2O emissions\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and data removed:\n\nDisclosures and sustainability reports often contain dense text, and there is a lack of systematic, sector- and region-specific reduction lever libraries available to companies. This research proposes a multi-agent system that leverages Large Language Models (LLMs) integrated with Retrieval-Augmented Generation (RAG) to systematically extract, classify, and validate carbon reduction actions from publicly available sustainability reports. By constructing a standardized database of reduction levers categorized by industry, geography, and greenhouse gas scopes, this work empowers companies to prioritize high-impact, cost-effective emissions reduction strategies. The system will integrate environmentally-extended input-output models to ensure that these actions are closely tied to sector-specific emissive sources, increasing their relevance and scalability.\n\nThis initiative aims to support companies in mitigating greenhouse gas emissions by offering a practical resource that accelerates the transition to a low-carbon economy and makes actionable insights readily available to corporations, industry, and the research community. Over 9,000 companies, including more than half of the Fortune 2,000 companies, have pledged to go net zero by mid-century. As companies strive to achieve these goals, the need for actionable, data-driven strategies to reduce greenhouse gas (GHG) emissions is increasing. Despite numerous publications on mitigation strategies, a comprehensive, standardized database of feasible actions is still lacking.\n\nExisting carbon reduction frameworks, such as Project Drawdown, though valuable, often overlook regional feasibility and lack guidance on prioritizing high-impact strategies based on the emissive sources within each sector. Having access to transparent, sector- and geography-specific data on successful corporate emissions reductions initiatives is critical. While this information is often included in public sustainability reports and other disclosures, it is typically buried within long-form text, tables, or figures. Other entities, such as the GHG Protocol and the Science-Based Targets Initiative, provide sector-specific guidance on carbon emissions reduction, but the non-standardized representation makes it hard to quickly extract and compare actionable insights across companies and sectors.\n\nThis work aims to address this challenge by creating a standardized dataset of carbon emissions reduction levers, categorized by industry sector and geography, and validated against environmentally-extended input-output models. This dataset will be organized by emissive source, GHG scopes, and associated quantitative metrics, allowing actions to be ranked by impact. Using pre-trained Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) techniques, our system will autonomously extract and classify reduction actions from publicly available sustainability reports to build this dataset.\n\nThe dataset will help prioritize high-impact strategies and provide a practical tool for driving reductions. The proposed framework is described in Figure 1. The first step involves extracting relevant text from a list of publicly available sustainability and ESG reports using traditional text extraction and cleaning methods. The next agent will then classify these chunks of text and summarize extracted information into actionable climate solutions using transformers such as Anthropic's Claude 3.5 Sonnet or OpenAI's GPT models.\n\nThe actions will be structured into a comprehensive knowledge database, including key metadata such as industrial sector, associated North American Industry Classification System (NAICS) code, and geography. Validation of extracted actions will be done by domain experts reviewing a random sample of actions. Domain experts will also help craft prompts to guide the summarization process to ensure alignment with sustainability best practices. We will also evaluate incorporating ClimateBERT, a model specifically trained on climate-related texts, to enhance the accuracy of extracted actions.\n\nTo equip companies with the tools to better understand effective strategies to reduce sector-specific emissions, we will use an LLM-agent to classify each action extracted from sustainability reports into a taxonomy of emissive sources. This agent will be refined on some domain-specific information, such as the IPCC's classification of over 200 emissions sources, which forms the basis for the taxonomy. Examples of source categories include N2O emissions.\n\nFigure 1: Multi-agent LLM system for creating a carbon emissions reduction database.\n\n2.1 Extraction pipeline\n\nThe overall framework is described in Figure 1. The first step involves extracting relevant text from a list of publicly available sustainability and ESG reports. The next agent will then classify these chunks of text and summarize extracted information into actionable climate solutions. We propose using transformers such as Anthropic's Claude 3.5 Sonnet or OpenAI's GPT models for this step.\n\n2.2 Categorizing actions into emissive sources\n\nTo equip companies with the tools to better understand effective strategies to reduce sector-specific emissions, we will use an LLM-agent to classify each action extracted from sustainability reports into a taxonomy of emissive sources. This agent will be refined on some domain-specific information, such as the IPCC's classification of over 200 emissions sources, which forms the basis for the taxonomy. Examples of source categories include N2O emissions."
}