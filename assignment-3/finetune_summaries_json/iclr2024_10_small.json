{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" Seasonal forecasting is a crucial task when it comes to detecting the extreme heat and colds that occur due to climate change. Confidence in the predictions should be reliable since a small increase in the temperatures in a year has a big im- pact on the world. Calibration of the neural networks provides a way to ensure our confidence in the predictions. However, calibrating regression models is an under-researched topic, especially in forecasters. We calibrate a UNet++ based ar- chitecture, which was shown to outperform physics-based models in temperature anomalies. We show that with a slight trade-off between prediction error and cal- ibration error, it is possible to get more reliable and sharper forecasts. We believe that calibration should be an important part of safety-critical machine learning applications such as weather forecasters. 1 I NTRODUCTION Seasonal forecasting is a crucial task when it comes to foreseeing the effects of climate change, especially in making predictions and decisions based on these effects. Generating accurate seasonal and sub-seasonal forecasts demands substantial resources, such as the curation of Coupled Model Intercomparison Projects (CMIP) datasets. These datasets combine outputs from over a hundred climate models worldwide, facilitating top-tier climate simulations. Leveraging the vast data reser- voirs from CMIP6 (Eyring et al., 2016), the latest phase of CMIP, there are ongoing efforts to harness deep learning methodologies for enhanced climate forecasting. For instance, Luo et al. (2022) use Bayesian Neural Networks (BNN) with CMIP6 for climate prediction in the North Atlantic, and Anochi et al. (2021) use CMIP6 to assess precipitation. Andersson et al. (2021) forecast the change in Arctic sea ice area with the same dataset. In this work, we also utilize the CMIP6 dataset to produce well-calibrated and sharp forecasts which are crucial for climate sciences (Gneiting et al., 2007). We expand the capabilities of the forecast model introduced in Unal et al. (2023) using the cali- bration approach proposed by Kuleshov et al. (2018). This model is shown to achieve better perfor- mance than physics-based methods on sub-seasonal forecasting, especially at predicting temperature anomalies that indicate extreme hot and cold temperatures that are crucial for climate change. In this work, we calibrate the Bayesian version of the forecaster in a regression setting. We show that the BNNs produce the most calibrated and sharp forecasts. We compare the performance of BNNs, Monte Carlo Dropout (MC-Dropout) Gal & Ghahramani (2016), and Deep Ensemble Lakshmi- narayanan et al. (2017) methods for assessing climate forecast uncertainty and sharpness, exploring the potential for improved reliability through calibration. Our contributions can be listed as follows: 1. We apply calibration to a sub-seasonal forecaster that is able to predict extreme events better than simulations. We show that calibrating deep learning models should be a crucial step while applying deep learning to climate sciences. ∗Corresponding author: asan18@itu.edu.tr 1Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024 2. We show that well-calibrated forecasters not only produce better confidence intervals but may also improve the sharpness of the forecasts. 3. This method may be generalized to any other application in climate sciences that gives critical importance to the reliability of the results such as extreme events, precipitation, and natural disasters such as earthquakes, floods, and drought. 2 M ETHODOLOGY We formulate the problem as predicting the monthly average air temperature at 2 meters above the earth surface ( 2m) for each coordinate in a 2D temperature grid which we will name as the temperature map. Our aim is to construct a reliable confidence interval for each coordinate since Bayesian methods often produce uncalibrated results Kuleshov et al. (2018). We first train the model on CMIP6 climate simulations, then fine-tune it with ERA5 reanalysis data based on real climate measurements. We denote the 2D temperature map at time tasxt. Train set D={Xt, Yt}T t=1consists of stacked monthly time-series temperature maps as the input. The input Xtrefers to xt−1:t−k−mwhich denotes the range of the stacked months and Ytcorresponds to xt. The periodical month selection process from the given range is described in Unal et al. (2023) and the same setting is used to make a fair comparison. 2.1 B AYESIAN UN ET++FOR TEMPERATURE PREDICTION For temperature forecasting, we convert UNet++ into a BNN (Goan & Fookes, 2020). BNNs are highly regarded for their capability in quantifying uncertainty, offering robust insights into predictive models Kristi\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nSeasonal forecasting is a crucial task for detecting extreme heat and cold events caused by climate change. The reliability of predictions is essential, as even small temperature increases can have a significant impact on the world. Calibration of neural networks is a way to ensure confidence in predictions. However, calibrating regression models is an under-researched area, particularly in the field of forecasting. We calibrate a UNet++ architecture, which has been shown to outperform physics-based models in temperature anomaly prediction. Our results demonstrate that a trade-off between prediction error and calibration error can lead to more reliable and sharper forecasts. We believe that calibration should be an essential part of safety-critical machine learning applications, such as weather forecasting.\n\nIntroduction:\nSeasonal forecasting is a critical task for predicting the effects of climate change, particularly in making informed decisions based on these effects. Generating accurate seasonal and sub-seasonal forecasts requires significant resources, including the curation of Coupled Model Intercomparison Projects (CMIP) datasets. These datasets combine outputs from over a hundred climate models worldwide, enabling high-quality climate simulations. Leveraging the vast data from CMIP6 (Eyring et al., 2016), the latest phase of CMIP, researchers are exploring deep learning methodologies for enhanced climate forecasting. For instance, Luo et al. (2022) used Bayesian Neural Networks (BNN) with CMIP6 for climate prediction in the North Atlantic, while Anochi et al. (2021) used CMIP6 to assess precipitation. Andersson et al. (2021) forecasted the change in Arctic sea ice area using the same dataset. In this work, we utilize the CMIP6 dataset to produce well-calibrated and sharp forecasts, which are essential for climate science (Gneiting et al., 2007). We build upon the forecast model introduced in Unal et al. (2023) using the calibration approach proposed by Kuleshov et al. (2018). This model has been shown to achieve better performance than physics-based methods on sub-seasonal forecasting, particularly in predicting temperature anomalies that indicate extreme hot and cold temperatures critical for climate change. We calibrate the Bayesian version of the forecaster in a regression setting and demonstrate that BNNs produce the most calibrated and sharp forecasts.\n\nOur contributions can be summarized as follows:\n\n1. We apply calibration to a sub-seasonal forecaster that outperforms simulations in predicting extreme events. We emphasize the importance of calibrating deep learning models in climate science.\n2. We show that well-calibrated forecasters not only produce better confidence intervals but also improve the sharpness of forecasts.\n3. This method can be generalized to other climate science applications that require reliable results, such as extreme events, precipitation, and natural disasters like earthquakes, floods, and droughts.\n\nMethodology:\nWe formulate the problem as predicting the monthly average air temperature at 2 meters above the earth's surface for each coordinate in a 2D temperature grid, which we call the temperature map. Our goal is to construct a reliable confidence interval for each coordinate, as Bayesian methods often produce uncalibrated results (Kuleshov et al., 2018). We first train the model on CMIP6 climate simulations and then fine-tune it with ERA5 reanalysis data based on real climate measurements. We denote the 2D temperature map at time t as Xt. The training set D = {Xt, Yt}T t=1 consists of stacked monthly time-series temperature maps as the input. The input Xt refers to xt−1:t−k−m, which denotes the range of stacked months, and Yt corresponds to xt. The periodical month selection process is described in Unal et al. (2023) and is used to ensure a fair comparison.\n\nBayesian UNet++ for Temperature Prediction:\nFor temperature forecasting, we convert UNet++ into a BNN (Goan & Fookes, 2020). BNNs are highly regarded for their ability to quantify uncertainty, providing robust insights into predictive models (Kristi)."
}