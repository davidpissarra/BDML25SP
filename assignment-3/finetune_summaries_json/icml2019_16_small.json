{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"- ing (1) the loss function or (2) the architecture of the network itself. Applied to the emulation of explicitly-resolved cloud processes in a prototype multi-scale climate model, we show that archi- tecture constraints can enforce conservation laws to satisfactory numerical precision, while all con- straints help the neural-network better generalize to conditions outside of its training set, such as global warming. 1. Motivation The largest source of uncertainty in climate projections is the response of clouds to warming ( 12). The turbulent eddies generating clouds are typically only O(100m\u000010km) - wide, meaning that climate models need to be run at spatial resolutions as ﬁne as O(1km) to prevent large biases. Un- fortunately, computational resources currently limit climate models to spatial resolutions of O(25km) when run for time periods relevant to societal decisions, e.g. 100 years ( 7). Therefore, climate models rely on semi-empirical models of cloud processes, referred to as convective parametrizations (14;13). If designed by hand, convective parametrizations are unable to capture the complexity of cloud processes and cause well-known biases, including a lack of extreme precipitation events and unrealistic cloud structures (5; 4). 1Department of Earth System Science, University of Cal- ifornia, Irvine, CA, USA2Department of Earth and Envi- ronmental Engineering, Columbia University, New York, NY, USA3Meteorological Institute, Ludwig-Maximilian-University, Munich, Germany. Correspondence to: Tom Beucler <tom.beucler@gmail.com>.Recent advances in statistical learning offer the possibil- ity of designing data-driven convective parametrizations by training algorithms on short-period but high-resolution cli- mate simulations ( 6). The ﬁrst attempts have successfully modeled the interaction between small-scale clouds and the large-scale climate, offering a pathway to improve the ac- curacy of climate predictions ( 2;11;9). However, machine learning-based climate models do not intrinsically conserve energy and mass, which is a major obstacle to their adoption by the physical science community for several reasons, e.g.: 1) Realistic simulations of climate change respond to rel- atively smallO\u0000 1W m\u00002\u0001 radiative forcing from carbon dioxide. Inconsistencies of this magnitude can prevent this small forcing from being communicated down to the surface and the ocean where most of the biomass lives. 2) Artiﬁcial sources and sinks of mass and energy distort weather and cloud formation on short timescales, resulting in large temperature and humidity drifts or biases for the long-term climate. Current machine-learning convective parametrizations that conserve energy are based on decision trees (e.g. random forests), but these are too slow for practical use in climate models ( 10). Since neural-network convective parametriza- tions can signiﬁcantly reduce cloud biases in climate mod- els while decreasing their overall computational cost ( 11), we ask: How can we enforce conservation laws in neural- network emulators of physical models? After proposing two methods to enforce physical constraints in neural network models of physical systems in Section 2, we apply them to emulate cloud processes in a climate model in Section 3, before comparing their performances and how they improve climate predictions in Section 4. 2. Theory Consider a physical system represented by a function f: Rm7!Rpthat maps an input x2Rmto an output y2Rp: y=f(x): (1) Many physical systems satisfy exact physical constraints, such as the conservation of energy or momentum. In this paper, we assume that these physical constraints (C)can beAchieving Conservation of Energy in Neural Network Emulators for Climate Modeling written as an under-determined linear system of rank n: (C)def=\u001a C\u0014x y\u0015 = 0\u001b ; (2) whereC2Rn\u0002Rm+pis a constraints matrix acting on the input and output of the system. The physical system has nconstraints, and by construction, n<p +m. Our goal is to build a computationally-efﬁcient emulator of the physical systemfand its physical constraints (C). For the sake of simplicity, we build this emulator using a feed-forward neural network (NN) trained on preexisting measurements ofxandy, as shown in Figure 1. We measure the quality of Figure 1. Standard feed-forward conﬁguration (NN) (NN) using the mean-squared error, deﬁned as: MSE (y;yNN)def=ky\u0000yNNkdef=1 ppX i=1(yi\u0000yNN;i)2; (3) whereyNNis the neural network’s output and ythe “truth”. Our reference case, referred to as “unconstrained neural network” (NNU), optimizes (\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nThe loss function or the architecture of the network itself can be modified. Applied to the emulation of explicitly-resolved cloud processes in a prototype multi-scale climate model, we show that architecture constraints can enforce conservation laws to satisfactory numerical precision, while all constraints help the neural-network better generalize to conditions outside of its training set, such as global warming.\n\n1. Motivation\n\nThe largest source of uncertainty in climate projections is the response of clouds to warming (12). The turbulent eddies generating clouds are typically only O(100m to 10km) wide, meaning that climate models need to be run at spatial resolutions as fine as O(1km) to prevent large biases. Unfortunately, computational resources currently limit climate models to spatial resolutions of O(25km) when run for time periods relevant to societal decisions, e.g., 100 years (7). Therefore, climate models rely on semi-empirical models of cloud processes, referred to as convective parametrizations (14, 13). If designed by hand, convective parametrizations are unable to capture the complexity of cloud processes and cause well-known biases, including a lack of extreme precipitation events and unrealistic cloud structures (5, 4).\n\nRecent advances in statistical learning offer the possibility of designing data-driven convective parametrizations by training algorithms on short-period but high-resolution climate simulations (6). The first attempts have successfully modeled the interaction between small-scale clouds and the large-scale climate, offering a pathway to improve the accuracy of climate predictions (2, 11, 9). However, machine learning-based climate models do not intrinsically conserve energy and mass, which is a major obstacle to their adoption by the physical science community for several reasons, e.g.:\n\n1. Realistic simulations of climate change respond to relatively small O(1W/m^2) radiative forcing from carbon dioxide. Inconsistencies of this magnitude can prevent this small forcing from being communicated down to the surface and the ocean where most of the biomass lives.\n2. Artificial sources and sinks of mass and energy distort weather and cloud formation on short timescales, resulting in large temperature and humidity drifts or biases for the long-term climate.\n\nCurrent machine-learning convective parametrizations that conserve energy are based on decision trees (e.g., random forests), but these are too slow for practical use in climate models (10). Since neural-network convective parametrizations can significantly reduce cloud biases in climate models while decreasing their overall computational cost (11), we ask: How can we enforce conservation laws in neural-network emulators of physical models?\n\nAfter proposing two methods to enforce physical constraints in neural network models of physical systems in Section 2, we apply them to emulate cloud processes in a climate model in Section 3, before comparing their performances and how they improve climate predictions in Section 4.\n\n2. Theory\n\nConsider a physical system represented by a function f: R^m → R^p that maps an input x ∈ R^m to an output y ∈ R^p: y = f(x). (1)\n\nMany physical systems satisfy exact physical constraints, such as the conservation of energy or momentum. In this paper, we assume that these physical constraints (C) can be written as an under-determined linear system of rank n: (C) = Cx - y = 0, (2) where C ∈ R^n × R^m+p is a constraints matrix acting on the input and output of the system. The physical system has n constraints, and by construction, n < p + m. Our goal is to build a computationally-efficient emulator of the physical system f and its physical constraints (C). For the sake of simplicity, we build this emulator using a feed-forward neural network (NN) trained on pre-existing measurements of x and y, as shown in Figure 1.\n\nWe measure the quality of the emulator using the mean-squared error, defined as: MSE(y, yNN) = ||y - yNN||^2 = 1/p ∑[i=1 to p] (yi - yNN,i)^2, (3) where yNN is the neural network's output and y is the \"truth\".\n\nOur reference case, referred to as \"unconstrained neural network\" (NNU), optimizes the loss function (\"."
}