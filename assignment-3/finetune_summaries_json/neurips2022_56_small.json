{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"@concordia.ca Abstract Companies worldwide contribute to climate change, emitting significant amounts of greenhouse gases (GHGs). Yet, most do not report their direct or Scope 1 emissions, resulting in a large data gap in corporate emissions. This study aims to fill this gap by training several decision-tree machine learning models to predict company-level Scope 1 emissions. Our results demonstrate that the Extreme Gradient Boosting and LightGBM models perform best, where the former shows a 19% improvement in prediction error over a benchmark model. Our model is also of reduced complexity and greater computational efficiency; it does not require meta-learners and is trained on a smaller number of features, for which data is more common and accessible compared to prior works. Our features are uniquely chosen based on concepts of environmental pollution in economic theory. Predicting corporate emissions with machine learning can be used as a gap-filling approach, which would allow for better GHG accounting and tracking, thus facilitating corporate decarbonization efforts in the long term. It can also impact representations of a company’s carbon performance and carbon risks, thereby helping to funnel investments towards companies with lower emissions and those making true efforts to decarbonize. 1 Introduction In light of the climate crisis and the significant amounts of greenhouse gases (GHGs) emitted by companies, stakeholders have been pressuring on them to disclose their GHG emissions [1,2]. While companies that conduct carbon footprints typically report their emissions voluntarily [3], some countries or regions have mandatory reporting requirements. However, such schemes are often limited to certain industries and/or companies emitting beyond some threshold [4,5]. Research has shown that less than 5%of public companies actually disclose their direct (Scope 1) GHG emissions [6], and it is likely that even less disclose indirect (Scope 2 and 3) emissions, as demonstrated by disclosure patterns in prior research [7]1. This gap in corporate emissions data presents several 1A company’s carbon footprint is typically calculated according to three emissions categories: Scope 1 (direct emissions from sources owned or controlled by the company), Scope 2 (indirect emissions from the generation Tackling Climate Change with Machine Learning: workshop at NeurIPS 2021.problems. First, it makes it difficult to reconcile company-level emissions with industry, national, and global GHG estimates, which is essential for assessing decarbonization efforts accurately [9]. Second, since many companies have begun announcing ambitious emissions targets and claiming emissions reductions [10,11], there is a greater need to track and corroborate such claims in order to hold companies accountable for their polluting activities. Finally, the lack of company-level GHG data poses challenges for evaluating carbon performance and carbon risk accurately for investment portfolio construction [12], in turn impacting where investments are funneled. Ideally, investments would be directed to companies making true efforts to decarbonize, yet in reality, this is difficult to ensure due to missing GHG accounts. 1.1 Related Works To address this gap in corporate emissions data, GHG estimation models have cropped up as potential solutions. Data providers, such as Morgan Stanley Capital International (MSCI), CDP (formerly Carbon Disclosure Project), and Thomson Reuters have developed models to estimate emissions based on various company features [12,13]. The CDP uses statistical regression techniques, while MSCI and Thomson Reuters use simple calculations that rely on data availability of a company’s energy figures or historical emissions, or simply industry-averaged data [14,15,16]. The academic research is limited to two statistical models (17,18) and three machine learning (ML) models [19, 13, 20]. Statistical approaches are constrained by the motive of making inferences about populations from specific samples [21], relying on “in-sample goodness-of-fit rather than the out-of-sample prediction accuracy,” [13]. In contrast, ML models can predict data by finding patterns in complex datasets, allowing for greater out-of-sample prediction accuracy [21, 13, 19] use the Light Gradient Boosting Machine (GBM) to estimate Scope 1 and 2 emissions, training the model on over 24,000 company-year GHG observations and over 1,000 predictor variables from the Bloomberg Terminal, with no clear justification for the choice of predictors. A large set of features renders the model complex and difficult to replicate, while including unnecessary features in a model may cause overfitting or deteriorate performance. Nguyen et al. [13] use a much smaller sample (>2,000 company-year GHG observations), and rely on a specific selection of predictors to estimate Scope 1, 2, 3, and total emissions. Their model is developed as a meta-learner (Elastic Net) which aggregates predictions from six base-learners. Of the base learners, the best performing is the tree-based learners, which include Extreme Gradient Boosting (XGBoost) and Random Forest. Serafeim and Caicedo [20] compare Random Forest and Adaptive Boosting (Ada\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nCompanies worldwide contribute to climate change by emitting significant amounts of greenhouse gases (GHGs). However, most companies do not report their direct or Scope 1 emissions, resulting in a large data gap in corporate emissions. This study aims to fill this gap by training decision-tree machine learning models to predict company-level Scope 1 emissions. Our results show that the Extreme Gradient Boosting and LightGBM models perform best, with the former demonstrating a 19% improvement in prediction error over a benchmark model. Our model is also of reduced complexity and greater computational efficiency, requiring fewer features and no meta-learners. The features used are uniquely chosen based on concepts of environmental pollution in economic theory.\n\nPredicting corporate emissions with machine learning can be used as a gap-filling approach, allowing for better GHG accounting and tracking, which facilitates corporate decarbonization efforts in the long term. This can also impact representations of a company's carbon performance and carbon risks, helping to direct investments towards companies with lower emissions and those making genuine efforts to decarbonize.\n\nIntroduction\n\nIn light of the climate crisis and the significant amounts of greenhouse gases (GHGs) emitted by companies, stakeholders have been pressuring them to disclose their GHG emissions. While companies that conduct carbon footprints typically report their emissions voluntarily, some countries or regions have mandatory reporting requirements. However, these schemes are often limited to certain industries and/or companies emitting beyond a certain threshold. Research has shown that less than 5% of public companies disclose their direct (Scope 1) GHG emissions, and it is likely that even fewer disclose indirect (Scope 2 and 3) emissions.\n\nThis gap in corporate emissions data presents several problems. First, it makes it difficult to reconcile company-level emissions with industry, national, and global GHG estimates, which is essential for assessing decarbonization efforts accurately. Second, since many companies have begun announcing ambitious emissions targets and claiming emissions reductions, there is a greater need to track and corroborate such claims to hold companies accountable for their polluting activities. Finally, the lack of company-level GHG data poses challenges for evaluating carbon performance and carbon risk accurately for investment portfolio construction, impacting where investments are directed.\n\nIdeally, investments would be directed to companies making true efforts to decarbonize, but in reality, this is difficult to ensure due to missing GHG accounts.\n\n1.1 Related Works\n\nTo address the gap in corporate emissions data, GHG estimation models have emerged as potential solutions. Data providers, such as Morgan Stanley Capital International (MSCI), CDP (formerly Carbon Disclosure Project), and Thomson Reuters, have developed models to estimate emissions based on various company features. The CDP uses statistical regression techniques, while MSCI and Thomson Reuters use simple calculations relying on data availability of a company's energy figures or historical emissions, or industry-averaged data.\n\nAcademic research is limited to two statistical models and three machine learning (ML) models. Statistical approaches are constrained by the motive of making inferences about populations from specific samples, relying on \"in-sample goodness-of-fit rather than out-of-sample prediction accuracy.\" In contrast, ML models can predict data by finding patterns in complex datasets, allowing for greater out-of-sample prediction accuracy.\n\nA previous study used the Light Gradient Boosting Machine (GBM) to estimate Scope 1 and 2 emissions, training the model on over 24,000 company-year GHG observations and over 1,000 predictor variables from the Bloomberg Terminal, but did not justify the choice of predictors. A large set of features renders the model complex and difficult to replicate, while including unnecessary features may cause overfitting or deteriorate performance.\n\nAnother study used a smaller sample (>2,000 company-year GHG observations) and relied on a specific selection of predictors to estimate Scope 1, 2, 3, and total emissions. Their model was developed as a meta-learner (Elastic Net) that aggregates predictions from six base-learners. The best-performing base learners were tree-based learners, including Extreme Gradient Boosting (XGBoost) and Random Forest. A comparison of Random Forest and Adaptive Boosting (AdaBoost) was also conducted."
}