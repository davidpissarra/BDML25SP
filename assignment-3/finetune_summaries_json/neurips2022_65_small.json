{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" a major societal and economic hazard, claiming thousands of lives and causing billions of dollars in damage every year. Under climate change, their impact and intensity are expected to worsen significantly. Unfortunately, general circulation models (GCMs), which are currently the primary tool for climate projections, cannot characterize weather extremes accurately. To address this, we present a multi-resolution deep-learning framework that, firstly, corrects a GCM’s biases by matching low-order and tail statistics of its output with observations at coarse scales; and secondly, increases the level of detail of the debiased GCM output by reconstructing the finer scales as a function of the coarse scales. We use the proposed framework to generate statistically realistic realizations of the climate over Western Europe from a simple GCM corrected using observational atmospheric reanalysis. We also discuss implications for probabilistic risk assessment of natural disasters in a changing climate. 1 Introduction The development of extreme weather under climate change is of growing concern for many stake- holders across the globe, including civil society, governments, and businesses [ 1–3]. The assessment of the risks associated with weather extremes is thereby highly critical. Quite often, the most unlikely events in the tail of a hazard’s probability distribution are also the most devastating. Because of their unlikely nature, their statistics are difficult to predict, even more so on a regional scale [ 4]. In addition, the effects of climate change are expected to vary across weather perils, making exploration of catastrophic scenarios even more challenging. Extreme weather risk is often estimated by generating ensembles of possible climate states using global circulation models (GCMs). Unfortunately, ensemble size and resolution are insufficient to characterize tail events properly. Even at high resolution, GCMs suffer from statistical biases [ 5] which can lead to the incorrect characterization of extreme-weather inducing processes (e.g., blocking events [ 6]). Moreover, high-resolution GCMs require vast computing resources. Hence, to create large ensembles that provide a better statistical sampling, simple GCMs and coarse resolutions have to be employed. However, these simulations will be polluted with severe biases. To remedy these issues, one strategy is to leverage the wealth of observational data available about the Earth system and the power of machine learning [ 7]. This can be pursued either in a purely data-based Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.Coarse -scale debiased  simulationWavelet transform LSTM -based  Neural Networks Coarse -scale biased  GCM simulation Inverse wavelet transform Coarse -scale biased  wavelet coefficientsCoarse -scale debiased  wavelet coefficients Coarse -scale  reanalysis Fine-scale  reanalysis Wavelet transform TCN -based  Neural Networks Inverse wavelet transform Coarse -scale wavelet coefficientsFine-scale  wavelet coefficients Full-scale debiased  simulation TestingStep 1 Step 2  Figure 1: Overview of framework. Reanalysis data is used as benchmark as it provides the most comprehensive description of the observed climate. fashion [ 8], or by augmenting the GCM dynamical equations with data-driven terms [ 9] or post- processing the GCM output to make it consistent with observations [ 10,11]. The main challenges are thereby the strongly nonlinear energy scattering across scales as well the non-deterministic nature of the very fine scales [ 12]. These two issues often compromise the stability of machine-learning schemes [13, 14] and the physical consistency of the output [15, 16]. We introduce a multi-resolution deep learning framework for accelerating the simulation of weather extremes. We combine a physics-based GCM run at coarse resolution with machine-learning models trained on observational data to reduce the biases and enhance the resolution of the GCM simulation. The key ingredients are a) a compact, multi-scale representation of physical processes on the sphere which efficiently captures energy transfers across scales; b) novel statistical loss functions which place emphasis on extreme values and space–time coherency; and c) a divide-and-conquer training strategy which enables training of regional models at high spatial resolution. The full-scale debiased simulation provides a complete view of risk at arbitrary resolution which decision makers can use to investigate near-present scenarios and assess their vulnerability to catastrophic weather events. 2 Methods We start from coarse-resolution runs of a simple but fast GCM polluted by strong biases. Based on these, we proceed in two steps; see Figure 1. First, we correct the low-order and tail statistics of the GCM output at coarse scales to match the statistics of observations. Second, we enhance the resolution of the debiased GCM output by reconstructing the finer scales as a function of the coarse ones. In both steps, the ground truth is reanalysis data, a blend of observations and past forecasts which provides the most realistic picture of past atmospheric states that is available. Decomposition of spatial scales The dynamics of the atmosphere are characterized by a wide range of scales, from thousands of kilometers to a few meters. To delineate\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy and dirty parts removed:\n\nClimate change poses a significant societal and economic hazard, claiming thousands of lives and causing billions of dollars in damage annually. Under climate change, the impact and intensity of these hazards are expected to worsen. However, general circulation models (GCMs), the primary tool for climate projections, struggle to accurately characterize weather extremes. To address this, we propose a multi-resolution deep-learning framework that corrects GCM biases by matching low-order and tail statistics of its output with observations at coarse scales, and then increases the level of detail of the debiased GCM output by reconstructing finer scales as a function of the coarse scales.\n\nWe apply this framework to generate statistically realistic realizations of the climate over Western Europe from a simple GCM corrected using observational atmospheric reanalysis. We also discuss the implications for probabilistic risk assessment of natural disasters in a changing climate.\n\nThe development of extreme weather under climate change is a growing concern for various stakeholders, including civil society, governments, and businesses. Assessing the risks associated with weather extremes is critical, as the most unlikely events in the tail of a hazard's probability distribution are often the most devastating. Due to their unlikely nature, their statistics are difficult to predict, especially on a regional scale. Climate change is expected to vary the effects across different weather perils, making the exploration of catastrophic scenarios even more challenging.\n\nExtreme weather risk is often estimated by generating ensembles of possible climate states using GCMs. However, ensemble size and resolution are insufficient to characterize tail events properly. Even at high resolution, GCMs suffer from statistical biases, which can lead to incorrect characterization of extreme-weather inducing processes. High-resolution GCMs require vast computing resources, making it challenging to create large ensembles that provide a better statistical sampling. To address these issues, we leverage the wealth of observational data available about the Earth system and the power of machine learning.\n\nOur proposed framework combines a physics-based GCM run at coarse resolution with machine-learning models trained on observational data to reduce biases and enhance the resolution of the GCM simulation. The key ingredients are a compact, multi-scale representation of physical processes on the sphere, novel statistical loss functions that emphasize extreme values and space-time coherency, and a divide-and-conquer training strategy that enables training of regional models at high spatial resolution.\n\nThe full-scale debiased simulation provides a complete view of risk at arbitrary resolution, which decision makers can use to investigate near-present scenarios and assess their vulnerability to catastrophic weather events.\n\nWe start from coarse-resolution runs of a simple but fast GCM polluted by strong biases. We proceed in two steps: first, we correct the low-order and tail statistics of the GCM output at coarse scales to match the statistics of observations, and second, we enhance the resolution of the debiased GCM output by reconstructing the finer scales as a function of the coarse ones. The ground truth is reanalysis data, a blend of observations and past forecasts that provides the most realistic picture of past atmospheric states available.\n\nThe dynamics of the atmosphere are characterized by a wide range of scales, from thousands of kilometers to a few meters. To delineate these scales, we use a wavelet transform to decompose the spatial scales."
}