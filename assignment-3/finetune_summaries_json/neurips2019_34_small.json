{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" decade, model predictive control (MPC) has been considered as the most promising solution for intelligent building operation. Despite extensive effort, transfer of this technology into practice is hampered by the need to obtain an accurate controller model with minimum effort, the need of expert knowledge to set it up, and the need of increased computational power and dedicated software to run it. A promising direction that tackles the last two problems was proposed by approximate explicit MPC where the optimal control policies are learned from MPC data via a suitable function approximator, e.g., a deep learning (DL) model. The main advantage of the proposed approach stems from simple evaluation at execution time leading to low computational footprints and easy deployment on embedded HW platforms. We present the energy savings potential of physics- based (also called ’white-box’) MPC applied to an ofﬁce building in Belgium. Moreover, we demonstrate how deep learning approximators can be used to cut the implementation and maintenance costs of MPC deployment without compromising performance. We also critically assess the presented approach by pointing out the major challenges and remaining open-research questions. 1 Introduction Nowadays buildings use roughly 40 % of the global energy (approx. 64 PWh), a large portion of which is being used for heating, cooling, ventilation, and air-conditioning (HV AC) [ 1]. The energy efﬁciency of buildings is thus one of the priorities to sustainably address the increased energy demands and reduction of CO 2emissions in the long term [2]. It has been shown that smart control strategies like model predictive control (MPC) can maximize system-level efﬁciency for existing built environments, thus reducing the emissions of greenhouse gases, and can improve the thermal comfort of the occupants, with reported energy use reductions of 15 % up to 50 % [3, 4, 5]. Despite this, the practical implementations of MPC are hampered by the challenge of obtaining an accurate controller model with minimum effort, the need of expert knowledge to set it up, and the need of increased computational power and dedicated software to run it [ 6]. Every building represent a unique system which requires tailored modeling and control design. 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.The MPC in this work is based on detailed physical modeling of a real-life ofﬁce building which provides an accurate prediction of the building’s thermal behavior and high control performance. On the other hand, the disadvantage of such high-ﬁdelity MPC approach lies in its computational demands and software dependencies. Here we are exploring the use of DL to learn the optimal control policies from MPC data. The main advantage of the proposed method stems from its low computational footprint, minimal software dependencies and easy deployment even on low-level hardware without compromising control performance. The advantage compared to reinforcement learning is its sample efﬁciency, because policies are learned with supervision from pre-computed optimal control trajectories in realistic operational scenarios. 2 Optimization-based model predictive control using physical models The ofﬁce building considered in the experimental and simulation study called Hollandsch Huys is located in Hasselt, Belgium. Hollandsch Huys represents a so-called GEOTABS building with slow dynamics and complex heating ventilation and air conditioning (HV AC) system [ 7]. The building’s layout consists of ﬁve ﬂoors divided into 12thermal zones. For detailed description of the building and physics-based modeling in Modelica language we refer to [ 8]. The main advantage of such a high ﬁdelity physics-based \"digital twin\" model stems from its potentially high prediction accuracy, interpretability, and reliability. Based on the approach described in [ 9] the physics-based model can be transformed to state-space representation with 700states x,301disturbance signals d,12thermal zones yand20control inputs u. Fig. 1 shows the corresponding control conﬁguration. The optimization-based MPC (OB-MPC) computes the optimal control actions u, based on estimated states xvia Kalman Filter (KF), for details see [ 10,11]. The MPC problem is solved using a state-of the art optimization solver Gurobi [ 12] running in the MATLAB environment. The non-linear weather forecaster model is running in the Dymola environment and computes the forecasts of disturbances d(weather, occupancy), and reference rtrajectories based on actual weather data wobtained from the Dark Sky API [ 13]. Optimal control actions at the current time step u0represent the heat ﬂows to be delivered to the building and are re-computed once per sampling time in so-called receding horizon control (RHC) fashion. Hollandsch Huys  office buildingu yd rw Dark Sky  weather  y r u w train replace MPC & KF OB-MPCDL-MPC Disturbances and comfort forecaster Figure 1: Optimization-based MPC methodology with deep learning-based policy approximator. 3 Deep learning-based approximation of\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nModel predictive control (MPC) has been considered a promising solution for intelligent building operation over the past decade. Despite extensive efforts, the transfer of this technology into practice is hindered by the need for an accurate controller model with minimal effort, the requirement of expert knowledge to set it up, and the need for increased computational power and dedicated software to run it. A promising direction that addresses the latter two issues is approximate explicit MPC, where optimal control policies are learned from MPC data using a suitable function approximator, such as a deep learning (DL) model. This approach offers the advantage of simple evaluation at execution time, resulting in low computational footprints and easy deployment on embedded hardware platforms.\n\nWe present the energy-saving potential of physics-based MPC applied to an office building in Belgium. Additionally, we demonstrate how deep learning approximators can be used to reduce the implementation and maintenance costs of MPC deployment without compromising performance. We also critically assess the presented approach by highlighting the major challenges and remaining open research questions.\n\nIntroduction\n\nBuildings account for approximately 40% of global energy consumption, with a significant portion used for heating, cooling, ventilation, and air-conditioning (HVAC). The energy efficiency of buildings is a priority to sustainably address increased energy demands and reduce CO2 emissions in the long term. Smart control strategies like MPC can maximize system-level efficiency for existing built environments, reducing greenhouse gas emissions and improving thermal comfort for occupants, with reported energy use reductions of 15% to 50%.\n\nDespite this, the practical implementation of MPC is hindered by the challenge of obtaining an accurate controller model with minimal effort, the need for expert knowledge to set it up, and the need for increased computational power and dedicated software to run it. Each building represents a unique system requiring tailored modeling and control design.\n\nThe MPC in this work is based on detailed physical modeling of a real-life office building, providing an accurate prediction of the building's thermal behavior and high control performance. However, this high-fidelity MPC approach has a disadvantage in terms of computational demands and software dependencies. We explore the use of DL to learn optimal control policies from MPC data.\n\nThe proposed method offers the advantage of a low computational footprint, minimal software dependencies, and easy deployment on low-level hardware without compromising control performance. This approach is more sample-efficient than reinforcement learning, as policies are learned with supervision from pre-computed optimal control trajectories in realistic operational scenarios.\n\nOptimization-based model predictive control using physical models\n\nThe office building considered in the experimental and simulation study, Hollandsch Huys, is located in Hasselt, Belgium. Hollandsch Huys is a GEOTABS building with slow dynamics and a complex HVAC system. The building's layout consists of five floors divided into 12 thermal zones. For a detailed description of the building and physics-based modeling in Modelica language, refer to [8].\n\nThe main advantage of this high-fidelity physics-based \"digital twin\" model is its potentially high prediction accuracy, interpretability, and reliability. Based on the approach described in [9], the physics-based model can be transformed into a state-space representation with 700 states, 301 disturbance signals, 12 thermal zones, and 20 control inputs. Figure 1 shows the corresponding control configuration.\n\nThe optimization-based MPC (OB-MPC) computes the optimal control actions based on estimated states via a Kalman Filter, for details see [10, 11]. The MPC problem is solved using a state-of-the-art optimization solver, Gurobi, running in the MATLAB environment. The non-linear weather forecaster model runs in the Dymola environment and computes forecasts of disturbances and reference trajectories based on actual weather data obtained from the Dark Sky API [13]. Optimal control actions at the current time step represent the heat flows to be delivered to the building and are re-computed once per sampling time in receding horizon control fashion.\n\nHollandsch Huys office building\nDark Sky weather\nDisturbances and comfort forecaster\nFigure 1: Optimization-based MPC methodology with deep learning-based policy approximator.\n\nDeep learning-based approximation of optimal control policies"
}