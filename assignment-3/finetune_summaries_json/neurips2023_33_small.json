{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" goodall@virginia.eduHeather Richter Old Dominion University‡ Norfolk, V A 23529 hrichter@odu.edu Abstract Everyday citizens, emergency responders, and critical infrastructure can be dramat- ically affected by the flooding of streets and roads. Climate change exacerbates these floods through sea level rise and more frequent major storm events. Low-level flooding, such as nuisance flooding, continues to increase in frequency, especially in cities like Norfolk, Virginia, which can expect nearly 200 flooding events by 2050 [ 1]. Recently, machine learning (ML) models have been leveraged to produce real-time predictions based on local weather and geographic conditions. However, ML models are known to produce unusual results when presented with data that varies from their training set. For decision-makers to determine the trustworthiness of the model’s predictions, ML models need to quantify their prediction uncer- tainty. This study applies Deep Quantile Regression to a previously published, Long Short-Term Memory-based model for hourly water depth predictions [ 2], and analyzes its out-of-distribution performance. 1 Introduction and Motivation Coastal cities face combined forces of climate change: more frequent storms, increased precipitation, amplified storm surge and tidal action, sea level rise, and fluctuations in groundwater levels. These factors can lead to increased vulnerability and less resiliency to urban flooding [ 3]. Community members and city officials would benefit from a surrogate model capable of real-time prediction and fast simulation for what-if analysis, enabling them to understand potential disruptions in transportation, emergency management, and city services. Additionally, corresponding uncertainty estimations are essential for providing reliable decision support as they inform decision-makers when a data-driven model may be inadequately trained for climate or geographic conditions of interest. The Hampton Roads region of Virginia has a total population of 1.7 million. The city of Norfolk is the second largest in the region, has the highest population density, and is home to over 245,000 people. Norfolk is a coastal city with 144 miles of waterfront, which enhances the quality of life and drives an economy that relies heavily on the Naval Station Norfolk and the Port of Virginia [ 4]. While access to water is an asset to the city, Norfolk is vulnerable to both pluvial and tidal flooding, which ∗Thomas Jefferson National Accelerator Facility †UV A Department of Civil and Environmental Engineering ‡ODU School of Community and Environmental Health Tackling Climate Change with Machine Learning workshop at NeurIPS 2023Figure 1: Plot of 16,923 Norfolk street segments in the full study area, and includes markers for the six flood-prone street segments, the Hampton Roads Sanitation District rain gauges, and the NOAA’s Sewells Point tide station monitor. Figure 2: Model diagram for the Base and DQR models with activations in italics and output units following the dash. The final layer changes out- put size and activation for the Base/DQR models. has increased in frequency and intensity due to climate change. As of 2018, the National Oceanic and Atmospheric Administration (NOAA) Sewells Point tide station documented the greatest change in relative sea level in the world of 1.45 feet in the last 100 years [ 3]. Additionally, since 1960, Norfolk has seen a 325% increase in nuisance flooding, lower levels of flooding not caused by extreme events or disasters [ 1]. With climate change, these trends are expected to continue, and the characteristics of tidal action, precipitation, soil saturation, and groundwater levels will continue to shift, leading to greater uncertainty in localized flooding predictions. The importance of uncertainty quantification (UQ) for decision-relevant ML surrogate flooding models has been highlighted in the context of fluvial flooding prediction [ 5], storm-tracking [ 6], and flood risk [ 7]. ML flooding surrogate models have been developed for characterization of an entire rainfall event: forecasting flood risk [ 8,9,10], predicting occurrence of floods [ 11], estimating total accumulative water overflow [ 12], and predicting maximum water depth [ 13,14,15,16]. However, these solutions do not include UQ. This work builds upon [ 17], which compared a physics-based 1- D/2-D high-resolution hydrodynamic model to a Random Forest (RF) surrogate model for street-scale flooding prediction in Norfolk and demonstrated RF inferences were approximately 3,000 times faster. Further research in [ 2] compared the performance of Recurrent Neural Network (RNN) surrogate models to [ 17]’s RF model and demonstrated equivalent error metrics. This work also employs RNNs as they support the inclusion of various UQ methods such as the Deep Quantile Regression (DQR) model presented here. 2 ML Methods and Datasets 2.1 Norfolk Rainfall Dataset Data for this work includes both geospatial and weather components, which are standardized to zero mean and unit variance prior to model training. The geospatial data includes\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nHeather Richter\nOld Dominion University\nNorfolk, VA 23529\nAbstract\n\nEveryday citizens, emergency responders, and critical infrastructure can be dramatically affected by flooding of streets and roads. Climate change exacerbates these floods through sea level rise and more frequent major storm events. Low-level flooding, such as nuisance flooding, continues to increase in frequency, especially in cities like Norfolk, Virginia, which can expect nearly 200 flooding events by 2050. Recently, machine learning (ML) models have been leveraged to produce real-time predictions based on local weather and geographic conditions. However, ML models are known to produce unusual results when presented with data that varies from their training set. For decision-makers to determine the trustworthiness of the model's predictions, ML models need to quantify their prediction uncertainty.\n\nThis study applies Deep Quantile Regression to a previously published, Long Short-Term Memory-based model for hourly water depth predictions, and analyzes its out-of-distribution performance.\n\n1 Introduction and Motivation\n\nCoastal cities face combined forces of climate change: more frequent storms, increased precipitation, amplified storm surge and tidal action, sea level rise, and fluctuations in groundwater levels. These factors can lead to increased vulnerability and less resiliency to urban flooding. Community members and city officials would benefit from a surrogate model capable of real-time prediction and fast simulation for what-if analysis, enabling them to understand potential disruptions in transportation, emergency management, and city services. Additionally, corresponding uncertainty estimations are essential for providing reliable decision support as they inform decision-makers when a data-driven model may be inadequately trained for climate or geographic conditions of interest.\n\nThe Hampton Roads region of Virginia has a total population of 1.7 million. The city of Norfolk is the second largest in the region, has the highest population density, and is home to over 245,000 people. Norfolk is a coastal city with 144 miles of waterfront, which enhances the quality of life and drives an economy that relies heavily on the Naval Station Norfolk and the Port of Virginia. While access to water is an asset to the city, Norfolk is vulnerable to both pluvial and tidal flooding, which has increased in frequency and intensity due to climate change.\n\nAs of 2018, the National Oceanic and Atmospheric Administration (NOAA) Sewells Point tide station documented the greatest change in relative sea level in the world of 1.45 feet in the last 100 years. Additionally, since 1960, Norfolk has seen a 325% increase in nuisance flooding, lower levels of flooding not caused by extreme events or disasters. With climate change, these trends are expected to continue, and the characteristics of tidal action, precipitation, soil saturation, and groundwater levels will continue to shift, leading to greater uncertainty in localized flooding predictions.\n\nThe importance of uncertainty quantification (UQ) for decision-relevant ML surrogate flooding models has been highlighted in the context of fluvial flooding prediction, storm-tracking, and flood risk. ML flooding surrogate models have been developed for characterization of an entire rainfall event: forecasting flood risk, predicting occurrence of floods, estimating total accumulative water overflow, and predicting maximum water depth. However, these solutions do not include UQ.\n\nThis work builds upon a previous study that compared a physics-based 1-D/2-D high-resolution hydrodynamic model to a Random Forest (RF) surrogate model for street-scale flooding prediction in Norfolk and demonstrated RF inferences were approximately 3,000 times faster. Further research compared the performance of Recurrent Neural Network (RNN) surrogate models to the RF model and demonstrated equivalent error metrics. This work also employs RNNs as they support the inclusion of various UQ methods such as the Deep Quantile Regression (DQR) model presented here.\n\n2 ML Methods and Datasets\n\n2.1 Norfolk Rainfall Dataset\n\nData for this work includes both geospatial and weather components, which are standardized to zero mean and unit variance prior to model training. The geospatial data includes..."
}