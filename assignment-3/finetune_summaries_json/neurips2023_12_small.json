{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"cce.com Abstract Fossil fuel energy production is a leading cause of climate change. While wind and solar energy have made advancements, ocean waves, a more consistent clean energy source, remain underutilized. Wave Energy Converters (WEC) transform wave power into electric energy. To be economically viable, modern WECs need sophisticated real-time controllers that boost energy output and minimize mechanical stress, thus lowering the overall cost of energy (LCOE). This paper presents how a Reinforcement Learning (RL) controller can outperform the default spring-damper controller for complex spread waves in the sea, enhancing wave energy’s viability. Using the Proximal Policy Optimization (PPO) algorithm with Transformer variants as function approximators, the RL controllers optimize multi- generator Wave Energy Converters (WEC) leveraging wave sensor data for multiple cost-efficiency goals. After successful tests in the EuropeWave2project’s emulator tank, the platform is planned to deploy. We discuss the challenges of deployment at the BiMEP site and how we had to tune the RL controller to address that. The RL controller outperforms the default Spring Damper controller in the BiMEP3 conditions by 22.8% on energy capture. Enhancing wave energy’s economic viability will expedite the transition to clean energy, reducing carbon emissions and fostering a healthier climate. 1 Introduction Ocean waves are a more consistent and reliable source of clean energy than wind and solar. It is estimated that the total potential of ocean wave energy is around 30,000 TWh/yr, which is about 20% of the 2019 world energy consumption Lewis et al. (2011). Harnessing this energy using Wave Energy Converters is a complex engineering task. ∗Corresponding author 2EuropeWave: https://www.europewave.eu/ 3BiMEP: https://www.bimep.com/en/ Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.Figure 1: (Left) Complexity increases from simple one-legged WEC to the multi-legged CETO 6. (Middle) Spread waves with components from multiple directions. (Right) Distribution of energy along various directions There are different methodologies for designing WECs. Here, we focus on the CETO design which is a fully submerged, point absorber type wave energy technology. WECs are typically submerged beneath the ocean, and are tethered to the ocean bed using mooring legs. These legs are connected to an electrical generator. As waves roll over, these legs extend and retract. The generator applies a varying control torque, which dictates how the device moves. The power generated by each leg is proportional to the product of the leg’s extension velocity and the control force. Maximizing generated power, requires advanced controllers that can operate in real-time. Traditional, passive controllers like spring-damper are optimal for simple, unidirectional sinusoidal waves. However, they sub-optimal for ocean waves that have a spectrum of frequencies with components in multiple directions - usually called spread waves as depicted in Figure 1. Spread waves introduce complexity for WECs due to simultaneous waves arriving from various angles, influenced by atmospheric events in different oceanic regions. Also, passive controllers cannot utilize information about incoming waves in advance obtained from wave sensors further out in the ocean. This work uses reinforcement learning to train an agent to maximize power for spread waves at the BiMEP test site. We design a state space ( Figure 2) that enable the agent to effectively utilize information from incoming waves. We also design a reward function that enables the agent to maximize power for a variety of sea states for a specific location while minimizing the yaw rotational motion detrimental to the device’s longevity. Overall this can significantly reduce the Levelized-Cost- of-Energy (LCOE). To our knowledge, this is the first reinforcement learning controller that was successfully tested in a physical multi-legged WEC. Related work: RL controllers for WEC have been explored in simplified settings - mostly for point absorbers with 1 degree of freedom. Anderlini et al. (2016), Anderlini et al. (2017) utilize RL in a non-real-time scenario to predict change in the damping coefficient of a spring-damper controller for a particular sea state. Anderlini et al. (2020) apply Soft Actor Critic for real-time control of a 1 legged point absorber. Sarkar et al. (2021), Sarkar et al. (2022a), Sarkar et al. (2022b), Sarkar et al. (2023), demonstrate using PPO for a multi-legged device, however, did not discuss the deployment issues with multidirectional spread waves. Figure 2: Reinforcement Learning controller for Wave Energy Controller 22 Reinforcement Learning for Wave Energy Converters The state vector for the reinforcement learning (RL) is formulated as shown in Figure 2. The position, velocity, and acceleration include both the translation and rotational components\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and data removed:\n\nAbstract:\nFossil fuel energy production is a leading cause of climate change. While wind and solar energy have made advancements, ocean waves remain a more consistent and reliable clean energy source. Wave Energy Converters (WECs) transform wave power into electric energy. To be economically viable, modern WECs need sophisticated real-time controllers that boost energy output and minimize mechanical stress, thus lowering the overall cost of energy (LCOE). This paper presents how a Reinforcement Learning (RL) controller can outperform the default spring-damper controller for complex spread waves in the sea, enhancing wave energy's viability.\n\nUsing the Proximal Policy Optimization (PPO) algorithm with Transformer variants as function approximators, the RL controllers optimize multi-generator Wave Energy Converters (WECs) leveraging wave sensor data for multiple cost-efficiency goals. After successful tests in the EuropeWave2 project's emulator tank, the platform is planned to deploy. We discuss the challenges of deployment at the BiMEP site and how we had to tune the RL controller to address these challenges. The RL controller outperforms the default Spring Damper controller in the BiMEP conditions by 22.8% on energy capture. Enhancing wave energy's economic viability will expedite the transition to clean energy, reducing carbon emissions and fostering a healthier climate.\n\nIntroduction:\nOcean waves are a more consistent and reliable source of clean energy than wind and solar. It is estimated that the total potential of ocean wave energy is around 30,000 TWh/yr, which is about 20% of the 2019 world energy consumption (Lewis et al., 2011). Harnessing this energy using Wave Energy Converters is a complex engineering task.\n\nTackling Climate Change with Machine Learning: workshop at NeurIPS 2023.\n\nThere are different methodologies for designing WECs. Here, we focus on the CETO design, a fully submerged, point absorber type wave energy technology. WECs are typically submerged beneath the ocean, and are tethered to the ocean bed using mooring legs. These legs are connected to an electrical generator. As waves roll over, these legs extend and retract. The generator applies a varying control torque, which dictates how the device moves. The power generated by each leg is proportional to the product of the leg's extension velocity and the control force. Maximizing generated power requires advanced controllers that can operate in real-time.\n\nTraditional, passive controllers like spring-damper are optimal for simple, unidirectional sinusoidal waves. However, they are suboptimal for ocean waves that have a spectrum of frequencies with components in multiple directions - usually called spread waves. Spread waves introduce complexity for WECs due to simultaneous waves arriving from various angles, influenced by atmospheric events in different oceanic regions. Passive controllers cannot utilize information about incoming waves in advance obtained from wave sensors further out in the ocean.\n\nThis work uses reinforcement learning to train an agent to maximize power for spread waves at the BiMEP test site. We design a state space that enables the agent to effectively utilize information from incoming waves. We also design a reward function that enables the agent to maximize power for a variety of sea states for a specific location while minimizing the yaw rotational motion detrimental to the device's longevity. Overall, this can significantly reduce the Levelized-Cost-of-Energy (LCOE).\n\nTo our knowledge, this is the first reinforcement learning controller that was successfully tested in a physical multi-legged WEC. Related work: RL controllers for WEC have been explored in simplified settings - mostly for point absorbers with 1 degree of freedom. Anderlini et al. (2016, 2017) utilize RL in a non-real-time scenario to predict change in the damping coefficient of a spring-damper controller for a particular sea state. Anderlini et al. (2020) apply Soft Actor Critic for real-time control of a 1-legged point absorber. Sarkar et al. (2021, 2022a, 2022b, 2023) demonstrate using PPO for a multi-legged device, however, did not discuss the deployment issues with multidirectional spread waves.\n\nThe state vector for the reinforcement learning (RL) is formulated as shown in Figure 2. The position, velocity, and acceleration include both the translation and rotational components."
}