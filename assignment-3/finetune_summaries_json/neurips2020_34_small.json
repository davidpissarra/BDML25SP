{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"ennifer.Adams g@esa.int ABSTRACT To address the mounting destruction caused by ﬂoods in climate-vulnerable re- gions, we propose Street to Cloud, a machine learning pipeline for incorporat- ing crowdsourced ground truth data into the segmentation of satellite imagery of ﬂoods. We propose this approach as a solution to the labor-intensive task of gen- erating high-quality, hand-labeled training data, and demonstrate successes and failures of different plausible crowdsourcing approaches in our model. Street to Cloud leverages community reporting and machine learning to generate novel, near-real time insights into the extent of ﬂoods to be used for emergency response. 1 I NTRODUCTION The frequency and magnitude of ﬂooding are increasing at an alarming rate (UNDRR, 2015), affect- ing growing populations of climate-vulnerable people. Flooding affects more people than any other environmental hazard and hinders sustainable development (Hallegatte et al., 2017; CRED, 2019), and research consistently shows that relative property loss for ﬂoods are highest in places of social vulnerability (Tellman et al., 2020). Nowcasting ﬂood extents enables decision makers, relief agencies, and citizens to make informed decisions and provide direct relief where it is needed most. Optical, radar, and microwave satellites make it possible to remotely create scalable, low-cost, and high-quality ﬂood maps and impact assessments. However, there are signiﬁcant challenges to ﬂood mapping, monitoring, and analyzing based on satellite data. Unique challenges arise from infrequent revisit times, varying resolutions across satellites, adverse and obscuring weather conditions, and difﬁcult to parse images of urban areas where most of the world’s population and assets are concentrated. Most existing algorithms to process these images, machine learning or otherwise, use ﬁnely an- notated data that often requires remote sensing expertise to generate. Traditional, threshold-based remote sensing often requires a nontrivial amount of manual quality assurance and parameter tuning from domain experts. In an effort to develop an algorithm that not only addresses these data issues but also directly engages the communities affected in disaster reporting, we propose a methodology for using crowd-sourced data and simpliﬁed ﬂood masks to train a semantic segmentation model to generate high quality ﬂood masks. Using Cloud to Street’s Sen1Floods11 dataset (Bonaﬁlia et al., 2020) of high-quality hand-labeled Sentinel-2 imagery, we created a dataset of simpliﬁed ﬂood masks and synthetic crowd- sourced data points. These masks are intended to be simple to generate even without remote sensing expertise, and therefore can be generated easily and at scale. Our synthetic crowdsourced data mir- rors two plausible scenarios for aggregating data from the community: passive social media scraping and active data collection by community members or trained data collectors. Leveraging dense and sparse data at the same time is a challenge for segmentation networks that we tackle by adopting a 1Tackling Climate Change with Machine Learning workshop at NeurIPS 2020 two-stage process (see Figure 1) in which the second stage is inspired by continual learning. Af- ter training our network using these two approaches, we benchmark our results against the models trained on purely hand-labeled and purely simpliﬁed training masks. We expect this research to allow us to provide high quality, rapidly available ﬂood maps for evacu- ation and aid. In the case of some urban areas, crowdsourcing will enable us to verify ﬂooding on a street-by-street level where remote sensing data alone cannot. Flood waters recede quickly, some- times before there is a satellite overpass or the clouds clear, rendering optical remote sensing data insufﬁcient for ﬂood detection. Similarly, radar data, which can map water through clouds, is often very noisy in urban areas as signals can bounce off buildings. With street-level crowdsourcing and machine learning, we can train models to do necessary initial inundation detection and compensate for challenges when only using satellite data. Figure 1: The inference pipeline of our model. The two-stage model ﬁrst generates a segmentation mask from Sentinel-2 imagery in Stage 1, and then combines Sentinel-2 imagery, initial coarse output, and crowdsourced points in Stage 2 to generate the ﬁnal segmentation mask. Points collected from either a Trained Collector or Social Media model can be used interchangeably in this model. In this work we provide a dataset of simpliﬁed water masks of ﬂood events, built off of Sen1Floods11, as well as a dataset of synthetic crowdsourced data for each event in a number of plausible collection scenarios. We present Street to Cloud, a multi-modal model framework which combines satellite imagery and in-situ, crowdsourced data in a segmentation and reﬁner network to produce nowcast ﬂood extent maps for monitoring, aid, and\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nJennifer Adams, esa.int\nAbstract:\nTo address the growing destruction caused by floods in climate-vulnerable regions, we propose Street to Cloud, a machine learning pipeline for incorporating crowdsourced ground truth data into the segmentation of satellite imagery of floods. This approach aims to solve the labor-intensive task of generating high-quality, hand-labeled training data and demonstrates the successes and failures of different plausible crowdsourcing approaches in our model. Street to Cloud leverages community reporting and machine learning to generate novel, near-real-time insights into the extent of floods for emergency response.\n\nIntroduction:\nThe frequency and magnitude of flooding are increasing at an alarming rate (UNDRR, 2015), affecting growing populations of climate-vulnerable people. Flooding affects more people than any other environmental hazard and hinders sustainable development (Hallegatte et al., 2017; CRED, 2019). Research consistently shows that relative property loss for floods is highest in places of social vulnerability (Tellman et al., 2020). Nowcasting flood extents enables decision-makers, relief agencies, and citizens to make informed decisions and provide direct relief where it is needed most. Optical, radar, and microwave satellites make it possible to remotely create scalable, low-cost, and high-quality flood maps and impact assessments.\n\nHowever, there are significant challenges to flood mapping, monitoring, and analyzing based on satellite data. Unique challenges arise from infrequent revisit times, varying resolutions across satellites, adverse and obscuring weather conditions, and difficult-to-parse images of urban areas where most of the world's population and assets are concentrated. Most existing algorithms to process these images, machine learning or otherwise, use finely annotated data that often requires remote sensing expertise to generate. Traditional, threshold-based remote sensing often requires a non-trivial amount of manual quality assurance and parameter tuning from domain experts.\n\nIn an effort to develop an algorithm that addresses these data issues and directly engages the communities affected in disaster reporting, we propose a methodology for using crowdsourced data and simplified flood masks to train a semantic segmentation model to generate high-quality flood masks. Using Cloud to Street's Sen1Floods11 dataset (Bonaﬁlia et al., 2020) of high-quality hand-labeled Sentinel-2 imagery, we created a dataset of simplified flood masks and synthetic crowdsourced data points. These masks are intended to be simple to generate even without remote sensing expertise, and therefore can be generated easily and at scale.\n\nOur synthetic crowdsourced data mirrors two plausible scenarios for aggregating data from the community: passive social media scraping and active data collection by community members or trained data collectors. Leveraging dense and sparse data at the same time is a challenge for segmentation networks that we tackle by adopting a two-stage process (see Figure 1) in which the second stage is inspired by continual learning. After training our network using these two approaches, we benchmark our results against the models trained on purely hand-labeled and purely simplified training masks.\n\nWe expect this research to allow us to provide high-quality, rapidly available flood maps for evacuation and aid. In the case of some urban areas, crowdsourcing will enable us to verify flooding on a street-by-street level where remote sensing data alone cannot. Flood waters recede quickly, sometimes before there is a satellite overpass or the clouds clear, rendering optical remote sensing data insufficient for flood detection. Similarly, radar data, which can map water through clouds, is often very noisy in urban areas as signals can bounce off buildings.\n\nWith street-level crowdsourcing and machine learning, we can train models to do necessary initial inundation detection and compensate for challenges when only using satellite data. Figure 1: The inference pipeline of our model. The two-stage model first generates a segmentation mask from Sentinel-2 imagery in Stage 1, and then combines Sentinel-2 imagery, initial coarse output, and crowdsourced points in Stage 2 to generate the final segmentation mask. Points collected from either a Trained Collector or Social Media model can be used interchangeably in this model.\n\nIn this work, we provide a dataset of simplified water masks of flood events, built off of Sen1Floods11, as well as a dataset of synthetic crowdsourced data for each event in a number of plausible collection scenarios. We present Street to Cloud, a multi-modal model framework that combines satellite imagery and in-situ, crowdsourced data in a segmentation and refiner network to produce nowcast flood extent maps for monitoring, aid, and response."
}