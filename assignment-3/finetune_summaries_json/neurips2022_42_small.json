{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" the labeling requirements of a purely supervised learning method. Past attempts have used such unlabelled data by creating weak labels out of them, but end up learning the label mistakes in those weak labels. Motivated by knowledge distillation and semi supervised learning, we explore the use of a teacher to train a student with the help of a small hand labeled dataset and a large unlabelled dataset. Unlike the conventional self distillation setup, we propose a cross modal distillation framework that transfers supervision from a teacher trained on richer modality (multi-spectral images) to a student model trained on SAR imagery. The trained models are then tested on the Sen1Floods11 dataset. Our model outperforms the Sen1Floods11 SAR baselines by an absolute margin of 4:15% pixel wise Intersection-over-Union (IoU) on the test split. 1 Introduction Floods are one of the major natural disasters, exacerbated by climate change, affecting between 85 million to 250 million people annually and causing between $32to$36billion in economic damages [14, 11]. Some of these harms can be alleviated by providing early ﬂood warnings, so that people can take proactive measures such as planned evacuation, move assets such as food and cattle and use sandbags for protection. One of the important user experience elements for an effective warning system is its overall accuracy, as false alerts lead to eroded trust in the system. Our work contributes towards improving the accuracy of ﬂood warning systems such as [ 24], by increasing the accuracy of the inundation module. The inundation model in [ 24] learns a mapping between historical river water gauge levels and the corresponding ﬂooded area which can be leveraged to predict future ﬂooding extent based on forecast of the future river water gauge level. The accuracy of these forecasts is directly correlated with the accuracy of the underlying historical segmentation maps, hence we aim to improve the segmentation module through our contributions in this work. In recent years, remote sensing technology has considerably improved and provided high resolution spatial and temporal satellite data. Sentinel-1 [ 30] and Sentinel-2 [ 10] satellites are commonly used to map the water surface because they provide open access to high spatial and temporal resolution data. Although Sentinel-2 is better for water segmentation as it shows high water absorption capacity in short wave infrared spectral range (SWIR) and near infrared (NIR) spectrum, it cannot penetrate cloud cover. This limits its application for mapping historical ﬂoods as cloud cover is highly correlated with ﬂooding events. On the other hand, radar pulses readily penetrate clouds, making SAR satellites well suited for ﬂood mapping [28, 22, 31]. Thresholding algorithms [ 20,21,6] are traditionally used to segment ﬂooded regions from SAR images because of low back scatter intensity of water. Though techniques like Otsu thresholding [ 4] Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.work well for many cases, its failure modes include generating false positives for mountain shadows and generating excessive background noise due to speckle in SAR imagery. In recent years, Convolu- tional Neural Networks (CNN) have been used to segment ﬂooded areas from satellite images. Unlike traditional pixel-wise methods, they can look at a larger context and incorporate spatial features from an image. A lot of work has focused on using opportunistically available cloud free Sentinel-2 images [ 23,1]. Though these methods have good performance, their utility at inference time is limited because of the cloud cover issues mentioned above. Another line of work fuses Sentinel-1 and Sentinel-2 images [ 19,9,29,3] to enhance surface water detection during ﬂooded events. These methods not only a require a cloud free Sentinel-2 image, but also require that both images are taken at about the same time to avoid alignment issues. There has been some work done that uses multi temporal images [ 33,27,32] containing a pre-ﬂood and a post-ﬂood event. These methods can do change detection and exhibit better performance. In our work however, we focus on methods that only take a single Sentinel-1 timestamp image as input. Sen1Floods11 [ 5] is a publicly available dataset with a small set of high quality hand labeled images and a larger set of weak labeled images. Most of the prior work that uses a single Sentinel-1 image as input [ 5,12,18,16], used this weak labeled data to train their models. However, the limitation of using weak labeled data (despite using various regularization techniques), is that the model still learns the mistakes in those labels. Motivated by the semi-supervised methods in [ 25] and cross modal feature distillation [ 15], we use a teacher student setup that extracts information from a more informative modality (Sentinel-2\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nThe labeling requirements of a supervised learning method are challenging. Past attempts have used unlabeled data by creating weak labels, but this approach often learns the mistakes in those labels. Motivated by knowledge distillation and semi-supervised learning, we explore the use of a teacher to train a student with a small hand-labeled dataset and a large unlabeled dataset. Unlike conventional self-distillation, we propose a cross-modal distillation framework that transfers supervision from a teacher trained on richer modality (multi-spectral images) to a student model trained on SAR imagery. The trained models are then tested on the Sen1Floods11 dataset. Our model outperforms the Sen1Floods11 SAR baselines by an absolute margin of 4.15% pixel-wise Intersection-over-Union (IoU) on the test split.\n\nIntroduction\n\nFloods are a major natural disaster, exacerbated by climate change, affecting between 85 million to 250 million people annually and causing between $32 billion to $36 billion in economic damages. Some of these harms can be alleviated by providing early flood warnings, allowing people to take proactive measures such as planned evacuation, moving assets, and using sandbags for protection. One of the key user experience elements for an effective warning system is its overall accuracy, as false alerts lead to eroded trust in the system. Our work contributes to improving the accuracy of flood warning systems by increasing the accuracy of the inundation module.\n\nThe inundation model in previous work learns a mapping between historical river water gauge levels and the corresponding flooded area, which can be used to predict future flooding extent based on forecasts of future river water gauge levels. The accuracy of these forecasts is directly correlated with the accuracy of the underlying historical segmentation maps, so we aim to improve the segmentation module through our contributions in this work.\n\nIn recent years, remote sensing technology has improved, providing high-resolution spatial and temporal satellite data. Sentinel-1 and Sentinel-2 satellites are commonly used to map the water surface because they provide open access to high spatial and temporal resolution data. Although Sentinel-2 is better for water segmentation due to its high water absorption capacity in the short-wave infrared spectral range and near-infrared spectrum, it cannot penetrate cloud cover, limiting its application for mapping historical floods, as cloud cover is highly correlated with flooding events. On the other hand, radar pulses readily penetrate clouds, making SAR satellites well-suited for flood mapping.\n\nThresholding algorithms are traditionally used to segment flooded regions from SAR images because of the low backscatter intensity of water. However, techniques like Otsu thresholding can fail, generating false positives for mountain shadows and excessive background noise due to speckle in SAR imagery. In recent years, Convolutional Neural Networks (CNNs) have been used to segment flooded areas from satellite images. Unlike traditional pixel-wise methods, they can look at a larger context and incorporate spatial features from an image.\n\nA lot of work has focused on using opportunistically available cloud-free Sentinel-2 images. Although these methods have good performance, their utility at inference time is limited due to cloud cover issues. Another line of work fuses Sentinel-1 and Sentinel-2 images to enhance surface water detection during flooded events. These methods require a cloud-free Sentinel-2 image and both images taken at about the same time to avoid alignment issues. There has been some work done using multi-temporal images containing a pre-flood and a post-flood event. These methods can do change detection and exhibit better performance. In our work, we focus on methods that only take a single Sentinel-1 timestamp image as input.\n\nSen1Floods11 is a publicly available dataset with a small set of high-quality hand-labeled images and a larger set of weak-labeled images. Most prior work using a single Sentinel-1 image as input used this weak-labeled data to train their models. However, the limitation of using weak-labeled data is that the model still learns the mistakes in those labels. Motivated by semi-supervised methods and cross-modal feature distillation, we use a teacher-student setup that extracts information from a more informative modality (Sentinel-2)."
}