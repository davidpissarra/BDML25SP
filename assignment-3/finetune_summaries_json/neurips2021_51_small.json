{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" of the greatest sources of renewable energy and are a promising  resource to tackle climate challenges by decarbonizing energy generation.  Lowering the Levelized Cost of Energy (LCOE) for wave  energy converters is  key to competitiveness with ot her forms of clean energy like wind and solar. Also,  the complexity of control has gone up significantly with the state-of-the-art multi - generator multi -legged industrial Wave Energy Converters (WEC). This paper  introduces a Multi -Agent Reinforcement Learn ing controller (MARL)  architecture that can handle these multiple objectives for LCOE, helping the  increase in energy capture efficiency, boosting revenue, reducing structural stress  to limit maintenance and operating cost, and adaptively and proactively p rotect  the wave energy converter from catastrophic weather events, preserving  investments and lowering effective capital cost.  We use a MARL implementing  proximal policy optimization (PPO) with various optimizations to help sustain the  training convergence  in the complex hyperplane. The MARL is able to better  control the reactive forces of the generators on multiple tethers ( legs) of WEC   than the commonly deployed  spring damper controller.  The design for trust is  implemented to assure the operation of WEC within a safe zone of mechanical  compliance and guarantee mechanical integrity. This is achieved through reward  shaping for multiple objectives of energy capture and penalty for harmful motions  to minimize stress and lower the cost of maintenance. We a chieved double -digit  gains in energy capture efficiency across the waves of different principal  frequencies over the baseline Spring Damper controller with the proposed MARL  controllers.  1 Introduction and Related Work   Waves in the ocean are one of the more consistent and predictable sources of renewable energy, and  the exploitable  resource of coastal wave energy has been estimated to be over 2 TW, representing   about 16% of the world energy consumption (Yusop et al. 2020).   Some s ignificant challenges of  deploying Wave Energy Converters(WEC)  include variability of the wave time period, height, and  directionality in offshore locations, leading to the complexity of capturing energy.  Also, WEC  must  be operated to minimize maintenance cost, and withstand rare but  extreme wave conditions.   1.1 Wave Energy Controller (WEC)   The industrial WEC considered in this study is composed of a submerged cylindrical  Buoyant  Actuator (BA)  similar in structure as in Figure 1. The BA is secured to the seabed with three mooring   legs, each of which terminates on one of the three power take -offs (PTOs) located within the BA.   ______________________    * Soumyendu Sarkar is the corresponding author {Soumyendu.Sarkar@hpe.com}       2 The electric generator of the PTO resist s the extension of the mooring legs  applying varying reactive  force controlled by the RL controller, thereby generating electrical power. RL controllers need to  optimize the t iming and value of the PTO forces in relation to  the wave excitation force, which  is  key to maximizing WEC  energy capture and conversion efficiency. The different controllers  currently deployed are damping control, spring damper control, latching control, and model  predic tive control with various degrees of success  but fail to leverage multi -generator WECs  well.  1.2 Related work  There has been recent work on applying RL to control simple one -legged WECs in different  academic settings.  (Anderlini et al., 2016, 2017, 2018, 2020 ) uses RL to obtain optimal reactive  force for a two -body heaving point absorber with one degree of freedom. To our knowledge, RL  has not been used to control advanced industrial multi -legged and multi - generator WECs  with six degrees of freedom of motion, where the complexity and impact are even greater.   2 Reinforcement learning design for WEC Multi -generator control   The heterogeneity and complexity of WEC require a versatile controller like Multi -Agent  Reinforcement Learning (MARL). The three legs and the generators mounted for each of the legs  act differently, as they tend to generate different amounts of energy base d on the orientation of the  mechanical structure and wave directionality. Simpler one agent RL with multiple actions failed to  control the WEC effectively. Hence, separate agents of MARL as show n in Figure 2, were used to  control the reactive force of the generators on each of the three legs to learn the policy better.   2.1 Environment state, action, and reward  design   For training, the state information is provided as a vector represented by s, where  “e” represents the  buoy position, “g” represents the tether ex tension, and “z” represents wave exc\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and text removed:\n\nThe ocean's waves are one of the most promising sources of renewable energy and a vital resource to tackle climate challenges by decarbonizing energy generation. Lowering the Levelized Cost of Energy (LCOE) for wave energy converters is key to their competitiveness with other forms of clean energy like wind and solar. The complexity of control has increased significantly with the state-of-the-art multi-generator, multi-legged industrial Wave Energy Converters (WECs). This paper introduces a Multi-Agent Reinforcement Learning (MARL) architecture that can handle multiple objectives for LCOE, enhancing energy capture efficiency, boosting revenue, reducing structural stress to limit maintenance and operating costs, and adaptively and proactively protecting the wave energy converter from catastrophic weather events, preserving investments and lowering effective capital costs.\n\nWe use a MARL implementing Proximal Policy Optimization (PPO) with various optimizations to help sustain training convergence in the complex hyperplane. The MARL is able to better control the reactive forces of the generators on multiple tethers (legs) of WEC than the commonly deployed spring damper controller. The design for trust is implemented to ensure the operation of WEC within a safe zone of mechanical compliance and guarantee mechanical integrity. This is achieved through reward shaping for multiple objectives of energy capture and penalty for harmful motions to minimize stress and lower the cost of maintenance. We achieved double-digit gains in energy capture efficiency across waves of different principal frequencies over the baseline Spring Damper controller with the proposed MARL controllers.\n\n1. Introduction and Related Work\n\nWaves in the ocean are one of the more consistent and predictable sources of renewable energy, and the exploitable resource of coastal wave energy has been estimated to be over 2 TW, representing about 16% of the world's energy consumption (Yusop et al., 2020). Some significant challenges of deploying Wave Energy Converters (WECs) include variability of the wave time period, height, and directionality in offshore locations, leading to the complexity of capturing energy. Also, WECs must be operated to minimize maintenance costs and withstand rare but extreme wave conditions.\n\n1.1 Wave Energy Controller (WEC)\n\nThe industrial WEC considered in this study is composed of a submerged cylindrical Buoyant Actuator (BA) similar in structure to Figure 1. The BA is secured to the seabed with three mooring legs, each of which terminates on one of the three power take-offs (PTOs) located within the BA.\n\n2. The electric generator of the PTO resists the extension of the mooring legs, applying varying reactive force controlled by the RL controller, thereby generating electrical power. RL controllers need to optimize the timing and value of the PTO forces in relation to the wave excitation force, which is key to maximizing WEC energy capture and conversion efficiency. The different controllers currently deployed are damping control, spring damper control, latching control, and model predictive control with various degrees of success but fail to leverage multi-generator WECs well.\n\n1.2 Related Work\n\nThere has been recent work on applying RL to control simple one-legged WECs in different academic settings. Anderlini et al. (2016, 2017, 2018, 2020) used RL to obtain optimal reactive force for a two-body heaving point absorber with one degree of freedom. To our knowledge, RL has not been used to control advanced industrial multi-legged and multi-generator WECs with six degrees of freedom of motion, where the complexity and impact are even greater.\n\n2. Reinforcement Learning Design for WEC Multi-Generator Control\n\nThe heterogeneity and complexity of WEC require a versatile controller like Multi-Agent Reinforcement Learning (MARL). The three legs and the generators mounted for each of the legs act differently, as they tend to generate different amounts of energy based on the orientation of the mechanical structure and wave directionality. Simpler one-agent RL with multiple actions failed to control the WEC effectively. Hence, separate agents of MARL, as shown in Figure 2, were used to control the reactive force of the generators on each of the three legs to learn the policy better.\n\n2.1 Environment State, Action, and Reward Design\n\nFor training, the state information is provided as a vector represented by s, where \"e\" represents the buoy position, \"g\" represents the tether extension, and \"z\" represents wave excitation."
}