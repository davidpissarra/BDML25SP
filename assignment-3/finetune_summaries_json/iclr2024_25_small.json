{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\".ac.kr Abstract Recently, both the frequency and intensity of wildfires have increased worldwide, primarily due to climate change (Sathishkumar et al., 2023). In this paper, we propose a novel protocol for wildfire detection, leveraging semi-supervised Domain Adaptation for object detection, accompanied by a corresponding dataset designed for use by both academics and industries. Our dataset encompasses 30 times more diverse labeled scenes for the current largest benchmark wildfire dataset, HPWREN (2000), and introduces a new labeling policy for wildfire detection. Inspired by Liu et al. (2018), we propose a robust baseline, Location-Aware Object Detection for Semi-Supervised Domain Adaptation (LADA), utilizing a teacher-student (Liu et al., 2021) based framework capable of extracting translational variance features characteristic of wildfires. With only using 1% target domain labeled data, our framework significantly outperforms our source-only baseline by a notable margin of 3.8% in mean Average Precision on the HPWREN wildfire dataset. Our dataset is available at https://github.com/BloomBerry/LADA. 1 Introduction Wildfires contribute to and are exacerbated by global warming, leading to significant economic losses and ecological damage (Sathishkumar et al., 2023; Lindsey & Dahlman, 2020). Such impacts can be mitigated through the early detection of wildfires, enabling firefighters to intervene promptly. For effective mitigation, wildfire detection systems must achieve high accuracy and maintain low false positive rates (Ranadive et al., 2022). However, applying fire detection in real-world scenarios present challenges, including a domain shift between the training and testing environments that can degrade detection performance (Yoo et al., 2022). Even worse, acquiring a large volume of labeled data for the target domain is particularly challenging for infrequent events like wildfires (Kim et al., 2022). To address these challenges, this paper introduces a new protocol, semi-supervised domain adaptation(SSDA) for wildfire detection. To the best of our knowledge, this is the first paper to apply SSDA for object detection task. As depicted in Fig.1, SSDA is a combination of semi-supervised learning (SSL) and unsupervsied domain adaptation (UDA) task. It uses large amount of source domain images, while uses minimal set of target labeled images alongside a substantial corpus of target unlabeled images. SSDA setting is practical for real-world application considering labeling cost and performance. (Yu & Lin, 2023) ∗corresponding author: Nojun Kwak (nojunk@snu.ac.kr) 1arXiv:2404.01842v1  [cs.CV]  2 Apr 2024Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024 Figure 1: semi-supervised Domain Adaptation This work makes two primary contributions. First, we introduce new labels for wildfire detec- tion tasks, increasing label diversity by thirtyfold compared to existing labels within the HPWren dataset, as in Table 3. We classified source domain as previous publicily available labels and target domain as new labeled set we suggested in this paper. Second, we present a novel approach to learn translational variance characteristics of wildfires called Location-Aware Semi-Supervised Domain Adaptation (LADA) framework, which integrates Coordinate Convolution (Liu et al., 2018) with a scale-aware Faster R-CNN (Chen et al., 2021b). Our result demostrate inhanced performance accross various SSDA protocols from current state-of-the-art UDA framework (Hoyer et al., 2023). Related work. SSDA approach seeks to reduce the domain-gap between source and target using consistency regularization loss (Yu & Lin, 2023), or use cutmix augmentation for domain-mixing loss (Chen et al., 2021a). However, those methods neither applied for object detection task. Our method uses consistency regularization loss using masked augmentation similar to (Hoyer et al., 2023). 2 Methods 2.1 Proposed Dataset In this paper, we propose a refined set of labels for the HPWREN (2000) dataset. This dataset serves as a benchmark for wildfire detection tailored to individual researchers. However, direct application of this benchmark for research encounters two primary obstacles. First, the diversity and quality of the labels are limited, leading to potential overfitting issues. Specifically, the dataset comprises only 609 labeled images across 9 scenes. Second, the practice of labeling smoke with separated bounding boxes demands considerable time and efforts for annotation. We have discovered that merging these bounding boxes not only simplifies the labeling process but also improves detection performance, as illustrated in Fig. 2. Detailed results are presented in Section 3. To address these challenges, we introduce a new benchmark for semi-supervised domain adaptation in object detection, detailed in Table 1. Inspired by Li et al. (\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy data removed:\n\nAbstract:\n\nRecently, the frequency and intensity of wildfires have increased worldwide, primarily due to climate change (Sathishkumar et al., 2023). This paper proposes a novel protocol for wildfire detection, leveraging semi-supervised domain adaptation for object detection, accompanied by a corresponding dataset designed for use by both academics and industries. Our dataset encompasses 30 times more diverse labeled scenes for the current largest benchmark wildfire dataset, HPWREN (2000), and introduces a new labeling policy for wildfire detection. Inspired by Liu et al. (2018), we propose a robust baseline, Location-Aware Object Detection for Semi-Supervised Domain Adaptation (LADA), utilizing a teacher-student (Liu et al., 2021) based framework capable of extracting translational variance features characteristic of wildfires. With only 1% target domain labeled data, our framework significantly outperforms our source-only baseline by a notable margin of 3.8% in mean Average Precision on the HPWREN wildfire dataset. Our dataset is available at https://github.com/BloomBerry/LADA.\n\nIntroduction:\n\nWildfires contribute to and are exacerbated by global warming, leading to significant economic losses and ecological damage (Sathishkumar et al., 2023; Lindsey & Dahlman, 2020). Such impacts can be mitigated through the early detection of wildfires, enabling firefighters to intervene promptly. For effective mitigation, wildfire detection systems must achieve high accuracy and maintain low false positive rates (Ranadive et al., 2022). However, applying fire detection in real-world scenarios presents challenges, including a domain shift between the training and testing environments that can degrade detection performance (Yoo et al., 2022). Even worse, acquiring a large volume of labeled data for the target domain is particularly challenging for infrequent events like wildfires (Kim et al., 2022). To address these challenges, this paper introduces a new protocol, semi-supervised domain adaptation (SSDA) for wildfire detection. To the best of our knowledge, this is the first paper to apply SSDA for object detection tasks.\n\nThis work makes two primary contributions. First, we introduce new labels for wildfire detection tasks, increasing label diversity by thirtyfold compared to existing labels within the HPWREN dataset. Second, we present a novel approach to learn translational variance characteristics of wildfires called Location-Aware Semi-Supervised Domain Adaptation (LADA) framework, which integrates Coordinate Convolution (Liu et al., 2018) with a scale-aware Faster R-CNN (Chen et al., 2021b). Our results demonstrate enhanced performance across various SSDA protocols from current state-of-the-art UDA frameworks (Hoyer et al., 2023).\n\nRelated work:\n\nSSDA approaches seek to reduce the domain-gap between source and target using consistency regularization loss (Yu & Lin, 2023), or use cutmix augmentation for domain-mixing loss (Chen et al., 2021a). However, those methods neither applied for object detection tasks. Our method uses consistency regularization loss using masked augmentation similar to (Hoyer et al., 2023).\n\nMethods:\n\n2.1 Proposed Dataset:\n\nIn this paper, we propose a refined set of labels for the HPWREN (2000) dataset. This dataset serves as a benchmark for wildfire detection tailored to individual researchers. However, direct application of this benchmark for research encounters two primary obstacles. First, the diversity and quality of the labels are limited, leading to potential overfitting issues. Specifically, the dataset comprises only 609 labeled images across 9 scenes. Second, the practice of labeling smoke with separated bounding boxes demands considerable time and efforts for annotation. We have discovered that merging these bounding boxes not only simplifies the labeling process but also improves detection performance, as illustrated in Fig. 2. Detailed results are presented in Section 3. To address these challenges, we introduce a new benchmark for semi-supervised domain adaptation in object detection, detailed in Table 1. Inspired by Li et al., we propose a new labeling policy for wildfire detection, which is more efficient and effective.\n\nNote: I removed the following noisy data:\n\n- \".ac.kr\" from the abstract\n- Footnotes and corresponding author information\n- arXiv and publication information\n- Table numbers and references that were not directly related to the text\n- Some minor typos and grammatical errors\n- The sentence \"1arXiv:2404.01842v1  [cs.CV]  2 Apr 2024Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024\""
}