{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" these chal- lenges in image-based characterization of porous media using deep generative models. We present a machine learning workﬂow for characterizing porous media from limited imaging data. We develop methods for 3D image volume transla- tion and synthesis from 2D training data, apply this method to grayscale and multimodal image datasets of sandstones and shales, and simulate ﬂow through the generated volumes. Results show that the proposed image reconstruction and gen- eration approaches produce realistic pore-scale 3D representations of rock samples using only 2D training data. The models proposed here expand our capabilities for characterization of rock sam- ples and enable new understanding of pore-scale storage and recovery processes. 1. Introduction The transition to a sustainable energy future requires a com- bination of greenhouse gas sequestration, long-term adop- tion of renewable sources of energy, and near-term fuel switching to cleaner available energy resources (EIA/ARI, 2013). Three such approaches that could contribute to each of these goals are, respectively, CO 2sequestration, subsur- face H 2storage, and natural gas recovery (Zoback & Kohli, *Equal contribution1Department of Electrical Engineering, Stanford University, Stanford, CA2Department of Energy Re- sources Engineering, Stanford University, Stanford, CA. Corre- spondence to: Anthony R. Kovscek <kovscek@stanford.edu >. Proceedings of the 38thInternational Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s).2019; Hassanpouryouzband et al., 2021). One important requirement for scalable and sustainable implementation of these technologies is characterization of porous media transport properties in order to identify viable candidate reservoirs. Image-based characterization in conjunction with digital rock physics techniques is a versatile approach for under- standing properties of reservoir rocks at the pore and rock fabric scales (Ketcham & Carlson, 2001; Vega et al., 2013), but these methods often require a large number of high- contrast images. Micro- and nanoscale image datasets often suffer from data scarcity or destroy the sample during image acquisition, resulting in datasets that are either too small to estimate rock properties or preclude further experimenta- tion. Furthermore, many relevant imaging modalities, such as electron microscopy, only acquire images in 2D, but 3D information is needed to characterize fully a rock sample. Here we outline approaches to overcoming these limitations of reservoir rock imaging using deep generative models. We present a deep learning-based image characterization workﬂow, shown in Fig. 1, and outline two applications of this workﬂow: image modality translation for predicting image volumes when only 2D training data is available, and image synthesis for grayscale and multimodal porous media image volumes from 2D images. In what follows, we describe the imaging workﬂow and outline the deep learning models used for data translation and synthesis for reservoir rock images. 2. Image Modality Translation 2.1. Multimodal Imaging Overview Multimodal imaging is an emerging method for geomate- rial characterization where image data is acquired at the same scale from two or more image modalities (Aljamaan et al., 2017). While multimodal imaging is commonplace in medical imaging (Torrado-Carvajal et al., 2016; Cao et al., 2018), substantially less prior work has applied multimodal imaging to the characterization of subsurface samples. Micro- and nanoimaging modalities often present a trade- off between resolution and volume representativity. Addi-Generative Modeling of Reservoir Rock Images Figure 1. Machine learning image characterization workﬂow. Images are acquired, curated, and preprocessed into a form suitable for model training. The deep generative model is trained for applications such as image synthesis, translation, or super-resolution. The model is deployed to generate or predict images. The images are then postprocessed, often by segmentation into a simulation domain, and ﬁnally the petrophysical properties of the sample such as permeability kor porosity\u001eare analyzed. tionally, nanoimaging is often destructive. Thus, methods with high contrast and resolution often destroy samples to acquire small image volumes (Sondergeld et al., 2010), while sample-preserving methods often have comparatively lower contrast and resolution. Translation between image domains using multimodal imaging offers the potential to predict high-resolution images suitable for segmentation and estimation of transport properties from low-resolution, non-destructive images. 2.2. Volume Translation Approach In this application, we seek to predict destructively-acquired focused ion beam-scanning electron microscopy (FIB-SEM) images from non-destructive nano-computed tomography (nano-CT) images (Anderson et al., 2020b). Predicting FIB-SEM images from nano-CT data is a\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and data removed:\n\nThese challenges in image-based characterization of porous media using deep generative models are addressed. We present a machine learning workflow for characterizing porous media from limited imaging data. We develop methods for 3D image volume translation and synthesis from 2D training data, apply this method to grayscale and multimodal image datasets of sandstones and shales, and simulate flow through the generated volumes. Results show that the proposed image reconstruction and generation approaches produce realistic pore-scale 3D representations of rock samples using only 2D training data. The models proposed here expand our capabilities for characterization of rock samples and enable new understanding of pore-scale storage and recovery processes.\n\n1. Introduction\n\nThe transition to a sustainable energy future requires a combination of greenhouse gas sequestration, long-term adoption of renewable sources of energy, and near-term fuel switching to cleaner available energy resources (EIA/ARI, 2013). Three such approaches that could contribute to each of these goals are CO2 sequestration, subsurface H2 storage, and natural gas recovery (Zoback & Kohli, 2019; Hassanpouryouzband et al., 2021). One important requirement for scalable and sustainable implementation of these technologies is characterization of porous media transport properties in order to identify viable candidate reservoirs. Image-based characterization in conjunction with digital rock physics techniques is a versatile approach for understanding properties of reservoir rocks at the pore and rock fabric scales (Ketcham & Carlson, 2001; Vega et al., 2013), but these methods often require a large number of high-contrast images. Micro- and nanoscale image datasets often suffer from data scarcity or destroy the sample during image acquisition, resulting in datasets that are either too small to estimate rock properties or preclude further experimentation. Furthermore, many relevant imaging modalities, such as electron microscopy, only acquire images in 2D, but 3D information is needed to characterize fully a rock sample.\n\nHere, we outline approaches to overcoming these limitations of reservoir rock imaging using deep generative models. We present a deep learning-based image characterization workflow, shown in Figure 1, and outline two applications of this workflow: image modality translation for predicting image volumes when only 2D training data is available, and image synthesis for grayscale and multimodal porous media image volumes from 2D images.\n\n2. Image Modality Translation\n\n2.1. Multimodal Imaging Overview\n\nMultimodal imaging is an emerging method for geomaterial characterization where image data is acquired at the same scale from two or more image modalities (Aljamaan et al., 2017). While multimodal imaging is commonplace in medical imaging (Torrado-Carvajal et al., 2016; Cao et al., 2018), substantially less prior work has applied multimodal imaging to the characterization of subsurface samples. Micro- and nanoimaging modalities often present a trade-off between resolution and volume representativity. Additionally, nanoimaging is often destructive. Thus, methods with high contrast and resolution often destroy samples to acquire small image volumes (Sondergeld et al., 2010), while sample-preserving methods often have comparatively lower contrast and resolution.\n\nTranslation between image domains using multimodal imaging offers the potential to predict high-resolution images suitable for segmentation and estimation of transport properties from low-resolution, non-destructive images.\n\n2.2. Volume Translation Approach\n\nIn this application, we seek to predict destructively-acquired focused ion beam-scanning electron microscopy (FIB-SEM) images from non-destructive nano-computed tomography (nano-CT) images (Anderson et al., 2020b). Predicting FIB-SEM images from nano-CT data is a challenging task.\n\nFigure 1. Machine learning image characterization workflow. Images are acquired, curated, and preprocessed into a form suitable for model training. The deep generative model is trained for applications such as image synthesis, translation, or super-resolution. The model is deployed to generate or predict images. The images are then postprocessed, often by segmentation into a simulation domain, and finally the petrophysical properties of the sample, such as permeability and porosity, are analyzed."
}