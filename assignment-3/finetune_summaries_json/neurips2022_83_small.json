{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" in the frequency, extent, and severity of wildfires in recent years. Given the danger posed by wildland fires to people, property, wildlife, and the environment, there is an urgency to provide tools for effective wildfire management. Early detection of wildfires is essential to minimizing potentially catastrophic destruction. In this paper, we present our work on integrating multiple data sources in SmokeyNet, a deep learning model using spatio-temporal information to detect smoke from wildland fires. Camera image data is integrated with weather sensor measurements and processed by SmokeyNet to create a multimodal wildland fire smoke detection system. We present our results comparing performance in terms of both accuracy and time-to-detection for multimodal data vs. a single data source. With a time-to-detection of only a few minutes, SmokeyNet can serve as an automated early notification system, providing a useful tool in the fight against destructive wildfires. 1 Introduction Research has shown that climate change creates warmer temperatures and drier conditions, leading to longer wildfire seasons and increased wildfire risks in many areas in the United States [ 1][2]. These factors have in turn led to increases in the frequency, extent, and severity of wildfires [ 3]][4] According to the National Centers for Environmental Information (NCEI) [5], which keeps track of weather and climate events with significant economic impacts, there have been 20 wildfire events exceeding $1 billion in damages in the United States from 1980 to 2022, and 16 of those have occurred since 2000 [ 3]. In the western United States, climate change has doubled the forest fire area from 1984 to 2015 [6]. Given the danger posed by wildland fires to people, property, wildlife, and the environment, there is an urgency to provide tools for effective wildfire management. Early detection of wildfires is essential to minimizing potentially catastrophic destruction. Currently, wildfires are detected by humans: scouts trained to be on the lookout for wildfires, residents in an area, or passersby. We propose here a system for automated wildfire smoke detection to provide early notification of wildfires. In previous work [ 7], we introduced FIgLib (Fire Ignition Library), a dataset of labeled wildfire smoke images from fixed-view cameras, and SmokeyNet, a novel deep learning architecture using spatio-temporal information from camera imagery to detect smoke from wildland fires. Here, we extend that work by investigating the use of multiple data sources to improve performance in terms of both accuracy and time-to-detection. Specifically, we integrate weather sensor measurements with camera imagery to create a multimodal wildland fire smoke detection system. ∗Corresponding Author: mhnguyen@ucsd.edu Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.2 Data The work presented in this paper makes use of two different types of data: camera imagery and weather sensor measurements. 2.1 FIgLib Data Camera imagery comes from the Fire Ignition images Library (FIgLib) dataset [ 8]. The FIgLib dataset consists of sequences of wildfire images captured from fixed cameras at HPWREN sites [ 9]. Each fire contains 80 minutes of MP4 high resolution video feed, with 40 minutes prior to the beginning of the fire and 40 minutes after the beginning of the fire, providing negative and positive samples of fire images, respectively. After removing out-of-distribution sequences (e.g., night fires), sequences with missing and/or mislabeled annotations, and sequences without matching weather data, a subset of 255 fires remained. This subset was partitioned into 131 fires for training (51.4%), 63 fires for validation (24.7%), and 61 fires for testing (23.9%). 2.2 Weather Data Weather data in the HPWREN[ 10][9], SDG&E[ 11], SC-Edison[ 12] networks is fetched from weather stations using the Synoptic’s Mesonet API[ 13]. Synoptic is a service that helps in storing and serving weather data. The weather data has 23 attributes, out of which we selected the ones that have under 5% missing data for the FIgLib time frame of 03 June 2016 to 12 July 2021. These filtered attributes are: air temperature, relative humidity, wind speed, wind gust, wind direction, and dew point temperature. Wind speed and wind direction can be expressed as the radius and angle in a polar coordinate system [ 14], which are then used to obtain cartesian co-ordinates [ 15]− →uand− →v. This is done in aggregating the weather data. 3 Methods This section presents methods used for data preparation and model building. 3.1 Data Preparation The FIgLib data and the weather data have to be pre-processed before being fed into the model. This subsection discusses the procedures that we followed. FIgLib Data The images of the FIgLIb\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy text removed:\n\nIn recent years, there has been an increase in the frequency, extent, and severity of wildfires. Given the danger posed by wildland fires to people, property, wildlife, and the environment, there is an urgent need for effective wildfire management tools. Early detection of wildfires is essential to minimize potentially catastrophic destruction. This paper presents our work on integrating multiple data sources in SmokeyNet, a deep learning model that uses spatio-temporal information to detect smoke from wildland fires. We integrate camera image data with weather sensor measurements and process them using SmokeyNet to create a multimodal wildland fire smoke detection system. Our results show improved performance in terms of both accuracy and time-to-detection for multimodal data compared to a single data source. With a time-to-detection of only a few minutes, SmokeyNet can serve as an automated early notification system, providing a useful tool in the fight against destructive wildfires.\n\nIntroduction\nResearch has shown that climate change leads to warmer temperatures and drier conditions, resulting in longer wildfire seasons and increased wildfire risks in many areas in the United States. These factors have led to increases in the frequency, extent, and severity of wildfires. According to the National Centers for Environmental Information, there have been 20 wildfire events exceeding $1 billion in damages in the United States from 1980 to 2022, with 16 of those occurring since 2000. Climate change has also doubled the forest fire area in the western United States from 1984 to 2015. Given the danger posed by wildland fires, there is an urgent need for effective wildfire management tools. Early detection of wildfires is essential to minimize potentially catastrophic destruction.\n\nCurrently, wildfires are detected by humans, including scouts, residents, and passersby. We propose a system for automated wildfire smoke detection to provide early notification of wildfires. In previous work, we introduced FIgLib, a dataset of labeled wildfire smoke images from fixed-view cameras, and SmokeyNet, a novel deep learning architecture using spatio-temporal information from camera imagery to detect smoke from wildland fires. Here, we extend that work by investigating the use of multiple data sources to improve performance in terms of both accuracy and time-to-detection.\n\nData\nThe work presented in this paper makes use of two different types of data: camera imagery and weather sensor measurements.\n\n2.1 FIgLib Data\nThe FIgLib dataset consists of sequences of wildfire images captured from fixed cameras at HPWREN sites. Each fire contains 80 minutes of high-resolution video feed, with 40 minutes prior to the beginning of the fire and 40 minutes after the beginning of the fire, providing negative and positive samples of fire images, respectively. After removing out-of-distribution sequences, sequences with missing and/or mislabeled annotations, and sequences without matching weather data, a subset of 255 fires remained. This subset was partitioned into 131 fires for training (51.4%), 63 fires for validation (24.7%), and 61 fires for testing (23.9%).\n\n2.2 Weather Data\nWeather data from the HPWREN, SDG&E, and SC-Edison networks is fetched from weather stations using the Synoptic's Mesonet API. The weather data has 23 attributes, out of which we selected the ones with under 5% missing data for the FIgLib time frame of June 2016 to July 2021. These filtered attributes are: air temperature, relative humidity, wind speed, wind gust, wind direction, and dew point temperature. Wind speed and wind direction can be expressed as the radius and angle in a polar coordinate system, which are then used to obtain cartesian coordinates.\n\n3 Methods\nThis section presents methods used for data preparation and model building.\n\n3.1 Data Preparation\nThe FIgLib data and the weather data have to be pre-processed before being fed into the model. This subsection discusses the procedures that we followed. The images of the FIgLib dataset were pre-processed to remove out-of-distribution sequences, sequences with missing and/or mislabeled annotations, and sequences without matching weather data. The weather data was filtered to select attributes with under 5% missing data for the FIgLib time frame."
}