{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\", we explore three deep network algorithms to infer these pa- rameters in an objective and data-driven way. We compare the performance of a fully-connected net- work, a one-dimensional and, a two-dimensional convolutional networks to recover the underlying parameters of the Lorenz-96 model, a non-linear dynamical system that has similar behavior to the climate system. 1. Introduction The global warming target of the 2015 Paris Agreement is2\u000eC above pre-industrial level. How much greenhouse gases can accumulate in the atmosphere before this thresh- old is crossed? There is no certain answer to this question. There has not been one for decades because of the very large spread in climate models used to predict this target. The answers vary from 480 ppm, which will be reached around 2030, to 600 ppm, which will be reached much later after 2060 (Schneider et al., 2017b). Optimal emission path- ways, policy responses, and socioeconomic costs of climate change vary vastly between the high and low end of this range. What lies behind this recalcitrant uncertainty is the coarse 1Department of computer science, University of Toronto, ON, Canada2Department of Earth and Environmental Engineering, Earth Institute, and Data Science Institute, Columbia University, New York, NY, USA. Correspondence to: Soukayna Mouatadid <soukayna@cs.toronto.edu >. The36thInternational Conference on Machine Learning - Cli- mate Change Workshop, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s).resolution of global climate models (GCMs), which hin- ders resolving crucial processes like cloud formation and moist convection (Stevens & Bony, 2013). Climate models compute solutions to the laws of thermodynamics and ﬂuid dynamics on computational grids. These grids have a typi- cal scale varying from 10 to 150 km. Cloud formation takes place on smaller scales (i.e., 2 km or less) and cannot be resolved by current climate models. Therefore, clouds are modeled by heuristically approximated ”parameterization” schemes. These parameterization schemes include uncertain parameters, selected by climate scientists based on expe- rience and intuition (Hourdin et al., 2017) but not as sys- tematically informed by data. In addition, the non-linearity of the climate system means that climate simulations can depend sensitively and in unexpected ways on these parame- ters (Zhao et al., 2016), which is why we still cannot answer our initial question with certainty. In this study, we show that deep learning can provide an objective, data-driven and computationally efﬁcient approach to parameters estimation for sub-grid parameterization. We illustrate this idea using the Lorenz-96 model (Lorenz, 1996). 2. Lorenz-96 model The Lorenz-96 model is a dynamical system that behaves in a non-linear way resembling the non-linear behavior of the climate system and consists of a coupling of variables evolving over slow and fast timescales (Schneider et al., 2017a). The model consists of Kslow variables, where each slow variable Xk; k= 1; :::; K is coupled with J fast variables Yj;k; j= 1; :::; J. The model is governed by K+JKequations: dXk dt=\u0000Xk\u00001(Xk\u00002\u0000Xk+1)\u0000X\u0000k+F\u0000hcYk(1) 1 cdYj;k dt=\u0000bYj+1;k(Yj+2;k\u0000Yj\u00001;k)\u0000Yj;k+h JXk(2) where Yk=1 JJX j=1Yj;k (3) The slow variables Xrepresent resolved-scale variables in a climate model, while the fast variables Yrepresent unre- solved variables (e.g., turbulence and convection). This setRecovering the parameters underlying the Lorenz-96 chaotic dynamics of equations are coupled through the mean term Ykand this coupling is controlled by three keys parameters: b,cand h. The parameter bcontrols the amplitude of the nonlinear interactions among the fast variables, while the parameter c controls how rapidly the fast variables ﬂuctuate relative to the slow variables and the parameter hcontrols how strong the coupling between the fast and slow variables is. The goal of this study is to investigate the viability of parame- ter estimation using three learning models, namely a fully connected network (FC), a one-dimensional convolutional network (Conv1D) and a two-dimensional convolutional network (Conv2D). 3. Data and methodology The Lorenz-96 (L-96) model was used to generate 200 sim- ulations for four slow variables X, each associated with four fast variables Y. Each simulation was generated using a different combination of b,candh\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and data removed:\n\nWe explore three deep network algorithms to infer parameters in an objective and data-driven way. We compare the performance of a fully-connected network, a one-dimensional convolutional network, and a two-dimensional convolutional network to recover the underlying parameters of the Lorenz-96 model, a non-linear dynamical system that exhibits similar behavior to the climate system.\n\nThe global warming target of the 2015 Paris Agreement is 2°C above pre-industrial levels. However, there is no certain answer to the question of how much greenhouse gases can accumulate in the atmosphere before this threshold is crossed. Climate models used to predict this target vary widely, with answers ranging from 480 ppm, which will be reached around 2030, to 600 ppm, which will be reached much later after 2060 (Schneider et al., 2017b). Optimal emission pathways, policy responses, and socioeconomic costs of climate change vary greatly between the high and low ends of this range.\n\nThe uncertainty behind this range is due to the coarse resolution of global climate models (GCMs), which hinders resolving crucial processes like cloud formation and moist convection (Stevens & Bony, 2013). Climate models compute solutions to the laws of thermodynamics and fluid dynamics on computational grids, which have a typical scale varying from 10 to 150 km. Cloud formation occurs on smaller scales (i.e., 2 km or less) and cannot be resolved by current climate models. Therefore, clouds are modeled using heuristically approximated \"parameterization\" schemes. These schemes include uncertain parameters, selected by climate scientists based on experience and intuition (Hourdin et al., 2017) but not systematically informed by data. Additionally, the non-linearity of the climate system means that climate simulations can depend sensitively and in unexpected ways on these parameters (Zhao et al., 2016), which is why we still cannot answer our initial question with certainty.\n\nIn this study, we show that deep learning can provide an objective, data-driven, and computationally efficient approach to parameter estimation for sub-grid parameterization. We illustrate this idea using the Lorenz-96 model (Lorenz, 1996).\n\nThe Lorenz-96 model is a dynamical system that behaves in a non-linear way, resembling the non-linear behavior of the climate system, and consists of a coupling of variables evolving over slow and fast timescales (Schneider et al., 2017a). The model consists of K slow variables, where each slow variable Xk (k = 1,..., K) is coupled with J fast variables Yj,k (j = 1,..., J). The model is governed by K + J equations:\n\ndXk/dt = Xk-1(Xk-2 - Xk+1) - Xk + F*h*Yk\ndYj,k/dt = -b*Yj+1,k(Yj+2,k - Yj-1,k) - Yj,k + h*J*Xk\n\nwhere Yk = 1/J * Σj=1 to J Yj,k\n\nThe slow variables X represent resolved-scale variables in a climate model, while the fast variables Y represent unresolved variables (e.g., turbulence and convection). This set of equations are coupled through the mean term Yk, and this coupling is controlled by three key parameters: b, c, and h. The parameter b controls the amplitude of the non-linear interactions among the fast variables, while the parameter c controls how rapidly the fast variables fluctuate relative to the slow variables, and the parameter h controls how strong the coupling between the fast and slow variables is.\n\nThe goal of this study is to investigate the viability of parameter estimation using three learning models: a fully connected network (FC), a one-dimensional convolutional network (Conv1D), and a two-dimensional convolutional network (Conv2D).\n\nThe Lorenz-96 model was used to generate 200 simulations for four slow variables X, each associated with four fast variables Y. Each simulation was generated using a different combination of b, c, and h."
}