{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"ﬁcation of blade damages are still experimental and focus on optimizing the traditional machine learning metrics such as IoU. In this paper, we argue that pushing models to production long before achieving the \"optimal\" model performance can still generate real value for this use case. We discuss the performance of our damage’s suggestion model in production and how this system works in coordination with humans as part of a commercialized product and how it can contribute towards lowering wind energy’s operational costs. 1 Introduction In order to replace fossil fuels, renewable energy sources such as wind need to achieve a levelized cost competitive to that of the former, which is primarily responsible for CO 2emissions [ 3]. One of the major hurdles to wind energy is the high operational cost, which accounts for about 25% of the cost of energy compared to around 10% for natural gas [ 1]. During the operations of wind turbines, damages on blades is the leading cause of turbine failures [ 5]. The beneﬁts to detecting these damages early are two fold: keeping the turbines less susceptible to downtime, and lowering the costs of ﬁxing these damages by not allowing damages to worsen over time. These beneﬁts are key because ultimately, a wind turbine needs to be operational to generate revenue. The use of drones with cameras offers an attractive solution to ﬁnding damages on blades. Au- tonomous drones can traverse the blades and take pictures along the way with minimal to no human intervention. To this end, we have built and commercialized a drone inspection system. After each turbine inspection, the pictures are uploaded to a portal that then presents these pictures to a team of trained analysts to identify and categorize the damages. In light of lowering the cost of maintenance, analysts need to: 1. Miss fewer damages, and 2. Take less time to mark damages. Traditionally, analysts ﬁnd damages manually by drawing a polygon around the area of damage, as shown in 1a. However, sometimes even experienced analysts miss damages. The reason is that the blade is fairly large with respect to the damages, as shown in 1d. In addition, there are often multiple damages in one picture. Analysts can also miss damages simply because of fatigue. We aim to help analysts increase accuracy and productivity through an automated damage suggestion system. Recognizing the importance of this problem, a number of authors have proposed different approaches for damage detection of wind turbines blades from drone images. A two-stage learning approach was proposed in [ 10]. First, a feature extractor was trained, then a classiﬁer to categorize damages on blades. Another work attempted to classify damages on close-up pictures using different deep learning architectures [ 9]. [7] conducted a wind turbine inspection with a multicopter and used traditional 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.(a) Ground truth polygon (green) and bounding box (red) (b) Damage predicted by our system: Prediction mask and minimum area rectangle around it (blue) (c) Agreement between analysts and our system (d) Original inspection picture. Note that the damage is at the tip of the blade computer vision algorithm to detect damages. [ 6] proposed an automated suggestion system for damage detection that was based on Faster-RCNN. The system’s mAP scores were compared to that of humans. These works are critically valuable in discovering new architectures or methodologies to ML problems. However, the real-world beneﬁts often cannot be realized in the performances on test datasets or baked into a loss function. Neither the amount of time spent on annotating inspection pictures nor the chance of missing damages is tunable at the model level. Hence, our solution is to put the models in front of analysts quickly and to place more weight on iteratively optimizing how the model was used, rather than focusing on achieving better results on a ﬁxed test dataset. We believe that this is fundamentally different from prior works in this area. In this work, we describe an automated damage suggestion system, designed speciﬁcally to achieve these two goals. We establish the following criteria, which better measures how successful a blade damage detection model is, as such a system must be evaluated by the values driven for users. These values are rarely manifested in the common process of tuning a machine learning (ML) model. •The model must achieve high damage recall. That is, the model should be able to produce predictions that are close to the actual damage. The predictions and ground truths do not have to be an exact overlap, but do need to be greater than a certain IoU threshold. More than one prediction per actual damage is acceptable, as long as the actual damage is not missed. Note that we ignore pixel-level recall entirely. •The integration of the model into the current workﬂow must not slow down analysts in annotating blade damages. We achieve this by presenting the predictions from the model as polygons analysts can simply choose from instead of having to draw\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy characters and irrelevant data removed:\n\nThe classification of blade damages is still experimental and focuses on optimizing traditional machine learning metrics such as Intersection over Union (IoU). In this paper, we argue that pushing models to production before achieving optimal model performance can still generate real value for this use case. We discuss the performance of our damage suggestion model in production and how it works in coordination with humans as part of a commercialized product, contributing to lowering wind energy's operational costs.\n\nIntroduction\n\nTo replace fossil fuels, renewable energy sources like wind need to achieve a levelized cost competitive to that of the former, primarily responsible for CO2 emissions. One of the major hurdles to wind energy is the high operational cost, accounting for about 25% of the cost of energy compared to around 10% for natural gas. During wind turbine operations, damages on blades are the leading cause of turbine failures. Detecting these damages early has two benefits: keeping turbines less susceptible to downtime and lowering the costs of fixing these damages by preventing them from worsening over time. These benefits are crucial because ultimately, a wind turbine needs to be operational to generate revenue.\n\nThe use of drones with cameras offers an attractive solution to finding damages on blades. Autonomous drones can traverse the blades and take pictures with minimal to no human intervention. We have built and commercialized a drone inspection system. After each turbine inspection, the pictures are uploaded to a portal that presents them to a team of trained analysts to identify and categorize the damages. In light of lowering maintenance costs, analysts need to:\n\n1. Miss fewer damages\n2. Take less time to mark damages\n\nTraditionally, analysts find damages manually by drawing a polygon around the area of damage. However, even experienced analysts may miss damages due to the large size of the blade relative to the damages or fatigue. We aim to help analysts increase accuracy and productivity through an automated damage suggestion system.\n\nRecognizing the importance of this problem, several authors have proposed different approaches for damage detection of wind turbine blades from drone images. A two-stage learning approach was proposed, where a feature extractor was trained, followed by a classifier to categorize damages on blades. Another work attempted to classify damages on close-up pictures using different deep learning architectures. A study conducted a wind turbine inspection with a multicopter and used a traditional computer vision algorithm to detect damages. An automated suggestion system for damage detection was proposed based on Faster-RCNN, with its mAP scores compared to those of humans.\n\nHowever, the real-world benefits of these works often cannot be realized in test dataset performances or baked into a loss function. Neither the time spent on annotating inspection pictures nor the chance of missing damages is tunable at the model level. Our solution is to put the models in front of analysts quickly and focus on iteratively optimizing how the model is used, rather than achieving better results on a fixed test dataset.\n\nWe believe this approach is fundamentally different from prior works in this area. In this work, we describe an automated damage suggestion system designed to achieve the two goals mentioned above. We establish the following criteria to measure the success of a blade damage detection model:\n\n• The model must achieve high damage recall, producing predictions close to the actual damage. The predictions and ground truths do not have to be an exact overlap, but must be greater than a certain IoU threshold. More than one prediction per actual damage is acceptable, as long as the actual damage is not missed.\n• The integration of the model into the current workflow must not slow down analysts in annotating blade damages. We achieve this by presenting the predictions from the model as polygons analysts can choose from instead of having to draw them."
}