{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\", conventionally used for monitoring terrestrial vertebrates, are now being modified for insects, especially moths. We describe a complete, open-source machine learning-based software pipeline for automated monitoring of moths via camera traps, including object detection, moth/non-moth classification, fine-grained identification of moth species, and tracking individuals. We believe that our tools, which are already in use across three continents, represent the future of massively scalable data collection in entomology. 1 Introduction The Earth is undergoing a sixth mass extinction event, where an eighth of all species may become extinct by 2100 [ 1–3]. Insects account for about half of all living species on earth and 40% of the animal biomass [ 4], but both the diversity and abundance of insects are undergoing a precipitous decline [ 5] as a result of several factors, in which climate change figures prominently. The “insect apocalypse” significantly increases the risk of breakdown of ecosystem functions on which human society depends [ 6]. Monitoring insects is therefore a crucial component of climate change adaptation. Traditional insect collection and identification by entomologists is hard to scale, due to the massive number of insect species and a lack of experts, with certain geographies and taxonomic groups espe- cially poorly covered. The emergence of high-resolution cameras, low-cost sensors, and processing methods based on machine learning (ML) has the potential to fundamentally change insect monitoring methods [ 7]. Camera traps powered by computer vision models for terrestrial vertebrates monitoring are now commonplace [ 8], and specialized camera trap hardware for insect monitoring has begun to gain momentum [ 9–13]. A common group of focus for such studies has been moths[ 14–16], which serve vital ecological roles and represent a fifth of all insect species. Importantly, most moths can readily be attracted with UV light and are frequently visually distinguishable up to species or genus, making them ideal targets for camera traps. As hardware for moth-monitoring has grown more common, however, there is a need for scalable data processing techniques to match the influx of data. Prior methods have been greatly limited in the species and geography covered, as well as requiring extensive manual labelling for training the algorithms. ∗Equal contribution. †Corresponding author ( aditya.jain@mila.quebec ). ‡Work done while at Mila - Quebec AI Institute. Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.(a) A moth camera trap  (b) Trap in operation  (c) Machine learning predictions on a raw image Figure 1: Figure 1a and Figure 1b depict a moth camera trap used by our partners. Figure 1c shows our insect localization and species prediction on a raw image, with red boxes showing insects classified as moths (with fine-grained species predictions), and blue boxes showing non-moths. This work describes a complete software and ML framework that transforms raw photos from insect camera traps into species-level moth data (see Fig. 1). Our system is motivated by the following goals: 1) Model predictions should be highly accurate across moth species, 2) the presence of non-moths must be accounted for, 3) the algorithms should work across different hardware setups (camera, lighting, etc.) and geographic regions, 4) extensive manual labelling of training images should not be required, 5) the pipeline should be fast to run, 6) the system should be user-friendly for non-ML experts, and 7) the framework should easily be extended to other insect groups. Our tools are currently supporting multiple deployments in Canada, the USA, the UK, Denmark, and Panama. 2 Machine learning pipeline Our machine learning pipeline in a multi-stage process (Figure 2): 1) An object detector localizes all insects in the image (§2.2), 2) a binary image classifier distinguishes moths from other arthropods (§2.3), 3) the classified moths pass through a fine-grained moth species classifier to predict the species (§2.4), and 4) a tracking algorithm tracks the moths across frames to count the number of individuals (§2.5). Such a modular structure allows parallel development, improvement, and evaluation of each module. We now discuss each module in detail. Figure 2: Machine learning workflow. 2.1 Training data for image classification We need labelled data to train the binary and fine-grained species classifier. However, labelling data from the trap images directly is not scalable. The trap data likely would not include all rare species, labelling would be redone periodically with every change in hardware and new geographic location, and experts for species identification are scarce. We perform zero-shot transfer learning – training on a visually different dataset from the moth trap images. Specifically, we use annotated data indexed by the Global Biodiversity Information Facility (GBIF) [ 17], in particular from the citizen\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy parts removed:\n\nThe conventional methods used for monitoring terrestrial vertebrates are being adapted for insects, particularly moths. We present a complete, open-source machine learning-based software pipeline for automated moth monitoring using camera traps, including object detection, moth/non-moth classification, fine-grained species identification, and individual tracking. Our tools, already in use across three continents, represent the future of scalable data collection in entomology.\n\nThe Earth is experiencing a sixth mass extinction event, with an estimated eighth of all species facing extinction by 2100. Insects account for half of all living species and 40% of animal biomass, but their diversity and abundance are declining due to factors including climate change. Monitoring insects is crucial for climate change adaptation. Traditional insect collection and identification by entomologists is challenging due to the vast number of species and lack of experts, particularly in certain geographies and taxonomic groups.\n\nThe emergence of high-resolution cameras, low-cost sensors, and machine learning-based processing methods has the potential to revolutionize insect monitoring. Camera traps powered by computer vision models for terrestrial vertebrates are now common, and specialized camera trap hardware for insect monitoring is gaining momentum. Moths, which serve vital ecological roles and represent a fifth of all insect species, have been a focus of such studies. They can be easily attracted with UV light and are frequently visually distinguishable up to species or genus, making them ideal targets for camera traps.\n\nAs moth-monitoring hardware becomes more widespread, there is a need for scalable data processing techniques to match the influx of data. Prior methods have been limited in the species and geography covered, and required extensive manual labeling for training algorithms.\n\nWe describe a complete software and machine learning framework that transforms raw photos from insect camera traps into species-level moth data. Our system aims to achieve the following goals: 1) high accuracy across moth species, 2) account for non-moths, 3) work across different hardware setups and geographic regions, 4) not require extensive manual labeling, 5) be fast to run, 6) be user-friendly for non-ML experts, and 7) easily be extended to other insect groups.\n\nOur tools are currently supporting multiple deployments in Canada, the USA, the UK, Denmark, and Panama.\n\nOur machine learning pipeline is a multi-stage process: 1) an object detector localizes all insects in the image, 2) a binary image classifier distinguishes moths from other arthropods, 3) the classified moths pass through a fine-grained moth species classifier to predict the species, and 4) a tracking algorithm tracks the moths across frames to count the number of individuals.\n\nWe use a modular structure that allows parallel development, improvement, and evaluation of each module. We discuss each module in detail below.\n\nWe use labeled data from the Global Biodiversity Information Facility (GBIF) for training the binary and fine-grained species classifier, as direct labeling of trap images is not scalable. This approach allows us to train the algorithms without requiring extensive manual labeling."
}