{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" difficult to compare optimal products and processes between different studies. To aid policymakers and LCA practitioners alike, we plan to leverage large language models (LLM) to build a database containing documented assumptions for LCAs across the agricultural sector, with a case study on livestock management. The articles for this database are identified in a systematic literature search, then processed to extract relevant assumptions about the goal and scope definition of the LCA and inserted into a vector database. We then leverage this database to develop an AI co-pilot by augmenting LLMs with retrieval augmented generation to be used by stakeholders and LCA practitioners alike. This co-pilot will accrue two major benefits: 1) enhance the decision-making process through facilitating comparisons among LCAs to enable policymakers to adopt data-driven climate policies and 2) encourage the use of common assumptions by LCA practitioners. Ultimately, we hope to create a foundational model for LCA tasks that can plug-in with existing open source LCA software and tools. 1 Introduction Life cycle assessments (LCA) are a pre-eminent and commonly used model to evaluate the en- vironmental and climate impacts of products and processes, as well as providing the basis for climate-informed decision-making (e.g. [ 1]). While the stages and contents of LCAs are standardized [2], different studies on the same process or product may share the same functional unit but include different processes in the system boundary. This inconsistency complicates the use of LCAs as a decision-support tool for formulating climate-smart policies and increases the time necessary to compare the results from the LCA studies. In the worst case, the decision maker might make an incorrect choice based on the high-level findings, or might take significant time trying to understand how the different assumptions affect the LCA results. To address these problems, large language models (LLMs) can be utilized across all four stages of the LCA, from assisting practitioners in identifying the goal and scope of the LCA, establishing Tackling Climate Change with Machine Learning: workshop at NeurIPS 2024.Figure 1: Overview of the key strategies and benefits to improve the usability of life cycle assessments (LCA) as the basis for climate-smart decision making through large language models (LLM), includ- ing developing an LCA benchmarking dataset and implementing retrieval augmented generation, with the ultimate goal of developing a foundation model (FM) for LCA. provenance for emissions factors, and visualizing and interpreting results [ 3]. LLMs are emerging artificial intelligence methods that act as sophisticated tools to mimic human writing [ 4], and have achieved human-expert level accuracy across a variety of natural language tasks [ 5,6,7]. As a result, LLMs are already being used to manage life cycle inventory data, such as the TianGong AI project [8] and AutoPCF [ 9]. Moreover, fine-tuned BERT models are used for impact factor matching [ 10] and supply chain emissions estimation [ 11]. Up to this point, the use of language models has been confined to impact factor matching and other life cycle inventory collection tasks. In this study, we use LLMs to analyze the goal and scope definition assumptions to achieve two goals: increase the consistency of LCA studies by giving practitioners tools to utilize consistent assumption for certains systems, as well as enabling policy-makers to closely interrogate and analyze LCA results and assumptions, aiding the adoption of climate-smart policies and increasing the transparency of the decision-making process. This can streamline the process of conducting and interpreting LCAs, increasing comparability and transparency while increasing their usefulness as a support tool for climate-smart decision making. Ultimately, we look to create a foundational model for LCAs, as outlined in Figure 1, which could potentially make sustainability assessments more accessible and encourage wider adoption in agriculture and other LCA-intensive sectors. In this project, we conduct a systematic literature review to extract LCA studies on livestock production systems in the agricultural sector. These studies are then processed to form a high-quality dataset that is processed and stored in a vector database, which is referenced through retrieval augmented generation (RAG) to create an LLM co-pilot for both decision makers and LCA practitioners. 2 Proposed work To build a high-quality LCA-based dataset and a proof-of-concept LLM co-pilot using vector databases and RAG, we conduct a systematic literature review of life cycle assessments in livestock 2agricultural systems. Manuscripts were identified in academic journal databases, then screened to ensure that the articles are in english, have the full text available, and contain the correct systems and LCA steps. The text is extracted from these articles, chunked, and indexed in a vector database for RAG implementation. We choose agriculture as a sector due to the demonstrated success of applying LLM co-pilots as agronomist assistants [ 12,13,14], and we focus specifically on livestock systems due to the excessive variety of functional units and system boundary assumptions\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy data removed:\n\nTo compare optimal products and processes between different studies is challenging. To aid policymakers and LCA practitioners, we plan to leverage large language models (LLMs) to build a database containing documented assumptions for LCAs across the agricultural sector, with a case study on livestock management. We identify relevant articles through a systematic literature search, extract relevant assumptions about the goal and scope definition of the LCA, and insert them into a vector database. We then use this database to develop an AI co-pilot by augmenting LLMs with retrieval augmented generation to be used by stakeholders and LCA practitioners. This co-pilot will have two major benefits: 1) enhance the decision-making process through facilitating comparisons among LCAs to enable policymakers to adopt data-driven climate policies and 2) encourage the use of common assumptions by LCA practitioners. Ultimately, we aim to create a foundational model for LCA tasks that can integrate with existing open-source LCA software and tools.\n\nLife cycle assessments (LCA) are a widely used model to evaluate the environmental and climate impacts of products and processes, as well as provide the basis for climate-informed decision-making. While the stages and contents of LCAs are standardized, different studies on the same process or product may share the same functional unit but include different processes in the system boundary. This inconsistency complicates the use of LCAs as a decision-support tool for formulating climate-smart policies and increases the time necessary to compare the results from LCA studies. To address these problems, large language models (LLMs) can be utilized across all four stages of the LCA, from assisting practitioners in identifying the goal and scope of the LCA, establishing provenance for emissions factors, and visualizing and interpreting results.\n\nLLMs are emerging artificial intelligence methods that can mimic human writing and have achieved human-expert level accuracy across various natural language tasks. As a result, LLMs are being used to manage life cycle inventory data, such as the TianGong AI project and AutoPCF. Fine-tuned BERT models are also used for impact factor matching and supply chain emissions estimation. In this study, we use LLMs to analyze the goal and scope definition assumptions to achieve two goals: increase the consistency of LCA studies by giving practitioners tools to utilize consistent assumptions for certain systems, and enable policymakers to closely interrogate and analyze LCA results and assumptions, aiding the adoption of climate-smart policies and increasing the transparency of the decision-making process.\n\nThis can streamline the process of conducting and interpreting LCAs, increasing comparability and transparency while increasing their usefulness as a support tool for climate-smart decision making. Ultimately, we aim to create a foundational model for LCAs, which could make sustainability assessments more accessible and encourage wider adoption in agriculture and other LCA-intensive sectors.\n\nIn this project, we conduct a systematic literature review to extract LCA studies on livestock production systems in the agricultural sector. These studies are then processed to form a high-quality dataset that is stored in a vector database, which is referenced through retrieval augmented generation (RAG) to create an LLM co-pilot for both decision makers and LCA practitioners.\n\nTo build a high-quality LCA-based dataset and a proof-of-concept LLM co-pilot using vector databases and RAG, we conduct a systematic literature review of life cycle assessments in livestock agricultural systems. We identify manuscripts in academic journal databases, screen them to ensure they meet the criteria, and extract the text, which is then chunked and indexed in a vector database for RAG implementation. We choose agriculture as a sector due to the demonstrated success of applying LLM co-pilots as agronomist assistants, and we focus on livestock systems due to the excessive variety of functional units and system boundary assumptions."
}