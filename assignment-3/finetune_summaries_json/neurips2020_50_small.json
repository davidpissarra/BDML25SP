{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\" km and approximate any process occurring below this scale (e.g. thunderstorms) using so-called parametrizations. Machine learning could improve upon the accuracy of some traditional physical parametrizations by learning from so-called global cloud-resolving models. We compare the performance of two machine learning models, random forests (RF) and neural networks (NNs), at parametrizing the aggregate effect of moist physics in a 3 km resolution global simulation with an atmospheric model. The NN outperforms the RF when evaluated ofﬂine on a testing dataset. However, when the ML models are coupled to an atmospheric model run at 200 km resolution, the NN-assisted simulation crashes with 7 days, while the RF-assisted simulations remain stable. Both runs produce more accurate weather forecasts than a baseline conﬁguration, but globally averaged climate variables drift over longer timescales. 1 Introduction Machine learning has the potential to improve the accuracy of climate models but should take advantage of our existing physical knowledge. Climate and weather models represent the motions of the Earth’s atmosphere as a system of discretized ordinary differential equations (ODEs). Some of these terms are well-known from ﬁrst principles such as the Navier-Stokes equations and radiative transfer. However, climate models typically have a horizontal grid-size of 100 km (Intergovernmental Panel on Climate Change, 2014) and cannot resolve the dominant physical scales of some atmospheric processes, especially turbulence, cumulus convection, and cloud-radiation interactions; these must be parametrized. We call those processes that involve the formation of clouds and precipitation the ‘moist physics’. New simulations called global cloud resolving models (GCRMs), which explicitly resolve key aspects of global cloud ﬁelds associated with precipitating cumulus convection by using horizontal grid scales of less than 5 km (Satoh et al., 2019), are currently too expensive for long climate simulations but contain a wealth of information about how clouds interact with the large-scale—a valuable training dataset for inexpensive machine learning (ML) parametrizations. Sub-grid-scale parametrization is a function approximation problem. Let the ODEs describing a climate model can be divided into two components as follows dxi dt=gi(x;t) +f(xi;\u0012): (1) The known physics gaccount for large-scale atmospheric ﬂuid mechanics as well as some set of known physics, and are a function of the non-local state x. The vector xrepresents the state of the \u0003Corresponding author Tackling Climate Change with Machine Learning workshop at NeurIPS 2020.global atmosphere (e.g. temperature, humidity, and wind). Because the atmosphere mixes rapidly in the vertical direction, parametrized physics fare typically assumed to depend only on some ML parameters\u0012and the atmospheric column overlying a single horizontal grid cell i. We denote this horizontally local state with xi2Rmwheremis the number of vertical grid points times the number of 3D ﬁelds input to the parametrization. In this work, fwill include sources and sinks of humidity and heat due to moist physical processes. Moist physics are conventionally handled by a suite of human-devised parametrizations encorporating physical constraints and empirical knowledge. These typically assume an analytical sub-grid-scale cloud model in statistical equilibrium with the large-scale environment (Arakawa, 2004), but recent work proposes parameterizing moist physics using machine learning models trained from either higher-ﬁdelity simulations (Rasp et al., 2018; Brenowitz and Bretherton, 2018, 2019; Yuval and O’Gorman, 2020; Krasnopolsky et al., 2010) or reanalysis data (McGibbon and Bretherton, 2019). These ML schemes are trained ofﬂine, as a supervised learning problem, where the inputs xiand outputs fare taken from a pre-computed dataset. Because this training fails to account for feedbacks between giandf, ofﬂine accuracy does not translate immediately into online accuracy when the ML is coupled to the ﬂuid dynamics solver and used to simulate the weather or climate. For example, ofﬂine training will often yield a numerically unstable scheme that causes an online simulation to crash within a matter of days (Brenowitz and Bretherton, 2019; Brenowitz et al., 2020). The reasons behind this are starting to emerge. Brenowitz et al. (2020) demonstrated with formal stability analysis that this instability is related to the linearized behavior of a neural network (NN) when coupled to idealized wave dynamics. Also, feedback loops in coupled simulations can easily generate out-of-sample inputs unlike any in the training sample. On the other hand, random forests (RFs) are more stable online, likely because they can only predict averages of observed samples (O’Gorman and Dwyer, 2018; Yuval and O’\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy and dirty parts removed:\n\nMachine learning has the potential to improve the accuracy of climate models, but it should leverage existing physical knowledge. Climate and weather models represent the Earth's atmosphere as a system of discretized ordinary differential equations (ODEs). However, these models typically have a horizontal grid size of 100 km and cannot resolve the dominant physical scales of some atmospheric processes, such as turbulence, cumulus convection, and cloud-radiation interactions. These processes must be parametrized.\n\nParametrization is a function approximation problem. Let the ODEs describing a climate model be divided into two components:\n\ndxi/dt = g(x, t) + f(xi)\n\nThe known physics, g, account for large-scale atmospheric fluid mechanics and some set of known physics, and are a function of the non-local state x. The vector x represents the state of the global atmosphere (e.g., temperature, humidity, and wind).\n\nMoist physics are conventionally handled by human-devised parametrizations incorporating physical constraints and empirical knowledge. These typically assume an analytical sub-grid-scale cloud model in statistical equilibrium with the large-scale environment. However, recent work proposes parameterizing moist physics using machine learning models trained from higher-fidelity simulations or reanalysis data.\n\nMachine learning models, such as random forests (RF) and neural networks (NNs), can improve the accuracy of traditional physical parametrizations. We compare the performance of RF and NNs at parametrizing the aggregate effect of moist physics in a 3 km resolution global simulation with an atmospheric model. The NN outperforms the RF when evaluated offline on a testing dataset. However, when the ML models are coupled to an atmospheric model run at 200 km resolution, the NN-assisted simulation crashes within 7 days, while the RF-assisted simulations remain stable.\n\nBoth runs produce more accurate weather forecasts than a baseline configuration, but globally averaged climate variables drift over longer timescales. The reasons behind the instability of NNs in online simulations are starting to emerge. Formal stability analysis has shown that this instability is related to the linearized behavior of a neural network when coupled to idealized wave dynamics. Feedback loops in coupled simulations can also generate out-of-sample inputs unlike any in the training sample.\n\nRandom forests are more stable online, likely because they can only predict averages of observed samples. This suggests that machine learning models should be designed to account for feedbacks between the parametrized physics and the fluid dynamics solver to achieve online accuracy."
}