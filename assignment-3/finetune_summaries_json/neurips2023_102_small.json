{
    "question": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThe following text is noisy and dirty, so please rephrase the following text while removing noisy text (e.g., incorrect characters coming from the pdf reader, emails, footnotes, etc.), but without removing important content or adding new data, however keep as much data as possible:\n\n\"e Klein IBM Research kleinl@us.ibm.com Abstract To mitigate global warming, greenhouse gas sources need to be resolved at a high spatial resolution and monitored in time to ensure the reduction and ultimately elimination of the pollution source. However, the complexity of computation in resolving high-resolution wind fields left the simulations impractical to test different time lengths and model configurations. This study presents a preliminary development of a physics-informed super-resolution (SR) generative adversarial network (GAN) that super-resolves the three-dimensional (3D) low-resolution wind fields by upscaling ×9 times. We develop a pixel-wise self-attention (PWA) module that learns 3D weather dynamics via a self-attention computation followed by a 2D convolution. We also employ a loss term that regularizes the self-attention map during pretraining, capturing the vertical convection process from input wind data. The new PWA SR-GAN shows the high-fidelity super-resolved 3D wind data, learns a wind structure at the high-frequency domain, and reduces the computational cost of a high-resolution wind simulation by ×89.7 times. 1 Introduction Accurate tracing and monitoring of greenhouse gas (GHG) sources is a key measurement to take action for tackling the mitigation of global warming issues [ 3]. The higher spatial resolution of wind simulation enables precise tracking of GHG emissions from potential sources, and helps decision-making in various fields such as policymakers, agriculture, and renewable energy. However, high-resolution simulation is not always available due to the demands of computational resources. Artificial Intelligence (AI), including deep neural networks (DNNs), can reduce the computational cost by upscaling the wind fields from low-resolution (LR) to high-resolution (HR) data. Super- resolution (SR) is one of the solutions to achieve the goal: conventional SR techniques rely on convolutional neural networks (CNNs) to reproduce realistic HR wind fields [ 12,14,7,9,15,1]. However, these CNN-based approaches either perform on 2D data or fall short of capturing the 3D dynamics in weather systems because a convolutional kernel truncates the association between Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.vertical layers, limiting to learning of convection and diurnal cycles induced by incoming solar radiations. Another issue is that widely used weather simulations employ a non-uniform grid in a vertical axis for computational stability. The difference in height between a pair of two adjacent vertical layers becomes larger at higher altitudes. Thus, CNN is not sufficient to capture physics at the same vertical scaling. To address these issues, we develop a prototype of a novel architecture of physics-informed neural networks that learn multi-scale spatial dynamics. Our goal is to develop a physics-informed neural network that super-resolves 900 m resolution of three-dimensional wind data into 100 m scale high-resolution wind data and captures three-dimensional dynamics in weather systems. 2 3D super-resolution of wind fields We develop a pixel-wise self-attention network (PWA) to learn the three-dimensional dynamics of weather simulations. Using the neural network as a generator, we train a generative network for super-resolving wind velocity fields. 2.1 WRF model dataset The Weather Research & Forecasting Model (WRF) [ 11] has been widely used for simulating weather systems from mesoscale to turbulence scales. Large-eddy simulation (LES) is often nested into the WRF framework to allow simulating a convective process to capture a more realistic turbulence structure [ 2]. Outputs from WRF-LES used for this study are nested in 900 m, 300 m, and 100 m horizontal resolution. The outer 900 m and inner 100 m simulations differ in their model physics and our ultimate goal is to super-resolve 900 m LR data to 100 m HR data. This study, however, focuses on synthesizing the 900 m LR data by spatially averaging 100 m HR data as a preliminary step. Our training and testing data are produced by a WRF nested LES at 100 m horizontal scale and 59 vertical layers, generating outputs every five minutes from 00 UTC to 23:59 UTC. The initialization time window is set for two hours starting at 22:00 UTC a day before. We sample training and testing data randomly from one-month simulation outputs from September 2019. We select three wind velocity fields (U, V, W), all at 100 m spatial resolution over 40 km ×40 km simulation domain, and use only 8 layers from the surface level. We then extract 22 500 training and 2500 testing data, as the smaller geographical images, each of which is 126 pixels ×126 pixels ( ∼12.6 km ×12.6 km) for high-resolution (HR) data. To synthesize low-resolution (LR) data, we average every 9×9pixels, giving 900 m LR data. 2.\".<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "answer": "Here's the rephrased text with the noisy data removed:\n\nTo mitigate global warming, it is essential to resolve greenhouse gas sources at a high spatial resolution and monitor them in real-time to ensure the reduction and eventual elimination of pollution sources. However, the complexity of computation in resolving high-resolution wind fields makes it impractical to test different time lengths and model configurations. This study presents a preliminary development of a physics-informed super-resolution (SR) generative adversarial network (GAN) that super-resolves three-dimensional (3D) low-resolution wind fields by upscaling them nine times.\n\nWe develop a pixel-wise self-attention (PWA) module that learns 3D weather dynamics via a self-attention computation followed by a 2D convolution. We also employ a loss term that regularizes the self-attention map during pretraining, capturing the vertical convection process from input wind data. The new PWA SR-GAN shows high-fidelity super-resolved 3D wind data, learns a wind structure at the high-frequency domain, and reduces the computational cost of a high-resolution wind simulation by 89.7 times.\n\nAccurate tracing and monitoring of greenhouse gas (GHG) sources are crucial for tackling global warming issues. Higher spatial resolution of wind simulation enables precise tracking of GHG emissions from potential sources, aiding decision-making in various fields such as policymakers, agriculture, and renewable energy. However, high-resolution simulation is not always available due to computational resource demands. Artificial Intelligence (AI), including deep neural networks (DNNs), can reduce the computational cost by upscaling wind fields from low-resolution (LR) to high-resolution (HR) data. Super-resolution (SR) is one solution to achieve this goal. Conventional SR techniques rely on convolutional neural networks (CNNs) to reproduce realistic HR wind fields. However, these CNN-based approaches either perform on 2D data or fall short of capturing 3D dynamics in weather systems because a convolutional kernel truncates the association between vertical layers, limiting the learning of convection and diurnal cycles induced by incoming solar radiation.\n\nAnother issue is that widely used weather simulations employ a non-uniform grid in the vertical axis for computational stability. The difference in height between a pair of two adjacent vertical layers becomes larger at higher altitudes. Thus, CNN is not sufficient to capture physics at the same vertical scaling. To address these issues, we develop a prototype of a novel architecture of physics-informed neural networks that learn multi-scale spatial dynamics. Our goal is to develop a physics-informed neural network that super-resolves 900 m resolution of three-dimensional wind data into 100 m scale high-resolution wind data and captures three-dimensional dynamics in weather systems.\n\nWe develop a pixel-wise self-attention network (PWA) to learn the three-dimensional dynamics of weather simulations. Using the neural network as a generator, we train a generative network for super-resolving wind velocity fields. The Weather Research & Forecasting Model (WRF) has been widely used for simulating weather systems from mesoscale to turbulence scales. Large-eddy simulation (LES) is often nested into the WRF framework to allow simulating a convective process to capture a more realistic turbulence structure. Outputs from WRF-LES used for this study are nested in 900 m, 300 m, and 100 m horizontal resolution. The outer 900 m and inner 100 m simulations differ in their model physics, and our ultimate goal is to super-resolve 900 m LR data to 100 m HR data. This study, however, focuses on synthesizing the 900 m LR data by spatially averaging 100 m HR data as a preliminary step.\n\nOur training and testing data are produced by a WRF nested LES at 100 m horizontal scale and 59 vertical layers, generating outputs every five minutes from 00 UTC to 23:59 UTC. The initialization time window is set for two hours starting at 22:00 UTC a day before. We sample training and testing data randomly from one-month simulation outputs from September 2019. We select three wind velocity fields (U, V, W), all at 100 m spatial resolution over a 40 km × 40 km simulation domain, and use only 8 layers from the surface level. We then extract 22,500 training and 2,500 testing data, as smaller geographical images, each of which is 126 pixels × 126 pixels (∼12.6 km × 12.6 km) for high-resolution (HR) data. To synthesize low-resolution (LR) data, we average every 9 × 9 pixels, giving 900 m LR data."
}